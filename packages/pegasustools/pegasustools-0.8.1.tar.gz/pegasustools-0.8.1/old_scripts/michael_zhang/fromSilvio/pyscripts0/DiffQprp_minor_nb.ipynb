{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47274b-420e-4676-a2c1-b3c287674f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import math\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pegasus_read as pegr\n",
    "from matplotlib.pyplot import *\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from get_kparofkprp import get_kparofkprp\n",
    "import xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bb4037-71c4-4c30-bfd0-07296de130ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'b_b3_sim1'\n",
    "nspecies = 1#7\n",
    "plotsp = [1] #[0,2,1]\n",
    "#charge = [1,1,1]\n",
    "#mass = [1,1,1]\n",
    "charge = [1,5,2]\n",
    "mass = [1,16,4]\n",
    "\n",
    "\n",
    "#output range  phi   ()\n",
    "it0 = 50#25#0 #25 #65\n",
    "it1 = 76#50#76 #50 #144\n",
    "#output range f\n",
    "itf0 = 146#73#146#73#0\n",
    "itf1 = 222#146#222#222\n",
    "#25 and 73, 50 and 146\n",
    "#Try using a later range to match better (and use what constants Silvio has for each of his runs)\n",
    "interv = \"50-76/\"\n",
    "#interv = \"25-50/\"\n",
    "#interv = \"25-76/\"\n",
    "\n",
    "# window avg of f\n",
    "rolling_window = 15#15\n",
    "\n",
    "#cooling corrections\n",
    "it0corr = 0\n",
    "it1corr = 23 #25\n",
    "cooling_corr = False # shouldnt affect SH here? check... #False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e089f-8cea-46a7-890d-1eed2ed7b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box parameters (beta = 0.3)\n",
    "aspct = 6\n",
    "lprp = 48.1802/(2.0*np.pi)                # in (2*pi*d_i) units   divide by 2pi\n",
    "lprl = lprp*aspct         # in (2*pi*d_i) units\n",
    "Lperp = 2.0*np.pi*lprp    # in d_i units\n",
    "Lpara = 2.0*np.pi*lprl    # in d_i units\n",
    "N_perp = 280  #ncells in perp direction\n",
    "N_para = N_perp*aspct     # assuming isotropic resolution\n",
    "kperpdi0 = 1./lprp        # minimum k_perp ( = 2*pi / Lperp)\n",
    "kparadi0 = 1./lprl        # minimum k_para ( = 2*pi / Lpara)\n",
    "betai0 = 0.3 #1./9.            # ion plasma beta\n",
    "tau0 = 1.                 # temperature ratio (Te/Ti)\n",
    "beta0 = (1.+tau0)*betai0  # total plasma beta\n",
    "\n",
    "#number of processors used   (check if he computes D locally on each proc or not)\n",
    "# seems the f read in is a sum over all processors (not local)\n",
    "n_proc = 350*56\n",
    "\n",
    "#k_perp shells\n",
    "nkshells = 198#200\n",
    "\n",
    "#binning type\n",
    "bin_type = \"linear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40001291-c22c-4fcd-ad21-c3abf54e3ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaussian filter\n",
    "apply_smoothing = True #False\n",
    "smooth_method = 'gaussian'\n",
    "filter_passes = 1 #20 #10\n",
    "#gaussian filter\n",
    "sigma_smoothing = 0.5 #0.33\n",
    "#Savitzky-Golay filter\n",
    "window_size = 5\n",
    "polyn_order = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb4fa88-eb2e-4ff3-9c8d-884cb24d7c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy gradient: derivative order at edges\n",
    "edge_grad_order = 2\n",
    "\n",
    "#nomalization methods\n",
    "same_norm_all = False #True #False\n",
    "\n",
    "#exponential correction in diffusion coeff\n",
    "exp_corr = True #False\n",
    "c0exp = 0.09 #beta=0.3 0.05 #0.05\n",
    "\n",
    "#shaded area: +/- c_pm_std*sigma (sigma = standard dev.)\n",
    "c_pm_std = 1.0 #0.5\n",
    "\n",
    "#--parameters for final plot  k_perp w_perp / \\Omega = kappa  (translation from k_perp to w_perp for a given particle)\n",
    "kappaU01 = 1.1 #beta = 0.3 1.25 #1.2\n",
    "kappaB01 = 1.1 #1.25 #1.2\n",
    "kappaPHI01 = 1.1 #1.25 #1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d7b9d0-010b-4429-91b4-c24ecdcd1874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#complement kpara*dBperp. dont know what this is\n",
    "dBprp_complement = False #True #False\n",
    "dtheta_dir = '1p5deg/'\n",
    "path_strct_fnct = '../strct_fnct/'+dtheta_dir\n",
    "m_order = '2'\n",
    "cbprp_sign = +1.\n",
    "\n",
    "#2*pi coefficient            k_perp lambda =1 or k_perp lambda = 2pi. Chose the former\n",
    "TWOPIcoeff = False #True\n",
    "\n",
    "#non-linear corrections\n",
    "NLcorrections = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5ad813-7a7f-4216-9ff9-7536e509b451",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure format\n",
    "output_figure = False #True #False\n",
    "fig_frmt = \".pdf\"#\".png\"#\".pdf\"\n",
    "width_2columns = 512.11743/72.2\n",
    "width_1column = 245.26653/72.2\n",
    "\n",
    "#verbosity\n",
    "verb_diag = False\n",
    "verb_read = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a9a32-b99e-4dc8-9c10-a0ff921741bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--rho_i units and KAW eigenvector normalization for density spectrum\n",
    "kperprhoi0 = np.sqrt(betai0)*kperpdi0\n",
    "kpararhoi0 = np.sqrt(betai0)*kparadi0\n",
    "normKAW = betai0*(1.+betai0)*(1. + 1./(1. + 1./betai0))\n",
    "#--\n",
    "#--alfven speed (v_th units)\n",
    "vA01 = np.sqrt(1./betai0)\n",
    "#--d_i scale (rho_th units)\n",
    "kdi01 = np.sqrt(betai0)\n",
    "\n",
    "#--heating normalization\n",
    "Qnormalization01 = 0.75 #0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2321f24-2e7b-4ab2-a547-2163763ef114",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths\n",
    "problem = \"minor_turb\"\n",
    "path_save = \"../figures/\"\n",
    "base = \"../saved-analysis/spectrum_dat/\"+name+\"/\"+name\n",
    "#path_read_lev = \"../fig_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8809614d-e95a-4e3b-972f-c9b933ee39d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot parameters\n",
    "\n",
    "#latex fonts\n",
    "font = 9\n",
    "mpl.rc('text', usetex=True)\n",
    "mpl.rc('font', family = 'serif')\n",
    "mpl.rcParams['xtick.labelsize']=font-1\n",
    "mpl.rcParams['ytick.labelsize']=font-1\n",
    "#mpl.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath}\"]\n",
    "mpl.rcParams['contour.negative_linestyle'] = 'solid'\n",
    "plt.rcParams[\"font.weight\"] = \"normal\"\n",
    "plt.rcParams['xtick.top']=True\n",
    "plt.rcParams['ytick.right']=True\n",
    "\n",
    "\n",
    "#Hawley colormap\n",
    "bit_rgb = np.linspace(0,1,256)\n",
    "colors = [(0,0,127), (0,3,255), (0,255,255), (128,128,128), (255,255,0),(255,0,0),(135,0,0)]\n",
    "positions = [0.0,0.166667,0.333333,0.5,0.666667,0.833333,1]\n",
    "for iii in range(len(colors)):\n",
    " colors[iii] = (bit_rgb[colors[iii][0]],\n",
    "                bit_rgb[colors[iii][1]],\n",
    "                bit_rgb[colors[iii][2]])\n",
    "\n",
    "cdict = {'red':[], 'green':[], 'blue':[]}\n",
    "for pos, color in zip(positions, colors):\n",
    " cdict['red'].append((pos, color[0], color[0]))\n",
    " cdict['green'].append((pos, color[1], color[1]))\n",
    " cdict['blue'].append((pos, color[2], color[2]))\n",
    "\n",
    "cmap = mpl.colors.LinearSegmentedColormap('my_colormap',cdict,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0211b2c-8118-415e-ac31-3f697dedd34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n [ reading initial condition ]\")\n",
    "vdf0, time, vprp0, vprl0 = pegr.readmat_vdf(name,0,1,nspecies,plotsp,edv=False,grid=True,verbose=True)\n",
    "\n",
    "#first normalization by number of processors\n",
    "for i in np.arange(nspecies):\n",
    "    vdf0[i] = vdf0[i][0,:,:] / float(n_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3e69e8-cc78-4b2b-815f-f947f7d9c4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cooling_corr:\n",
    "    #correcting for numerical cooling\n",
    "    print(\"\\n [ calculate cooling correction (vs w_perp) ]\")\n",
    "    # if not apply_smoothing - store in edotv_prp_smooth arrays etc instead\n",
    "    # can just do everything in one line instead\n",
    "    # calculate here to not overload storage once main vdfs are read in\n",
    "    blank1, blank2, edotv_prp_, edotv_prl_, blank3, blank4 = pegr.readmat_vdf(name,it0corr,it1corr+1,nspecies,plotsp,edv=True,grid=True,verbose=verb_read)\n",
    "\n",
    "    for sp in np.arange(nspecies):\n",
    "        edotv_prl_[sp] = edotv_prl_[sp] / float(n_proc)\n",
    "        edotv_prp_[sp] = edotv_prp_[sp] / float(n_proc)\n",
    "\n",
    "        if apply_smoothing:\n",
    "            for ifilt in range(filter_passes):\n",
    "              edotv_prp_[sp] = gaussian_filter(edotv_prp_[sp],sigma=sigma_smoothing,axes=(1,2))\n",
    "              edotv_prl_[sp] = gaussian_filter(edotv_prl_[sp],sigma=sigma_smoothing,axes=(1,2))\n",
    "\n",
    "    edotv_prl_corr = []\n",
    "    edotv_prp_corr = []\n",
    "    edotv_prl_smooth_corr = []\n",
    "    edotv_prp_smooth_corr = []\n",
    "\n",
    "    for sp in np.arange(nspecies):\n",
    "        edotv_prl_corr.append(np.mean(edotv_prl_[sp],axis=0,keepdims=True))\n",
    "        edotv_prp_corr.append(np.mean(edotv_prp_[sp],axis=0,keepdims=True))\n",
    "        if (not apply_smoothing):\n",
    "            edotv_prl_smooth_corr.append(gaussian_filter(edotv_prl_[sp],sigma=sigma_smoothing,axes=(1,2)))\n",
    "            edotv_prp_smooth_corr.append(gaussian_filter(edotv_prp_[sp],sigma=sigma_smoothing,axes=(1,2)))\n",
    "            for ifilt in range(filter_passes-1):\n",
    "                edotv_prl_smooth_corr[sp] = gaussian_filter(edotv_prl_smooth_corr[sp],sigma=sigma_smoothing,axes=(1,2))\n",
    "                edotv_prp_smooth_corr[sp] = gaussian_filter(edotv_prp_smooth_corr[sp],sigma=sigma_smoothing,axes=(1,2))\n",
    "            edotv_prl_smooth_corr[sp] = np.mean(edotv_prl_smooth_corr[sp],axis=0,keepdims=True)\n",
    "            edotv_prp_smooth_corr[sp] = np.mean(edotv_prp_smooth_corr[sp],axis=0,keepdims=True)\n",
    "\n",
    "    del blank1, blank2, edotv_prp_, edotv_prl_, blank3, blank4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfab44c-0d84-4448-856a-7e1b310fb8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HEATING VS W_PERP (beta = 0.3)\n",
    "#\n",
    "# -> reading simulation data, time averaging, and cooling corrections\n",
    "# -> also: reading spectra of fluctuations, reducing to k_perp spectra, and time averaging\n",
    "#\n",
    "print(\"\\n ### HEATING VS W_PERP ###\")\n",
    "\n",
    "# read in VDF, edotv file saved using jono's scripts\n",
    "vdf_, time, edotv_prp_, edotv_prl_, vprp, vprl = pegr.readmat_vdf(name,itf0,itf1+1,nspecies,plotsp,edv=True,grid=True,verbose=verb_read)\n",
    "\n",
    "time = time[itf0:itf1+1,:]\n",
    "\n",
    "vdf_avg = []\n",
    "edotv_prp_t = []\n",
    "edotv_prl_t = []\n",
    "edotv_prp_avg = []\n",
    "edotv_prl_avg = []\n",
    "dfdwprp_t = []\n",
    "dfdwprp_avg = []\n",
    "\n",
    "for sp in np.arange(nspecies):\n",
    "  if verb_diag:\n",
    "    print(\"\\n\")\n",
    "    print(\"#########################################################\")\n",
    "    print(\"### v-space analysis: distribution function & heating ###\")\n",
    "    print(\"#########################################################\")\n",
    "  print(\"species\",plotsp[sp])\n",
    "\n",
    "  # is assumed dvprp and dvprl are the same for all species later on. (can change that)\n",
    "  dvprp = vprp[sp][0,2,0]-vprp[sp][0,1,0]\n",
    "  dvprl = vprl[sp][0,0,2]-vprl[sp][0,0,1]\n",
    "\n",
    "  #first normalization by number of processors\n",
    "  vdf_[sp] = vdf_[sp] / float(n_proc)\n",
    "  edotv_prl_[sp] = edotv_prl_[sp] / float(n_proc)\n",
    "  edotv_prp_[sp] = edotv_prp_[sp] / float(n_proc)\n",
    "\n",
    "  if apply_smoothing:\n",
    "    for ifilt in range(filter_passes):\n",
    "      edotv_prp_[sp] = gaussian_filter(edotv_prp_[sp],sigma=sigma_smoothing,axes=(1,2))\n",
    "      edotv_prl_[sp] = gaussian_filter(edotv_prl_[sp],sigma=sigma_smoothing,axes=(1,2))\n",
    "\n",
    "  # average over a rolling window (could also try fixed bin avgs)\n",
    "  vdf_avg.append(xarray.DataArray(vdf_[sp],dims=['t','wprp','wprl']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "  edotv_prp_avg.append(xarray.DataArray(edotv_prp_[sp],dims=['t','wprp','wprl']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "  edotv_prl_avg.append(xarray.DataArray(edotv_prl_[sp],dims=['t','wprp','wprl']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "\n",
    "  edotv_prp_t.append(edotv_prp_[sp]*1.0)\n",
    "  edotv_prl_t.append(edotv_prl_[sp]*1.0)\n",
    "\n",
    "  #computing <df/dwprp>\n",
    "  fvprp_t = np.sum(vdf_[sp]/vprp[sp]*dvprl,axis=2) / np.sum(np.sum(vdf_[sp]/vprp[sp]*dvprl*dvprl,axis=2),axis=1,keepdims=True)\n",
    "  dfdwprp_t.append(np.gradient(fvprp_t,vprp[sp][0,:,0],edge_order=edge_grad_order,axis=1))\n",
    "  dfdwprp_avg.append(xarray.DataArray(dfdwprp_t[sp],dims=['t','wprp']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f811fdfe-ec04-49f6-8d61-c4e7ca971218",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.gradient(fvprp_t,vprp[sp][0,:,0],edge_order=edge_grad_order,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa11328-8364-4262-8116-a6e697df340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vprp[sp][:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b04934-885f-4311-abef-775ef3a7ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "  ### reading spectra of fluctuations\n",
    "  ### NOTE: these are all in code units [i.e., both kprp and E(kprp) ]\n",
    "\n",
    "for ind in range(it0,it1+1):\n",
    "    filename1 = base+\".\"+\"%05d\"%ind+\".spectrum1d.nkperp\"+\"%d\"%nkshells+\".\"+bin_type+\".Uprp.dat\"\n",
    "    filename2 = base+\".\"+\"%05d\"%ind+\".spectrum1d.nkperp\"+\"%d\"%nkshells+\".\"+bin_type+\".Bprl.dat\"\n",
    "    filename3 = base+\".\"+\"%05d\"%ind+\".spectrum1d.nkperp\"+\"%d\"%nkshells+\".\"+bin_type+\".PHI.dat\"\n",
    "    if dBprp_complement:\n",
    "        filename4 = base+\".\"+\"%05d\"%ind+\".spectrum1d.nkperp\"+\"%d\"%nkshells+\".\"+bin_type+\".Bprp.dat\"\n",
    "        filename5 = base+\".\"+\"%05d\"%ind+\".spectrum1d.nkperp\"+\"%d\"%nkshells+\".\"+bin_type+\".B.dat\"\n",
    "    if verb_diag:\n",
    "        print(\"\\n  [reading spectrum of the fluctuations]\")\n",
    "        print(\"    ->\",filename1)\n",
    "        print(\"    ->\",filename2)\n",
    "        print(\"    ->\",filename3)\n",
    "    if dBprp_complement:\n",
    "        print(\"    ->\",filename4)\n",
    "\n",
    "    #Phi spectrum vs k_perp - probably just what we want\n",
    "    dataPhikprp = np.loadtxt(filename3)\n",
    "\n",
    "    if (ind == it0):\n",
    "        #generating 1D arrays for the first time\n",
    "        kprp_phi = dataPhikprp[1:,0]\n",
    "        Phikprp = np.zeros(len(kprp_phi))\n",
    "        Phikprp_t = np.zeros([len(kprp_phi),it1-it0+1])\n",
    "\n",
    "    # average over time window\n",
    "    Phikprp[:] = Phikprp[:] + dataPhikprp[1:,1]/float(it1-it0+1)\n",
    "\n",
    "    Phikprp_t[:,ind-it0] = dataPhikprp[1:,1]\n",
    "\n",
    "    # end loop over time\n",
    "\n",
    "# interpolate to time cadence of VDF data - but VDF more frequent...\n",
    "#phi_t_arr = np.arange(77)*28.90811\n",
    "#for ind in range(Phikprp_t.shape[0]):\n",
    "#  Phikprp_t[ind,:] = np.interp(time[:,0] phi_t_arr, Phikprp_t[ind,:])\n",
    "\n",
    "kprp = kprp_phi\n",
    "kprp_phi_rho = np.sqrt(betai0)*kprp_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babcba89-0720-47d7-8a68-b734530333ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_t_arr = np.arange(it0,it1+1)*28.90811\n",
    "dfdwprp_t_interp = []\n",
    "for sp in np.arange(nspecies):\n",
    "    dfdwprp_t_interp.append(np.zeros((it1+1-it0,dfdwprp_t[sp].shape[1])))\n",
    "    for ind in range(dfdwprp_t[sp].shape[1]):\n",
    "        dfdwprp_t_interp[sp][:,ind] = np.interp(phi_t_arr, time[:,0], dfdwprp_t[sp][:,ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8667331-d912-48e3-9d58-b22c36d11416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vdf_[sp]/vprp[sp]\n",
    "#vdf output is actually vperp*f: restoring f\n",
    "# check if jono's script already corrects for this\n",
    "vdf = []\n",
    "for sp in np.arange(nspecies):\n",
    "    vdf.append(vdf_avg[sp] / vprp[sp])\n",
    "    vdf0[sp] = vdf0[sp] / vprp0[sp][0,:,:]\n",
    "\n",
    "edotv_prl = edotv_prl_avg\n",
    "edotv_prp = edotv_prp_avg\n",
    "if (not apply_smoothing):\n",
    "  edotv_prl_smooth = edotv_prl_smooth_avg\n",
    "  edotv_prp_smooth = edotv_prp_smooth_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33156009-4a89-4207-9011-e89428093d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(\"########################## BETA = 0.3 ##########################\")\n",
    "print(\" (from v space -- before cooling corrections) \")\n",
    "print(\" after 3.5t_A\")\n",
    "for sp in  np.arange(nspecies):\n",
    "    print(\" species \",plotsp[sp])\n",
    "    print(\" 1) integral of <Qperp> (code units): \",np.mean(np.sum(edotv_prp[sp][:,:,:]*dvprp*dvprl,axis=(1,2))))\n",
    "    print(\" 2) integral of <Qpar> (code units): \",np.mean(np.sum(edotv_prl[sp][:,:,:]*dvprp*dvprl,axis=(1,2))))\n",
    "print(\"################################################################\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#computing d<f>/dw_perp\n",
    "#dfdwprp = np.gradient(np.sum(vdf*dvprl,axis=1),vprp)\n",
    "# f_vprp using rolling averaged f, and then calculating dfdwprp\n",
    "f_vprp = []\n",
    "f0_vprp = []\n",
    "dfdwprp = []\n",
    "dfdwprp_finitediff = []\n",
    "gg_tmp = []\n",
    "gg_tmp_smooth = []\n",
    "\n",
    "for sp in np.arange(nspecies):\n",
    "    f_vprp.append(np.sum(vdf[sp]*dvprl,axis=2)/np.abs(  np.sum(np.sum(vdf[sp]*dvprl*dvprp,axis=2),axis=1,keepdims=True)   ))\n",
    "    f0_vprp.append(np.sum(vdf0[sp]*dvprl,axis=1)/np.abs(np.sum(vdf0[sp]*dvprl*dvprp)))\n",
    "    dfdwprp.append(np.gradient(f_vprp[sp],vprp[sp][0,:,0],edge_order=edge_grad_order,axis=1))\n",
    "    dfdwprp_finitediff.append(np.zeros(f_vprp[sp].shape))\n",
    "    dfdwprp_finitediff[sp][:,1:-1] = (f_vprp[sp][:,2:]-f_vprp[sp][:,:-2])/(vprp[sp][:,2:,0]-vprp[sp][:,:-2,0])\n",
    "    dfdwprp_finitediff[sp][:,0] = (f_vprp[sp][:,1]-f_vprp[sp][:,0])/(vprp[sp][:,1,0]-vprp[sp][:,0,0])\n",
    "    dfdwprp_finitediff[sp][:,len(vprp[sp][0,:,0])-1] = (f_vprp[sp][:,len(vprp[sp][0,:,0])-1]-f_vprp[sp][:,len(vprp[sp][0,:,0])-2])/(vprp[sp][:,len(vprp[sp][0,:,0])-1,0]-vprp[sp][:,len(vprp[sp][0,:,0])-2,0])\n",
    "\n",
    "# rolling avg edotv\n",
    "    gg_tmp.append(edotv_prp[sp]/(np.abs( np.abs(np.sum(edotv_prl[sp]*dvprp*dvprl,axis=(1,2),keepdims=True)) + np.abs(np.sum(edotv_prp[sp]*dvprp*dvprl,axis=(1,2),keepdims=True)) )))\n",
    "    edotv_prp_t[sp] /= (np.abs( np.abs(np.sum(edotv_prl_t[sp]*dvprp*dvprl,axis=(1,2),keepdims=True)) + np.abs(np.sum(edotv_prp_t[sp]*dvprp*dvprl,axis=(1,2),keepdims=True)) ))\n",
    "    if (not apply_smoothing):\n",
    "        gg_tmp_smooth.append(edotv_prp_smooth[sp]/(np.abs( np.abs(np.sum(edotv_prl_smooth[sp]*dvprp*dvprl,axis=(1,2),keepdims=True)) + np.abs(np.sum(edotv_prp_smooth[sp]*dvprp*dvprl,axis=(1,2),keepdims=True)) )))\n",
    "        edotv_prp_smooth_t[sp] /= (np.abs( np.abs(np.sum(edotv_prl_smooth_t[sp]*dvprp*dvprl,axis=(1,2),keepdims=True)) + np.abs(np.sum(edotv_prp_smooth_t[sp]*dvprp*dvprl,axis=(1,2),keepdims=True)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf2b78f-63eb-4819-ad26-62b3eeac14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cooling_corr:\n",
    "    #correcting for numerical cooling\n",
    "    print(\"\\n [ apply cooling correction (vs w_perp) ]\")\n",
    "    \"\"\"\n",
    "    # if not apply_smoothing - store in edotv_prp_smooth arrays etc instead\n",
    "    # can just do everything in one line instead\n",
    "    edotv_prl_corr.append(np.mean(edotv_prl_[sp][it0corr:it1corr+1,:,:],axis=0,keepdims=True))\n",
    "    edotv_prp_corr.append(np.mean(edotv_prp_[sp][it0corr:it1corr+1,:,:],axis=0,keepdims=True))\n",
    "    if (not apply_smoothing):\n",
    "        edotv_prl_smooth_corr.append(gaussian_filter(edotv_prl_[sp][it0corr:it1corr+1,:,:],sigma=sigma_smoothing,axes=(1,2)))\n",
    "        edotv_prp_smooth_corr.append(gaussian_filter(edotv_prp_[sp][it0corr:it1corr+1,:,:],sigma=sigma_smoothing,axes=(1,2)))\n",
    "        for ifilt in range(filter_passes-1):\n",
    "            edotv_prl_smooth_corr[sp] = gaussian_filter(edotv_prl_smooth_corr[sp],sigma=sigma_smoothing,axes=(1,2))\n",
    "            edotv_prp_smooth_corr[sp] = gaussian_filter(edotv_prp_smooth_corr[sp],sigma=sigma_smoothing,axes=(1,2))\n",
    "        edotv_prl_smooth_corr[sp] = np.mean(edotv_prl_smooth_corr[sp],axis=0,keepdims=True)\n",
    "        edotv_prp_smooth_corr[sp] = np.mean(edotv_prp_smooth_corr[sp],axis=0,keepdims=True)\n",
    "    \"\"\"\n",
    "\n",
    "    gg_tmp[sp] -= edotv_prp_corr[sp]/(np.abs( np.abs(np.sum(edotv_prl_corr[sp]*dvprp*dvprl,keepdims=True)) + np.abs(np.sum(edotv_prp_corr[sp]*dvprp*dvprl,keepdims=True)) ))\n",
    "    edotv_prp_t[sp] -= edotv_prp_corr[sp]/(np.abs( np.abs(np.sum(edotv_prl_corr[sp]*dvprp*dvprl,keepdims=True)) + np.abs(np.sum(edotv_prp_corr[sp]*dvprp*dvprl,keepdims=True)) ))\n",
    "\n",
    "    if (not apply_smoothing):\n",
    "        gg_tmp_smooth[sp] -= edotv_prp_smooth_corr[sp]/(np.abs( np.abs(np.sum(edotv_prl_smooth_corr[sp]*dvprp*dvprl,keepdims=True)) + np.abs(np.sum(edotv_prp_smooth_corr[sp]*dvprp*dvprl,keepdims=True)) ))\n",
    "        edotv_prp_smooth_t[sp] -= edotv_prp_smooth_corr[sp]/(np.abs( np.abs(np.sum(edotv_prl_smooth_corr[sp]*dvprp*dvprl,keepdims=True)) + np.abs(np.sum(edotv_prp_smooth_corr[sp]*dvprp*dvprl,keepdims=True)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8ffbd-234e-4972-a6d3-8b3703626a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(gg_tmp[sp])#,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d0510f-11ae-4235-928b-b30f714f39ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nonzero(edotv_prp_[sp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e211ba1f-9d5e-419f-83c6-8cc7468265c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#edotv_prp[sp][200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13675747-a25d-4491-9d30-455960cb95ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(edotv_prp_t[sp]*dvprl,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa9c8f0-d30a-4bc3-9915-d0f3d990e7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffc2a1c-227d-4748-be91-b21116ac5dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c3f22-4bed-4ad2-9b89-b0931dab2719",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qprp_vprp = []\n",
    "Qprp_vprp_t = []\n",
    "Qprp_vprp_t_avg = []\n",
    "Qprp_vprp_smooth = []\n",
    "Qprp_vprp_smooth_t = []\n",
    "Qprp_vprp_smooth_t_avg = []\n",
    "stdQprp_vprp = []\n",
    "stdQprp_vprp_smooth = []\n",
    "Dprpprp = []\n",
    "Dprpprp_sign = []\n",
    "Dprpprp_t = []\n",
    "Dprpprp_t_avg = []\n",
    "Dprpprp_smooth = []\n",
    "Dprpprp_sign_smooth = []\n",
    "Dprpprp_smooth_t = []\n",
    "Dprpprp_smooth_t_avg = []\n",
    "stdDprpprp_vprp = []\n",
    "stdDprpprp_vprp_smooth = []\n",
    "\n",
    "for sp in np.arange(nspecies):\n",
    "    # total perpendicular heating from edotv\n",
    "    # does this need to be normalised by qom? since E field acceleration\n",
    "    Qprp_vprp.append(np.sum(gg_tmp[sp]*dvprl,axis=2))\n",
    "    Qprp_vprp_t.append(np.sum(edotv_prp_t[sp]*dvprl,axis=2))\n",
    "    Qprp_vprp_t_avg.append(xarray.DataArray(Qprp_vprp_t[sp],dims=['t','wprp']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "    if (not apply_smoothing):\n",
    "      Qprp_vprp_smooth.append(np.sum(gg_tmp_smooth[sp]*dvprl,axis=2))\n",
    "      Qprp_vprp_smooth_t.append(np.sum(edotv_prp_smooth_t[sp]*dvprl,axis=2))\n",
    "      Qprp_vprp_smooth_t_avg.append(xarray.DataArray(Qprp_vprp_smooth_t[sp],dims=['t','wprp']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "\n",
    "    #normalize Qprp_sim (after or before computing Dprpprp?)\n",
    "    #normQ_sim[sp] = Qnormalization01/np.sum(np.abs(Qprp_vprp[sp])*dvprp,axis=1,keepdims=True)\n",
    "    #print(\"  -> denom of normQ_sim = \",np.sum(np.abs(Qprp_vprp[sp])*dvprp,axis=1))\n",
    "    Qprp_vprp[sp] *= Qnormalization01/np.sum(np.abs(Qprp_vprp[sp])*dvprp,axis=1,keepdims=True)\n",
    "    #Qprp_vprp_t *= normQ_sim\n",
    "    Qprp_vprp_t[sp] *= Qnormalization01/np.sum(np.abs(Qprp_vprp_t[sp])*dvprp,axis=1,keepdims=True)\n",
    "    #for iit in range(it0,it1+1):\n",
    "    #  Qprp_vprp_t[:,iit-it0] *= Qnormalization01/np.sum(np.abs(Qprp_vprp_t[:,iit-it0])*dvprp)\n",
    "    #Qprp_vprp_t_avg *= normQ_sim\n",
    "    Qprp_vprp_t_avg[sp] *= Qnormalization01/np.sum(np.abs(Qprp_vprp_t_avg[sp])*dvprp,axis=1,keepdims=True)\n",
    "\n",
    "    #std in time\n",
    "    stdQprp_vprp.append(np.std(Qprp_vprp_t[sp],axis=0))\n",
    "\n",
    "    if (not apply_smoothing):\n",
    "        Qprp_vprp_smooth[sp] *= Qnormalization01/np.sum(np.abs(Qprp_vprp_smooth[sp])*dvprp,axis=1,keepdims=True)\n",
    "        Qprp_vprp_smooth_t[sp] *= Qnormalization01/np.sum(np.abs(Qprp_vprp_smooth_t[sp])*dvprp,axis=1,keepdims=True)\n",
    "        Qprp_vprp_smooth_t_avg[sp] *= Qnormalization01/np.sum(np.abs(Qprp_vprp_smooth_t_avg[sp])*dvprp,axis=1,keepdims=True)\n",
    "        stdQprp_vprp_smooth.append(np.std(Qprp_vprp_smooth_t[sp],axis=0))\n",
    "\n",
    "\n",
    "    #computing diff coefficient  heating/dfdw\n",
    "    #Get rid of divisions by zero that we get because of how many wprp we go out to (where there are no particles/f)\n",
    "    #Q is mostly small in these regions...\n",
    "    #dfdw0s = np.ones(dfdwprp[sp].shape)-np.isnan(1./dfdwprp[sp])\n",
    "    #dfdw0s_t = np.ones(dfdwprp_t[sp].shape)-np.isnan(1./dfdwprp_t[sp])\n",
    "    Dprpprp.append(- np.abs(Qprp_vprp[sp]) / dfdwprp[sp])\n",
    "    Dprpprp[sp][np.isinf(1./dfdwprp[sp])]=0\n",
    "    Dprpprp_sign.append(- Qprp_vprp[sp] / dfdwprp[sp])\n",
    "    Dprpprp_sign[sp][np.isinf(1./dfdwprp[sp])]=0\n",
    "    Dprpprp_t.append(- np.abs(Qprp_vprp_t[sp]) / dfdwprp_t[sp])\n",
    "    Dprpprp_t[sp][np.isinf(1./dfdwprp_t[sp])]=0\n",
    "    Dprpprp_t_avg.append(xarray.DataArray(Dprpprp_t[sp],dims=['t','wprp']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "    #Dprpprp_t_avg[sp][np.isnan(Dprpprp_t_avg[sp])]=0\n",
    "    stdDprpprp_vprp.append(np.std(Dprpprp_t[sp],axis=0))\n",
    "\n",
    "    if (not apply_smoothing):\n",
    "      Dprpprp_smooth.append(- np.abs(Qprp_vprp_smooth[sp]) / dfdwprp[sp])\n",
    "      Dprpprp_smooth[sp][np.isinf(1./dfdwprp[sp])]=0\n",
    "      Dprpprp_sign_smooth.append(- Qprp_vprp_smooth[sp] / dfdwprp[sp])\n",
    "      Dprpprp_sign_smooth[sp][np.isinf(1./dfdwprp[sp])]=0\n",
    "      Dprpprp_smooth_t.append(- np.abs(Qprp_vprp_smooth_t[sp]) / dfdwprp_t[sp])\n",
    "      Dprpprp_smooth_t[sp][np.isinf(1./dfdwprp_t[sp])]=0\n",
    "      Dprpprp_smooth_t_avg.append(xarray.DataArray(Dprpprp_smooth_t[sp],dims=['t','wprp']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "      #Dprpprp_smooth_t_avg[sp][np.isnan(Dprpprp_smooth_t_avg[sp])]=0\n",
    "      stdDprpprp_vprp_smooth.append(np.std(Dprpprp_smooth_t[sp],axis=0))\n",
    "\n",
    "    print(\"species \",sp)\n",
    "    print(\"\\n ##### CHECK: integral of simulation curves (beta_i = 0.3) ##### (avg after 3.5t_A)\")\n",
    "    print(\"  -> normQ_sim = \",Qnormalization01/np.mean(np.sum(np.abs(Qprp_vprp[sp])*dvprp,axis=1)[100:]))\n",
    "    print(\"  -> integral of df/dwprp..\")\n",
    "    print(\"     i) ..from np.gradient:\",np.mean(np.sum(dfdwprp[sp]*dvprp,axis=1)[100:]))\n",
    "    print(\"    ii) ..from finite diff:\",np.mean(np.sum(dfdwprp_finitediff[sp]*dvprp,axis=1)[100:]))\n",
    "    print(\"    ..to be compared with f(vprp=0):\",np.mean(f_vprp[sp][100:,0]))\n",
    "    #print(\"   [dfdwprp - dfdwprp_finitediff =\",dfdwprp - dfdwprp_finitediff,\"]\")\n",
    "    print(\"  -> integral of dQprp/dwprp: \",np.mean(np.sum(Qprp_vprp[sp]*dvprp,axis=1)[100:]))\n",
    "    print(\"  -> integral of Dprpprp.. \")\n",
    "    print(\"     i) ..from < dQ/dwprp > / < df/dwprp > :\",np.mean(np.sum(Dprpprp[sp]*dvprp,axis=1)[100:]))\n",
    "    print(\"    ii) ..from < (dQ/dwprp) / (df/dwprp) > :\",np.mean(np.sum(Dprpprp_t_avg[sp]*dvprp,axis=1)[100:]))\n",
    "    print(\" ################################################################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7009ea02-9827-448a-831d-730002ba2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isnan(1./dfdwprp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8083ab-223f-4d37-9c7e-b07baf390322",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isinf(1./dfdwprp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293bef8-3cdc-44a7-bf91-cd5fda805272",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isinf(Qprp_vprp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ea31a7-3726-4754-936f-7a82c9d2f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isinf(Qprp_vprp[0]/dfdwprp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8195a30-d7dd-490a-8f1d-634076334722",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.isnan(Qprp_vprp[0]/dfdwprp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3c0005-f939-4ccf-83d9-21601b1cdf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qprp_vprp[0][np.isinf(Qprp_vprp[0]/dfdwprp[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b2275f-3720-4581-b3fe-e13495ea4446",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qprp_vprp[0][np.isnan(Qprp_vprp[0]/dfdwprp[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a369072-e9c6-40b9-b4f3-76a87040c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPUTING THEORETICAL CURVES (Dprpprp and Qprp) FROM FLUCTUATIONS\n",
    "#\n",
    "# beta = 0.3\n",
    "alphaU = kappaU01\n",
    "alphaB = kappaB01\n",
    "alphaPHI = kappaPHI01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4feb299-0da4-45cb-a38e-d293325ed42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.interp(vprp[sp][0,:,0], alphaPHI/kprp_phi_rho[::-1], dPhi_k[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab101e4-d334-4c60-a344-2ca3f86e1c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0/alphaPHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd0b7ab-12af-46c4-8033-001bac4ddd59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc3d6cd-d98e-4979-999b-efd2f826c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "charge[plotsp[0]]/np.sqrt(mass[plotsp[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eae0f1-0f82-4f97-8253-fc449a34ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "c0exp = 0.06 #beta=0.3 0.05 #0.05\n",
    "alphaPHI = 1.1#1.1 #1.25 #1.2\n",
    "cst01 = 0.9 #0.9   #1.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe77754-4ed2-4c2b-a87f-0cdb65c05c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dPhi_v = [] #Phi vs vprp - different species may have different vprp scales\n",
    "dPhi_v_t = []\n",
    "Dprpprp_Phik = []\n",
    "Dprpprp_Phik_t = []\n",
    "Dprpprp_Phik_t_avg = []\n",
    "Qprp_Phik = []\n",
    "Qprp_Phik_t = []\n",
    "Qprp_Phik_t_avg = []\n",
    "normD_phi01 = []\n",
    "normD_phi01_t_avg = []\n",
    "Qprp_k_phik = []\n",
    "Qprp_k_phik_t_avg = []\n",
    "for sp in np.arange(nspecies):\n",
    "    # calculate k phi/beta and interpolate and convert to v-space\n",
    "    dPhi_k = np.sqrt(kprp_phi_rho*Phikprp/np.sqrt(betai0)) # attention! spectra were originally computed in kprp*di units!\n",
    "    #dPhi_v.append(np.interp(vprp[sp][0,:,0], alphaPHI/kprp_phi_rho[::-1], dPhi_k[::-1]))\n",
    "    dPhi_v.append(np.interp(vprp[sp][0,:,0], charge[plotsp[sp]]/np.sqrt(mass[plotsp[sp]]) * alphaPHI/kprp_phi_rho[::-1], dPhi_k[::-1]))\n",
    "    dPhi_v[sp] /= betai0 #thermal units\n",
    "    #\n",
    "    dPhi_k_t = np.zeros([len(kprp_phi_rho),it1-it0+1])\n",
    "    dPhi_v_t.append(np.zeros([len(vprp[sp][0,:,0]),it1-it0+1]))\n",
    "    for ind in range(it0,it1+1):\n",
    "      dPhi_k_t[:,ind-it0] = np.sqrt(kprp_phi_rho[:]*Phikprp_t[:,ind-it0]/np.sqrt(betai0)) # attention! spectra were originally computed in kprp*di units!\n",
    "      #dPhi_v_t[sp][:,ind-it0] = np.interp(vprp[sp][0,:,0], alphaPHI/kprp_phi_rho[::-1], dPhi_k_t[::-1,ind-it0])\n",
    "      dPhi_v_t[sp][:,ind-it0] = np.interp(vprp[sp][0,:,0], charge[plotsp[sp]]/np.sqrt(mass[plotsp[sp]]) * alphaPHI/kprp_phi_rho[::-1], dPhi_k_t[::-1,ind-it0])\n",
    "      dPhi_v_t[sp][:,ind-it0] = dPhi_v_t[sp][:,ind-it0] / betai0\n",
    "\n",
    "    # multiply the potential by the charge of the species of interest\n",
    "    dPhi_v[sp] *= charge[plotsp[sp]]\n",
    "    dPhi_v_t[sp] *= charge[plotsp[sp]]\n",
    "    #\n",
    "    #--second: corresponding diffusion coefficients\n",
    "    #\n",
    "    Dprpprp_Phik.append((dPhi_v[sp]**3.) / (vprp[sp][0,:,0]**2.) )           #diffusion coefficient associated to Phi_tot (in w_perp/v_th)\n",
    "    # We want dPhi_v - the fully combined phi\n",
    "    # Dprpprp_Phik calculates using time-averaged phi\n",
    "    #\n",
    "    Dprpprp_Phik_t.append(np.zeros([len(vprp[sp][0,:,0]),it1-it0+1]) )\n",
    "    for ind in range(it0,it1+1):\n",
    "      Dprpprp_Phik_t[sp][:,ind-it0] = (dPhi_v_t[sp][:,ind-it0]**3.) / (vprp[sp][0,:,0]**2.)\n",
    "      if exp_corr:\n",
    "         Dprpprp_Phik_t[sp][:,ind-it0] = Dprpprp_Phik_t[sp][:,ind-it0]*np.exp(-c0exp*(vprp[sp][0,:,0]**2./dPhi_v_t[sp][:,ind-it0]))\n",
    "    Dprpprp_Phik_t[sp] *= charge[plotsp[sp]] / mass[plotsp[sp]]\n",
    "    Dprpprp_Phik_t_avg.append(np.sum(Dprpprp_Phik_t[sp],axis=1)/float(it1-it0+1) )\n",
    "    #\n",
    "    # Dprpprp_Phik_t_avg calculates time dependent Dprpprp, and takes a time average\n",
    "    if exp_corr:\n",
    "       Dprpprp_Phik[sp] *= np.exp(-c0exp*(vprp[sp][0,:,0]**2./dPhi_v[sp]))           #apply exponential correction (but using: Phi_comb or Phi_tot)\n",
    "\n",
    "    Dprpprp_Phik[sp] *= charge[plotsp[sp]] / mass[plotsp[sp]]\n",
    "    # Matt's boardwork missed a factor of m in the definition of D (Eq.7 in Silvio's paper)\n",
    "\n",
    "    #\n",
    "    #--third: corresponding differential heating\n",
    "    #\n",
    "    Qprp_Phik.append(- Dprpprp_Phik[sp].reshape(1,vprp[sp].shape[1]) * dfdwprp[sp] )           #differential perpendicular heating associated to Phi_tot (in w_perp/v_th)\n",
    "    #^ has time as first dimension instead of second\n",
    "    Qprp_Phik_t.append(np.zeros([len(vprp[sp][0,:,0]),it1-it0+1]))\n",
    "    for ind in range(it0,it1+1):\n",
    "      Qprp_Phik_t[sp][:,ind-it0] = - Dprpprp_Phik_t[sp][:,ind-it0] * dfdwprp_t_interp[sp][ind-it0,:]\n",
    "    Qprp_Phik_t_avg.append(np.sum(Qprp_Phik_t[sp],axis=1)/float(it1-it0+1))\n",
    "\n",
    "    ### normalizations (made in w_perp/v_th space, then ported to k_perp*rho_th space)\n",
    "    #\n",
    "    #--Dprpprp vs wprp\n",
    "    #\n",
    "    #cst01 = 0.9 #1.0\n",
    "    #\n",
    "    i01 = np.where(vprp[sp][0,:,0] > 1.0 / (charge[plotsp[sp]]/np.sqrt(mass[plotsp[sp]]) * alphaPHI))[0][0]  #--match Dprpprp_phi with Dprpprp_sim (0.6?)  #1.0/alphaPHI\n",
    "    #\n",
    "    #normalisations to make things line up through a single w_perp - we don't care about the individual components\n",
    "\n",
    "    if apply_smoothing:\n",
    "      normD_phi01.append(cst01*Dprpprp[sp][:,i01] / Dprpprp_Phik[sp][i01] )#one normalisation for all t, or each t - plot this vs t to see if it changes much in time, taking the mean for now\n",
    "      normD_phi01_t_avg.append(cst01*Dprpprp[sp][:,i01] / Dprpprp_Phik_t_avg[sp][i01] )\n",
    "    else:\n",
    "      normD_phi01 = cst01*Dprpprp_smooth[sp][:,i01] / Dprpprp_Phik[sp][i01]\n",
    "      normD_phi01_t_avg = cst01*Dprpprp_smooth[sp][:,i01] / Dprpprp_Phik_t_avg[sp][i01]\n",
    "\n",
    "    # set minor ion normalisations to the same as for protons\n",
    "    #if plotsp[sp]!=0:\n",
    "    #  normD_phi01[sp] = 32728410.812698353\n",
    "    #  normD_phi01_t_avg[sp] = 31506759.908403452\n",
    "\n",
    "    #\n",
    "    Dprpprp_Phik[sp] *= np.mean(normD_phi01[sp])\n",
    "    Dprpprp_Phik_t_avg[sp] *= np.mean(normD_phi01_t_avg[sp])\n",
    "    #\n",
    "    print('\\n')\n",
    "    print('### betai0 = 0.3 ###')\n",
    "    print('species',sp)\n",
    "    print('* kappa0 values: ')\n",
    "    print('  effective kappa0_PHI = ',alphaPHI)\n",
    "    print('* D_perpperp normalizations: ')\n",
    "    print('  normD_Phi =',np.mean(normD_phi01[sp]))\n",
    "    print('  normD_Phi_t_avg =',np.mean(normD_phi01_t_avg[sp]))\n",
    "    #\n",
    "    #--Qprp vs wprp (apply same normalization as for Dprpprp)\n",
    "    Qprp_Phik[sp] *= np.mean(normD_phi01[sp])\n",
    "    Qprp_Phik_t_avg[sp] *= np.mean(normD_phi01_t_avg[sp])\n",
    "    #\n",
    "    #####\n",
    "    #\n",
    "    # << vs k_perp >>\n",
    "    #\n",
    "    # -> just interpolate dQperp/dwperp into k_perp*rho_th\n",
    "    #    (plus extra contribution due to the fact that we\n",
    "    #     need to compute dQperp/dlog(k_perp) and not dQperp/dk_perp)\n",
    "    #    [ normalization should already be consistent! ]\n",
    "    #\n",
    "    #--heating in k_perp from Phi spectrum\n",
    "    Qprp_k_phik.append(np.zeros((Qprp_Phik[sp].shape[0],kprp_phi_rho.shape[0])))\n",
    "\n",
    "    for t in np.arange(Qprp_Phik[sp].shape[0]):\n",
    "        Qprp_k_phik[sp][t] = np.interp( kprp_phi_rho, alphaPHI/vprp[sp][0,::-1,0], Qprp_Phik[sp][t,::-1] )\n",
    "    Qprp_k_phik[sp] *= (alphaPHI/kprp_phi_rho.reshape((1,kprp_phi_rho.shape[0])))\n",
    "\n",
    "    Qprp_k_phik_t_avg.append(np.interp( kprp_phi_rho, alphaPHI/vprp[sp][0,::-1,0], Qprp_Phik_t_avg[sp][::-1] ))\n",
    "    Qprp_k_phik_t_avg[sp] *= (alphaPHI/kprp_phi_rho)\n",
    "    Qprp_k_phik_t_avg[sp] /= np.log(10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac92b33-5cf9-4ad4-84f5-c1e36d2ec47e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b39d123-7abe-4172-b579-fe223f701fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f0228d-4ae1-43ff-a4b1-bdaca7fac927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--set ranges\n",
    "#\n",
    "# vs w_perp\n",
    "xr_min_w = 0.1\n",
    "xr_max_w = []\n",
    "yr_max_f_w = []\n",
    "yr_max_Q_w = []\n",
    "for sp in np.arange(nspecies):\n",
    "    xr_max_w.append(np.max(vprp[sp]) )\n",
    "    yr_max_f_w.append(1.025*np.max([np.max(f_vprp[sp]),np.max(f0_vprp[sp])]) )\n",
    "    yr_max_Q_w.append(1.1*np.max([np.max(Qprp_vprp[sp])]))\n",
    "xr_max_w = np.max(np.array(xr_max_w))#[plotsp]))\n",
    "yr_max_f_w = np.max(np.array(yr_max_f_w))#[plotsp]))\n",
    "yr_max_Q_w = np.max(np.array(xr_max_w))#[plotsp]))\n",
    "yr_min_f_w = 0.0\n",
    "yr_min_Q_w = -0.05 #1.05*np.min([np.min(Qprp_vprp),np.min(Qprp_vprp03)])\n",
    "yr_min_D_w = 0.9e-1 #8e-3#8e-1 #np.min(np.abs(Dprpprp_corrected))\n",
    "yr_max_D_w = 1.5e+1 #8e+1#8e+3 #np.max(np.abs(Dprpprp_corrected))\n",
    "#\n",
    "\n",
    "\n",
    "#--lines and fonts\n",
    "line_thick = 1.0 #1.25\n",
    "line_thick_aux = 0.75\n",
    "lnstyl = ['-','--','-.',':']\n",
    "ils_sim = 0 #linestyle index (simulation)\n",
    "ils_phi = 0 #linestyle index (dPhi)\n",
    "ils_phicomb = 0 #3\n",
    "ils_dB = 1  #linestyle index (dBpara)\n",
    "ils_dU = 2  #linestyle index (dUperp)\n",
    "clr_sim = 'k'\n",
    "clr_phi = 'darkorange'\n",
    "clr_phi_t_avg = 'r'\n",
    "clr_phicomb = 'darkorange' #'r'\n",
    "clr_dU = 'g'\n",
    "clr_dB = 'm'\n",
    "font_size = 9\n",
    "#fontweight_legend = 'light' #'normal' #--doesn't work..\n",
    "lbl_sim = r'$\\mathrm{simulation}$'\n",
    "lbl_phi = r'${\\rm theory}$ ($\\delta\\Phi_{\\rm tot}$)'\n",
    "lbl_phicomb = r'${\\rm theory}$ ($\\delta\\Phi_{\\rm tot}$)'\n",
    "#lbl_dU = r'${\\rm theory}$ (${\\rm only}$ $\\delta\\Phi_{\\rm mhd}$)'\n",
    "#lbl_dB = r'${\\rm theory}$ (${\\rm only}$ $\\delta\\Phi_{\\rm kin}$)'\n",
    "lbl_dU = r'${\\rm theory}$ ($\\delta\\Phi_{\\rm mhd}$)'\n",
    "lbl_dB = r'${\\rm theory}$ ($\\delta\\Phi_{\\rm kin}$)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee235a76-0b65-45fb-88d5-e3ad2ad6c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_max_f_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aac42d-9b97-46b9-a275-db7db327a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--set figure real width\n",
    "width = width_2columns\n",
    "#\n",
    "fig1 = plt.figure(figsize=(3,3))\n",
    "fig1.set_figheight((np.sqrt(5.0)-1.0)/2.0 * width*1.46)#1.35)#1.5)\n",
    "fig1.set_figwidth(width)\n",
    "grid = plt.GridSpec(3, 2, hspace=0.08, wspace=0.05)\n",
    "###--f vs w_perp - check\n",
    "#\n",
    "#ax1a = fig1.add_subplot(grid[0:1,1:2])\n",
    "# beta = 0.3\n",
    "ax2a = fig1.add_subplot(grid[0:1,0:1])\n",
    "for sp in np.arange(nspecies):\n",
    "    plt.plot(vprp[sp][0,:,0],f0_vprp[sp],':',linewidth=line_thick)\n",
    "    plt.plot(vprp[sp][0,:,0],f_vprp[sp][-1],linewidth=line_thick)\n",
    "#plt.plot(vprp,f_final,'k--',linewidth=line_thick)\n",
    "#ax2a.fill_between(vprp,f_final,f_init,facecolor='grey',alpha=0.25)\n",
    "plt.axvline(x=1.0,c='k',linestyle=':',linewidth=line_thick_aux,alpha=0.66)\n",
    "plt.axvline(x=vA01,c='k',linestyle='--',linewidth=line_thick_aux,alpha=0.66)\n",
    "plt.text(0.833*vA01,0.9*yr_max_f_w,r'$w_\\perp = v_{\\mathrm{A}0}$',va='top',ha='left',color='k',rotation=90,fontsize=font_size)\n",
    "plt.xlim(xr_min_w,xr_max_w)\n",
    "plt.ylim(yr_min_f_w,yr_max_f_w)\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel(r'$\\langle f(w_\\perp)\\rangle$',fontsize=font_size)\n",
    "plt.title(r'$\\beta_{\\mathrm{i}0}=0.3$',fontsize=font_size)\n",
    "ax2a.set_xticklabels('')\n",
    "#ax2a.set_yticklabels('')\n",
    "ax2a.tick_params(labelsize=font_size)\n",
    "plt.text(1.067*xr_min_w,1.0,r'$\\mathrm{(a)}$',va='center',ha='left',color='k',rotation=0,fontsize=font_size+1)#,weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a59820-96df-4bb7-8ba0-559bce4e445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(Dprpprp_t_avg[sp],axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a120d08d-4761-4e07-b406-508ff2e54614",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdDprpprp_vprp[sp].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db574cc-f5cb-4d6e-bc22-8ead9779d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2b = fig1.add_subplot(grid[1:2,0:1])\n",
    "#plt.plot(vprp,Dprpprp,c=clr_sim,ls=lnstyl[ils_sim],linewidth=line_thick,label=lbl_sim)\n",
    "#ax2b.fill_between(vprp,Dprpprp-c_pm_std*stdDprpprp_vprp,Dprpprp+c_pm_std*stdDprpprp_vprp,facecolor='grey',alpha=0.33)\n",
    "for sp in np.arange(nspecies):\n",
    "    plt.plot(vprp[sp][0,:,0],np.mean(Dprpprp_t_avg[sp],axis=0),c=clr_sim,ls=lnstyl[ils_sim],linewidth=line_thick,label=lbl_sim)\n",
    "    #ax2b.fill_between\n",
    "    plt.fill_between(vprp[sp][0,:,0],np.mean(Dprpprp_t_avg[sp],axis=0)-c_pm_std*stdDprpprp_vprp[sp],np.mean(Dprpprp_t_avg[sp],axis=0)+c_pm_std*stdDprpprp_vprp[sp],facecolor='grey',alpha=0.33)\n",
    "    #plt.plot(vprp,Dprpprp_Phik,c=clr_phi,ls=lnstyl[ils_phi],linewidth=line_thick,label=lbl_phi)\n",
    "    ##plt.plot(vprp,Dprpprp_Phik_comb,c=clr_phicomb,ls=lnstyl[ils_phicomb],linewidth=line_thick,label=lbl_phicomb)\n",
    "    #plt.plot(vprp,Dprpprp_Uk,c=clr_dU,ls=lnstyl[ils_dU],linewidth=line_thick,label=lbl_dU)\n",
    "    #plt.plot(vprp,Dprpprp_Bzk,c=clr_dB,ls=lnstyl[ils_dB],linewidth=line_thick,label=lbl_dB)\n",
    "    plt.plot(vprp[sp][0,:,0],Dprpprp_Phik_t_avg[sp],c=clr_phi,ls=lnstyl[ils_phi],linewidth=line_thick,label=lbl_phi)\n",
    "    #plt.plot(vprp,Dprpprp_Uk_t_avg,c=clr_dU,ls=lnstyl[ils_dU],linewidth=line_thick,label=lbl_dU)\n",
    "    #plt.plot(vprp,Dprpprp_Bzk_t_avg,c=clr_dB,ls=lnstyl[ils_dB],linewidth=line_thick,label=lbl_dB)\n",
    "plt.axvline(x=1.0,c='k',linestyle=':',linewidth=line_thick_aux,alpha=0.66)\n",
    "plt.axvline(x=vA01,c='k',linestyle='--',linewidth=line_thick_aux,alpha=0.66)\n",
    "plt.xlim(xr_min_w,xr_max_w)\n",
    "plt.ylim(yr_min_D_w,yr_max_D_w)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(r'$Q_\\mathrm{inj}^{-1}v_{\\mathrm{th,i}0}^{-2}\\langle D_{\\perp\\perp}^E\\rangle$',fontsize=font_size)\n",
    "ax2b.set_xticklabels('')\n",
    "#ax2b.set_yticklabels('')\n",
    "ax2b.tick_params(labelsize=font_size)\n",
    "#plt.legend(loc='best',markerscale=0.5,frameon=False,bbox_to_anchor=(0.55, 0.425),fontsize=font_size,ncol=1,handlelength=2.5)#,fontweight=fontweight_legend)\n",
    "plt.legend(loc='best',markerscale=0.5,frameon=False,bbox_to_anchor=(0.6, 0.425),fontsize=font_size,ncol=1,handlelength=1.66)#,fontweight=fontweight_legend)\n",
    "#plt.legend(loc='best',markerscale=0.5,frameon=False,bbox_to_anchor=(0.56, 0.41),fontsize=font_size,ncol=1,handlelength=2.5)#,fontweight=fontweight_legend)\n",
    "#plt.text(1.067*xr_min_w,0.9*yr_max_D_w,r'$\\mathrm{(b)}$',va='top',ha='left',color='k',rotation=0,fontsize=font_size+1)#,weight='bold')\n",
    "plt.text(1.067*xr_min_w,0.9*yr_max_D_w,r'$\\alpha_{\\phi}$= '+'%.2f' %alphaPHI,va='top',ha='left',color='k',rotation=0,fontsize=font_size+4)#,weight='bold')\n",
    "plt.text(1.067*xr_min_w,0.7*yr_max_D_w,r'$c0exp= $'+'%.3f' %c0exp,va='top',ha='left',color='k',rotation=0,fontsize=font_size+4)#,weight='bold')\n",
    "#plt.savefig(\"../figures/\"+name+\"/SH_fit_scan/50-76/alp\"+str(alphaPHI)+\"c0exp\"+str(c0exp)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd52392c-3b9b-42e3-a69a-cf8dd50173f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6efb11-c255-4622-9c98-02705459e5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a parameter scan over c0exp and alphaPHI, and save plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02b52ae-0192-4ee8-b6d8-347fc695f0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c0expscan = np.arange(0.03,0.132,0.002)\n",
    "alphaPHIscan = np.arange(0.65,1.37,0.02)\n",
    "\n",
    "\n",
    "c0exp = 0.05 #beta=0.3 0.05 #0.05\n",
    "alphaPHI = 1.25#1.1 #1.25 #1.2\n",
    "cst01 = 0.9 #0.9   #1.05\n",
    "if cooling_corr:\n",
    "    interv = interv+\"coolcorr/\"\n",
    "\n",
    "#outsp = \"p/\"\n",
    "#outsp = \"he/\"\n",
    "outsp = \"o5/\"\n",
    "\n",
    "for c0exp in c0expscan:\n",
    "    for alphaPHI in alphaPHIscan:\n",
    "        dPhi_v = [] #Phi vs vprp - different species may have different vprp scales\n",
    "        dPhi_v_t = []\n",
    "        Dprpprp_Phik = []\n",
    "        Dprpprp_Phik_t = []\n",
    "        Dprpprp_Phik_t_avg = []\n",
    "        Qprp_Phik = []\n",
    "        Qprp_Phik_t = []\n",
    "        Qprp_Phik_t_avg = []\n",
    "        normD_phi01 = []\n",
    "        normD_phi01_t_avg = []\n",
    "        Qprp_k_phik = []\n",
    "        Qprp_k_phik_t_avg = []\n",
    "        for sp in np.arange(nspecies):\n",
    "            # calculate k phi/beta and interpolate and convert to v-space\n",
    "            dPhi_k = np.sqrt(kprp_phi_rho*Phikprp/np.sqrt(betai0)) # attention! spectra were originally computed in kprp*di units!\n",
    "            dPhi_v.append(np.interp(vprp[sp][0,:,0], charge[plotsp[sp]]/np.sqrt(mass[plotsp[sp]]) * alphaPHI/kprp_phi_rho[::-1], dPhi_k[::-1]))\n",
    "            dPhi_v[sp] /= betai0 #thermal units\n",
    "            #\n",
    "            dPhi_k_t = np.zeros([len(kprp_phi_rho),it1-it0+1])\n",
    "            dPhi_v_t.append(np.zeros([len(vprp[sp][0,:,0]),it1-it0+1]))\n",
    "            for ind in range(it0,it1+1):\n",
    "              dPhi_k_t[:,ind-it0] = np.sqrt(kprp_phi_rho[:]*Phikprp_t[:,ind-it0]/np.sqrt(betai0)) # attention! spectra were originally computed in kprp*di units!\n",
    "              dPhi_v_t[sp][:,ind-it0] = dPhi_v_t[sp][:,ind-it0] = np.interp(vprp[sp][0,:,0], charge[plotsp[sp]]/np.sqrt(mass[plotsp[sp]]) * alphaPHI/kprp_phi_rho[::-1], dPhi_k_t[::-1,ind-it0])\n",
    "              dPhi_v_t[sp][:,ind-it0] = dPhi_v_t[sp][:,ind-it0] / betai0\n",
    "            #\n",
    "            #--second: corresponding diffusion coefficients\n",
    "            #\n",
    "            # multiply the potential by the charge of the species of interest\n",
    "            dPhi_v[sp] *= charge[plotsp[sp]]\n",
    "            dPhi_v_t[sp] *= charge[plotsp[sp]]\n",
    "            #\n",
    "            Dprpprp_Phik.append((dPhi_v[sp]**3.) / (vprp[sp][0,:,0]**2.) )           #diffusion coefficient associated to Phi_tot (in w_perp/v_th)\n",
    "            # We want dPhi_v - the fully combined phi\n",
    "            # Dprpprp_Phik calculates using time-averaged phi\n",
    "            #\n",
    "            Dprpprp_Phik_t.append(np.zeros([len(vprp[sp][0,:,0]),it1-it0+1]) )\n",
    "            for ind in range(it0,it1+1):\n",
    "              Dprpprp_Phik_t[sp][:,ind-it0] = (dPhi_v_t[sp][:,ind-it0]**3.) / (vprp[sp][0,:,0]**2.)\n",
    "              if exp_corr:\n",
    "                 Dprpprp_Phik_t[sp][:,ind-it0] = Dprpprp_Phik_t[sp][:,ind-it0]*np.exp(-c0exp*(vprp[sp][0,:,0]**2./dPhi_v_t[sp][:,ind-it0]))\n",
    "            Dprpprp_Phik_t[sp] *= charge[plotsp[sp]] / mass[plotsp[sp]]\n",
    "            Dprpprp_Phik_t_avg.append(np.sum(Dprpprp_Phik_t[sp],axis=1)/float(it1-it0+1) )\n",
    "            #\n",
    "            # Dprpprp_Phik_t_avg calculates time dependent Dprpprp, and takes a time average\n",
    "            if exp_corr:\n",
    "               Dprpprp_Phik[sp] *= np.exp(-c0exp*(vprp[sp][0,:,0]**2./dPhi_v[sp]))           #apply exponential correction (but using: Phi_comb or Phi_tot)\n",
    "            #\n",
    "\n",
    "            Dprpprp_Phik[sp] *= charge[plotsp[sp]] / mass[plotsp[sp]]\n",
    "            # Matt's boardwork missed a factor of m in the definition of D (Eq.7 in Silvio's paper)\n",
    "            #--third: corresponding differential heating\n",
    "            #\n",
    "            Qprp_Phik.append(- Dprpprp_Phik[sp].reshape(1,vprp[sp].shape[1]) * dfdwprp[sp] )           #differential perpendicular heating associated to Phi_tot (in w_perp/v_th)\n",
    "            #^ has time as first dimension instead of second\n",
    "            Qprp_Phik_t.append(np.zeros([len(vprp[sp][0,:,0]),it1-it0+1]))\n",
    "            for ind in range(it0,it1+1):\n",
    "              Qprp_Phik_t[sp][:,ind-it0] = - Dprpprp_Phik_t[sp][:,ind-it0] * dfdwprp_t_interp[sp][ind-it0,:]\n",
    "            Qprp_Phik_t_avg.append(np.sum(Qprp_Phik_t[sp],axis=1)/float(it1-it0+1))\n",
    "\n",
    "            ### normalizations (made in w_perp/v_th space, then ported to k_perp*rho_th space)\n",
    "            #\n",
    "            #--Dprpprp vs wprp\n",
    "            #\n",
    "            #cst01 = 0.9 #1.0\n",
    "            #\n",
    "            i01 = np.where(vprp[sp][0,:,0] > 1.0 / (charge[plotsp[sp]]/np.sqrt(mass[plotsp[sp]]) /alphaPHI))[0][0]  #--match Dprpprp_phi with Dprpprp_sim (0.6?)  #1.0/alphaPHI\n",
    "            #\n",
    "            #normalisations to make things line up through a single w_perp - we don't care about the individual components\n",
    "\n",
    "            if apply_smoothing:\n",
    "              normD_phi01.append(cst01*Dprpprp[sp][:,i01] / Dprpprp_Phik[sp][i01] )#one normalisation for all t, or each t - plot this vs t to see if it changes much in time, taking the mean for now\n",
    "              normD_phi01_t_avg.append(cst01*Dprpprp[sp][:,i01] / Dprpprp_Phik_t_avg[sp][i01] )\n",
    "            else:\n",
    "              normD_phi01 = cst01*Dprpprp_smooth[sp][:,i01] / Dprpprp_Phik[sp][i01]\n",
    "              normD_phi01_t_avg = cst01*Dprpprp_smooth[sp][:,i01] / Dprpprp_Phik_t_avg[sp][i01]\n",
    "\n",
    "            #\n",
    "            Dprpprp_Phik[sp] *= np.mean(normD_phi01[sp])\n",
    "            Dprpprp_Phik_t_avg[sp] *= np.mean(normD_phi01_t_avg[sp])\n",
    "            #\n",
    "            print('\\n')\n",
    "            print('### betai0 = 0.3 ###')\n",
    "            print('species',sp)\n",
    "            print('* kappa0 values: ')\n",
    "            print('  effective kappa0_PHI = ',alphaPHI)\n",
    "            print('* D_perpperp normalizations: ')\n",
    "            print('  normD_Phi =',np.mean(normD_phi01[sp]))\n",
    "            print('  normD_Phi_t_avg =',np.mean(normD_phi01_t_avg[sp]))\n",
    "            #\n",
    "            #--Qprp vs wprp (apply same normalization as for Dprpprp)\n",
    "            Qprp_Phik[sp] *= np.mean(normD_phi01[sp])\n",
    "            Qprp_Phik_t_avg[sp] *= np.mean(normD_phi01_t_avg[sp])\n",
    "            #\n",
    "            #####\n",
    "            #\n",
    "            # << vs k_perp >>\n",
    "            #\n",
    "            # -> just interpolate dQperp/dwperp into k_perp*rho_th\n",
    "            #    (plus extra contribution due to the fact that we\n",
    "            #     need to compute dQperp/dlog(k_perp) and not dQperp/dk_perp)\n",
    "            #    [ normalization should already be consistent! ]\n",
    "            #\n",
    "            #--heating in k_perp from Phi spectrum\n",
    "            Qprp_k_phik.append(np.zeros((Qprp_Phik[sp].shape[0],kprp_phi_rho.shape[0])))\n",
    "\n",
    "            for t in np.arange(Qprp_Phik[sp].shape[0]):\n",
    "                Qprp_k_phik[sp][t] = np.interp( kprp_phi_rho, alphaPHI/vprp[sp][0,::-1,0], Qprp_Phik[sp][t,::-1] )\n",
    "            Qprp_k_phik[sp] *= (alphaPHI/kprp_phi_rho.reshape((1,kprp_phi_rho.shape[0])))\n",
    "\n",
    "            Qprp_k_phik_t_avg.append(np.interp( kprp_phi_rho, alphaPHI/vprp[sp][0,::-1,0], Qprp_Phik_t_avg[sp][::-1] ))\n",
    "            Qprp_k_phik_t_avg[sp] *= (alphaPHI/kprp_phi_rho)\n",
    "            Qprp_k_phik_t_avg[sp] /= np.log(10.)\n",
    "\n",
    "        xr_max_w = []\n",
    "        yr_max_f_w = []\n",
    "        yr_max_Q_w = []\n",
    "        for sp in np.arange(nspecies):\n",
    "            xr_max_w.append(np.max(vprp[sp]) )\n",
    "            yr_max_f_w.append(1.025*np.max([np.max(f_vprp[sp]),np.max(f0_vprp[sp])]) )\n",
    "            yr_max_Q_w.append(1.1*np.max([np.max(Qprp_vprp[sp])]))\n",
    "        xr_max_w = np.max(np.array(xr_max_w))#[plotsp]))\n",
    "        yr_max_f_w = np.max(np.array(yr_max_f_w))#[plotsp]))\n",
    "        yr_max_Q_w = np.max(np.array(xr_max_w))#[plotsp]))\n",
    "\n",
    "        fig2 = plt.figure()\n",
    "        ax3b = fig2.add_subplot(111)\n",
    "        #plt.plot(vprp,Dprpprp,c=clr_sim,ls=lnstyl[ils_sim],linewidth=line_thick,label=lbl_sim)\n",
    "        #ax2b.fill_between(vprp,Dprpprp-c_pm_std*stdDprpprp_vprp,Dprpprp+c_pm_std*stdDprpprp_vprp,facecolor='grey',alpha=0.33)\n",
    "        for sp in np.arange(nspecies):\n",
    "            plt.plot(vprp[sp][0,:,0],np.mean(Dprpprp_t_avg[sp],axis=0),c=clr_sim,ls=lnstyl[ils_sim],linewidth=line_thick,label=lbl_sim)\n",
    "            #ax2b.fill_between\n",
    "            plt.fill_between(vprp[sp][0,:,0],np.mean(Dprpprp_t_avg[sp],axis=0)-c_pm_std*stdDprpprp_vprp[sp],np.mean(Dprpprp_t_avg[sp],axis=0)+c_pm_std*stdDprpprp_vprp[sp],facecolor='grey',alpha=0.33)\n",
    "            #plt.plot(vprp,Dprpprp_Phik,c=clr_phi,ls=lnstyl[ils_phi],linewidth=line_thick,label=lbl_phi)\n",
    "            ##plt.plot(vprp,Dprpprp_Phik_comb,c=clr_phicomb,ls=lnstyl[ils_phicomb],linewidth=line_thick,label=lbl_phicomb)\n",
    "            #plt.plot(vprp,Dprpprp_Uk,c=clr_dU,ls=lnstyl[ils_dU],linewidth=line_thick,label=lbl_dU)\n",
    "            #plt.plot(vprp,Dprpprp_Bzk,c=clr_dB,ls=lnstyl[ils_dB],linewidth=line_thick,label=lbl_dB)\n",
    "            plt.plot(vprp[sp][0,:,0],Dprpprp_Phik_t_avg[sp],c=clr_phi,ls=lnstyl[ils_phi],linewidth=line_thick,label=lbl_phi)\n",
    "            #plt.plot(vprp,Dprpprp_Uk_t_avg,c=clr_dU,ls=lnstyl[ils_dU],linewidth=line_thick,label=lbl_dU)\n",
    "            #plt.plot(vprp,Dprpprp_Bzk_t_avg,c=clr_dB,ls=lnstyl[ils_dB],linewidth=line_thick,label=lbl_dB)\n",
    "        plt.axvline(x=1.0,c='k',linestyle=':',linewidth=line_thick_aux,alpha=0.66)\n",
    "        plt.axvline(x=vA01,c='k',linestyle='--',linewidth=line_thick_aux,alpha=0.66)\n",
    "        plt.xlim(xr_min_w,xr_max_w)\n",
    "        plt.ylim(yr_min_D_w,yr_max_D_w)\n",
    "        plt.xscale(\"log\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.ylabel(r'$Q_\\mathrm{inj}^{-1}v_{\\mathrm{th,i}0}^{-2}\\langle D_{\\perp\\perp}^E\\rangle$',fontsize=font_size)\n",
    "        ax3b.set_xticklabels('')\n",
    "        #ax2b.set_yticklabels('')\n",
    "        ax3b.tick_params(labelsize=font_size)\n",
    "        #plt.legend(loc='best',markerscale=0.5,frameon=False,bbox_to_anchor=(0.55, 0.425),fontsize=font_size,ncol=1,handlelength=2.5)#,fontweight=fontweight_legend)\n",
    "        plt.legend(loc='best',markerscale=0.5,frameon=False,bbox_to_anchor=(0.6, 0.425),fontsize=font_size,ncol=1,handlelength=1.66)#,fontweight=fontweight_legend)\n",
    "        #plt.legend(loc='best',markerscale=0.5,frameon=False,bbox_to_anchor=(0.56, 0.41),fontsize=font_size,ncol=1,handlelength=2.5)#,fontweight=fontweight_legend)\n",
    "        plt.text(1.067*xr_min_w,0.9*yr_max_D_w,r'$\\alpha_{\\phi}$= '+'%.2f' %alphaPHI,va='top',ha='left',color='k',rotation=0,fontsize=font_size+4)#,weight='bold')\n",
    "        plt.text(1.067*xr_min_w,0.7*yr_max_D_w,r'$c0exp= $'+'%.3f' %c0exp,va='top',ha='left',color='k',rotation=0,fontsize=font_size+4)#,weight='bold')\n",
    "        print(\"../figures/\"+name+\"/SH_fit_scan/\"+outsp+interv+\"alp\"+'%.2f' %alphaPHI+\"c0exp\"+'%.3f' %c0exp+\".png\")\n",
    "        plt.savefig(\"../figures/\"+name+\"/SH_fit_scan/\"+outsp+interv+\"alp\"+'%.2f' %alphaPHI+\"c0exp\"+'%.3f' %c0exp+\".png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c992a0a-4f2c-4686-8ace-54382c12b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(alphaPHI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5ca68c-d688-4020-8434-190adb6d84f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c0expscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa40a5f-210e-4c37-8215-cf2c13997105",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphaPHIscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e7915e-dfbc-4498-83eb-e1b55b3f15f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(0.045)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24564cfd-af07-43af-969e-981238a3c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "'%.2f' %c0expscan[2]+\"hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f03d90-a1b1-454f-a110-4c33349a2b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ae2e50-405b-448a-83b3-d1bf6297e6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a70d079-044d-4713-8929-e027766ceae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vprp[sp][0,:,0],Dprpprp_Phik_t_avg[sp],c=clr_phi,ls=lnstyl[ils_phi],linewidth=line_thick,label=lbl_phi)\n",
    "plt.ylim(yr_min_D_w,yr_max_D_w)\n",
    "plt.xlim(xr_min_w,xr_max_w)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b27403f-7d73-4560-a6c1-45d2f2b676d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.fill_between(vprp[sp][0,:,0],np.mean(Dprpprp_t_avg[sp],axis=0)-c_pm_std*stdDprpprp_vprp[sp],np.mean(Dprpprp_t_avg[sp],axis=0)+c_pm_std*stdDprpprp_vprp[sp],facecolor='grey',alpha=0.33)\n",
    "plt.xlim(xr_min_w,xr_max_w)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6091e7-24c0-43a4-9bf2-b1b309b4a772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae601ae-141f-41c1-bfb0-827daa76ec0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c2485-90aa-4e9d-999f-b26e6d7c5e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dprpprp_Phik_t_avg[sp].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c49df1-5a00-43d4-b87e-955ce6d8e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dprpprp_Phik_t_avg.append(np.sum(Dprpprp_Phik_t,axis=1)/float(it1-it0+1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a358049b-22bb-4385-9451-c7ac04020f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.sum(Dprpprp_Phik_t[sp],axis=1)/float(it1-it0+1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf88111-0130-4ccd-9e8d-fb09a18eb8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qprp_Phik_t[sp].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97513247-6ce8-4116-ae4f-aeb452bbbf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qprp_Phik[sp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9046f0c-edba-4595-8ae2-d4a11419b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "vprp[sp][0,:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa137d2-3252-438b-9d15-7776ac84691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwdfwprp_t_interp[sp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63679aa8-7d87-4ef8-9758-45f2812c9b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cst01*Dprpprp[sp][:,i01] / Dprpprp_Phik[i01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a321f3-aca9-4a1f-aca5-1466e0d57c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "i01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98abd319-0e37-4d70-9e01-e6a67c2b3326",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Dprpprp_Phik[sp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f837a47b-dc73-4cdc-beaa-11d713c48911",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dprpprp_Phik_t_avg[sp].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f217d325-946d-4d68-bef3-adca21e67f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.interp( kprp_phi_rho, alphaPHI/vprp[0][0,::-1,0], Qprp_Phik_t_avg[0][::-1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe8950a-c419-4fa5-aa36-6911aa397f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "kprp_phi_rho.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6529208-2418-480e-a372-bdcbebe91bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "(alphaPHI/vprp[0][0,::-1,0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d68d88a-9d78-40aa-9f48-dfcd8e7dc8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Qprp_Phik_t_avg[0][::-1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486ba1bd-f55a-4631-ba61-521c24569281",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qprp_Phik_t[sp].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f9b8c2-9c93-4baa-821e-15fd420ac173",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(Qprp_Phik_t[sp],axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625b3544-c79e-4960-82d4-e612dd7d4026",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qprp_Phik_t_avg[sp].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d3992-c9c7-480f-81c9-9e901ad90070",
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.sum(Qprp_Phik_t,axis=1)/float(it1-it0+1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb9499c-aa78-46ff-beb1-c7f2c2551889",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608ace74-6c2d-4fe3-966e-3afc658653cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc6bbf0-05fe-4426-b851-e76573bfc3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b69712-3c7e-4a82-8b79-25562bbaff9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf602b1-d0af-4c43-ad09-9e0f20ec83a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.arange(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf3d98-7dbd-40b0-b260-6be8b43ff576",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a5a13-1ccf-4193-a41a-a9abe0c9b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "del a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab56b21-fb3c-48dd-84f4-594d493747d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eccb1cf-de1e-4923-a2a8-9faf3073a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d69dc0-840b-4ef1-afe5-7d28ad18be98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
