{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f252782-0cef-4d73-be6b-dd0d20872e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import math\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pegasus_read as pegr\n",
    "from matplotlib.pyplot import *\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from get_kparofkprp import get_kparofkprp\n",
    "import xarray\n",
    "import scipy.io\n",
    "import h5py\n",
    "import bottleneck as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e75d3-3e95-4b56-8edf-80b4f070a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'b_b3_sim1'\n",
    "nspecies = 1#7\n",
    "plotsp = [1] #[0,2,1]\n",
    "#charge = [1,1,1]\n",
    "#mass = [1,1,1]\n",
    "charge = [1,5,2]\n",
    "mass = [1,16,4]\n",
    "\n",
    "\n",
    "#output range  phi   ()\n",
    "it0 = 50#25#0 #25 #65\n",
    "it1 = 76#50#76 #50 #144\n",
    "#output range f\n",
    "itf0 = 0#146#73#146#73#0\n",
    "itf1 = 222#146#222#222\n",
    "#25 and 73, 50 and 146\n",
    "#Try using a later range to match better (and use what constants Silvio has for each of his runs)\n",
    "interv = \"50-76/\"\n",
    "#interv = \"25-50/\"\n",
    "#interv = \"25-76/\"\n",
    "\n",
    "# window avg of f\n",
    "rolling_window = 15#15\n",
    "\n",
    "#cooling corrections\n",
    "it0corr = 0\n",
    "it1corr = 23 #25\n",
    "cooling_corr = False # shouldnt affect SH here? check... #False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c3bb4-73fc-4447-9e50-bb3ad61f791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box parameters (beta = 0.3)\n",
    "aspct = 6\n",
    "lprp = 48.1802/(2.0*np.pi)                # in (2*pi*d_i) units   divide by 2pi\n",
    "lprl = lprp*aspct         # in (2*pi*d_i) units\n",
    "Lperp = 2.0*np.pi*lprp    # in d_i units\n",
    "Lpara = 2.0*np.pi*lprl    # in d_i units\n",
    "N_perp = 280  #ncells in perp direction\n",
    "N_para = N_perp*aspct     # assuming isotropic resolution\n",
    "kperpdi0 = 1./lprp        # minimum k_perp ( = 2*pi / Lperp)\n",
    "kparadi0 = 1./lprl        # minimum k_para ( = 2*pi / Lpara)\n",
    "betai0 = 0.3 #1./9.            # ion plasma beta\n",
    "tau0 = 1.                 # temperature ratio (Te/Ti)\n",
    "beta0 = (1.+tau0)*betai0  # total plasma beta\n",
    "\n",
    "#number of processors used   (check if he computes D locally on each proc or not)\n",
    "# seems the f read in is a sum over all processors (not local)\n",
    "n_proc = 350*56\n",
    "\n",
    "#k_perp shells\n",
    "nkshells = 198#200\n",
    "\n",
    "#binning type\n",
    "bin_type = \"linear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3025af0-b0b1-4b87-a119-a4e6aebe211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaussian filter\n",
    "apply_smoothing = True #False\n",
    "smooth_method = 'gaussian'\n",
    "filter_passes = 1 #20 #10\n",
    "#gaussian filter\n",
    "sigma_smoothing = 0.5 #0.33\n",
    "#Savitzky-Golay filter\n",
    "window_size = 5\n",
    "polyn_order = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d0eea7-3620-4f48-8f1e-40328886f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy gradient: derivative order at edges\n",
    "edge_grad_order = 2\n",
    "\n",
    "#nomalization methods\n",
    "same_norm_all = False #True #False\n",
    "\n",
    "#exponential correction in diffusion coeff\n",
    "exp_corr = True #False\n",
    "c0exp = 0.09 #beta=0.3 0.05 #0.05\n",
    "\n",
    "#shaded area: +/- c_pm_std*sigma (sigma = standard dev.)\n",
    "c_pm_std = 1.0 #0.5\n",
    "\n",
    "#--parameters for final plot  k_perp w_perp / \\Omega = kappa  (translation from k_perp to w_perp for a given particle)\n",
    "kappaU01 = 1.1 #beta = 0.3 1.25 #1.2\n",
    "kappaB01 = 1.1 #1.25 #1.2\n",
    "kappaPHI01 = 1.1 #1.25 #1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd0a7e5-5de0-4ecb-881f-bbfa1c9654d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#complement kpara*dBperp. dont know what this is\n",
    "dBprp_complement = False #True #False\n",
    "dtheta_dir = '1p5deg/'\n",
    "path_strct_fnct = '../strct_fnct/'+dtheta_dir\n",
    "m_order = '2'\n",
    "cbprp_sign = +1.\n",
    "\n",
    "#2*pi coefficient            k_perp lambda =1 or k_perp lambda = 2pi. Chose the former\n",
    "TWOPIcoeff = False #True\n",
    "\n",
    "#non-linear corrections\n",
    "NLcorrections = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f18e26-6a1c-4482-9652-0ffde793883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure format\n",
    "output_figure = False #True #False\n",
    "fig_frmt = \".pdf\"#\".png\"#\".pdf\"\n",
    "width_2columns = 512.11743/72.2\n",
    "width_1column = 245.26653/72.2\n",
    "\n",
    "#verbosity\n",
    "verb_diag = False\n",
    "verb_read = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4886ad-37d3-4e01-b9fc-b5fe3292bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--rho_i units and KAW eigenvector normalization for density spectrum\n",
    "kperprhoi0 = np.sqrt(betai0)*kperpdi0\n",
    "kpararhoi0 = np.sqrt(betai0)*kparadi0\n",
    "normKAW = betai0*(1.+betai0)*(1. + 1./(1. + 1./betai0))\n",
    "#--\n",
    "#--alfven speed (v_th units)\n",
    "vA01 = np.sqrt(1./betai0)\n",
    "#--d_i scale (rho_th units)\n",
    "kdi01 = np.sqrt(betai0)\n",
    "\n",
    "#--heating normalization\n",
    "Qnormalization01 = 0.75 #0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f81794-6aa9-4c43-adc2-72368f6195f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths\n",
    "problem = \"minor_turb\"\n",
    "path_save = \"../figures/\"\n",
    "base = \"../saved-analysis/spectrum_dat/\"+name+\"/\"+name\n",
    "#path_read_lev = \"../fig_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e47b80-9c98-4911-bb52-beba46ca9c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot parameters\n",
    "\n",
    "#latex fonts\n",
    "font = 9\n",
    "mpl.rc('text', usetex=True)\n",
    "mpl.rc('font', family = 'serif')\n",
    "mpl.rcParams['xtick.labelsize']=font-1\n",
    "mpl.rcParams['ytick.labelsize']=font-1\n",
    "#mpl.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath}\"]\n",
    "mpl.rcParams['contour.negative_linestyle'] = 'solid'\n",
    "plt.rcParams[\"font.weight\"] = \"normal\"\n",
    "plt.rcParams['xtick.top']=True\n",
    "plt.rcParams['ytick.right']=True\n",
    "\n",
    "\n",
    "#Hawley colormap\n",
    "bit_rgb = np.linspace(0,1,256)\n",
    "colors = [(0,0,127), (0,3,255), (0,255,255), (128,128,128), (255,255,0),(255,0,0),(135,0,0)]\n",
    "positions = [0.0,0.166667,0.333333,0.5,0.666667,0.833333,1]\n",
    "for iii in range(len(colors)):\n",
    " colors[iii] = (bit_rgb[colors[iii][0]],\n",
    "                bit_rgb[colors[iii][1]],\n",
    "                bit_rgb[colors[iii][2]])\n",
    "\n",
    "cdict = {'red':[], 'green':[], 'blue':[]}\n",
    "for pos, color in zip(positions, colors):\n",
    " cdict['red'].append((pos, color[0], color[0]))\n",
    " cdict['green'].append((pos, color[1], color[1]))\n",
    " cdict['blue'].append((pos, color[2], color[2]))\n",
    "\n",
    "cmap = mpl.colors.LinearSegmentedColormap('my_colormap',cdict,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffc51e2-ce2b-4a31-b2b0-0f9d9bead860",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n [ reading initial condition ]\")\n",
    "vdf0, time, vprp0, vprl0 = pegr.readmat_vdf(name,0,1,nspecies,plotsp,edv=False,grid=True,verbose=True)\n",
    "\n",
    "#first normalization by number of processors\n",
    "for i in np.arange(nspecies):\n",
    "    vdf0[i] = vdf0[i][0,:,:] / float(n_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e1d644-a352-4214-877b-ea7aa61085c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cooling_corr:\n",
    "    #correcting for numerical cooling\n",
    "    print(\"\\n [ calculate cooling correction (vs w_perp) ]\")\n",
    "    # if not apply_smoothing - store in edotv_prp_smooth arrays etc instead\n",
    "    # can just do everything in one line instead\n",
    "    # calculate here to not overload storage once main vdfs are read in\n",
    "    blank1, blank2, edotv_prp_, edotv_prl_, blank3, blank4 = pegr.readmat_vdf(name,it0corr,it1corr+1,nspecies,plotsp,edv=True,grid=True,verbose=verb_read)\n",
    "\n",
    "    for sp in np.arange(nspecies):\n",
    "        edotv_prl_[sp] = edotv_prl_[sp] / float(n_proc)\n",
    "        edotv_prp_[sp] = edotv_prp_[sp] / float(n_proc)\n",
    "\n",
    "        if apply_smoothing:\n",
    "            for ifilt in range(filter_passes):\n",
    "              edotv_prp_[sp] = gaussian_filter(edotv_prp_[sp],sigma=sigma_smoothing,axes=(1,2))\n",
    "              edotv_prl_[sp] = gaussian_filter(edotv_prl_[sp],sigma=sigma_smoothing,axes=(1,2))\n",
    "\n",
    "    edotv_prl_corr = []\n",
    "    edotv_prp_corr = []\n",
    "    edotv_prl_smooth_corr = []\n",
    "    edotv_prp_smooth_corr = []\n",
    "\n",
    "    for sp in np.arange(nspecies):\n",
    "        edotv_prl_corr.append(np.mean(edotv_prl_[sp],axis=0,keepdims=True))\n",
    "        edotv_prp_corr.append(np.mean(edotv_prp_[sp],axis=0,keepdims=True))\n",
    "        if (not apply_smoothing):\n",
    "            edotv_prl_smooth_corr.append(gaussian_filter(edotv_prl_[sp],sigma=sigma_smoothing,axes=(1,2)))\n",
    "            edotv_prp_smooth_corr.append(gaussian_filter(edotv_prp_[sp],sigma=sigma_smoothing,axes=(1,2)))\n",
    "            for ifilt in range(filter_passes-1):\n",
    "                edotv_prl_smooth_corr[sp] = gaussian_filter(edotv_prl_smooth_corr[sp],sigma=sigma_smoothing,axes=(1,2))\n",
    "                edotv_prp_smooth_corr[sp] = gaussian_filter(edotv_prp_smooth_corr[sp],sigma=sigma_smoothing,axes=(1,2))\n",
    "            edotv_prl_smooth_corr[sp] = np.mean(edotv_prl_smooth_corr[sp],axis=0,keepdims=True)\n",
    "            edotv_prp_smooth_corr[sp] = np.mean(edotv_prp_smooth_corr[sp],axis=0,keepdims=True)\n",
    "\n",
    "    del blank1, blank2, edotv_prp_, edotv_prl_, blank3, blank4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba14b1-38e6-4efa-9f78-f8a928c8ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HEATING VS W_PERP (beta = 0.3)\n",
    "#\n",
    "# -> reading simulation data, time averaging, and cooling corrections\n",
    "# -> also: reading spectra of fluctuations, reducing to k_perp spectra, and time averaging\n",
    "#\n",
    "print(\"\\n ### HEATING VS W_PERP ###\")\n",
    "\n",
    "for sp in np.arange(nspecies):\n",
    "\n",
    "    # read in VDF, edotv file saved using jono's scripts\n",
    "    vdf_, time, edotv_prp_, edotv_prl_, vprp, vprl = pegr.readmat_vdf(name,itf0,itf1+1,1,plotsp[sp],edv=True,grid=True,verbose=verb_read)\n",
    "\n",
    "    time = time[itf0:itf1+1,:]\n",
    "\n",
    "    vdf_avg = []\n",
    "    edotv_prp_t = []\n",
    "    edotv_prl_t = []\n",
    "    edotv_prp_avg = []\n",
    "    edotv_prl_avg = []\n",
    "    dfdwprp_t = []\n",
    "    dfdwprp_avg = []\n",
    "\n",
    "    if verb_diag:\n",
    "    print(\"\\n\")\n",
    "    print(\"#########################################################\")\n",
    "    print(\"### v-space analysis: distribution function & heating ###\")\n",
    "    print(\"#########################################################\")\n",
    "    print(\"species\",plotsp[sp])\n",
    "\n",
    "    # is assumed dvprp and dvprl are the same for all species later on. (can change that)\n",
    "    dvprp = vprp[sp][0,2,0]-vprp[sp][0,1,0]\n",
    "    dvprl = vprl[sp][0,0,2]-vprl[sp][0,0,1]\n",
    "\n",
    "    #first normalization by number of processors\n",
    "    vdf_[sp] = vdf_[sp] / float(n_proc)\n",
    "    edotv_prl_[sp] = edotv_prl_[sp] / float(n_proc)\n",
    "    edotv_prp_[sp] = edotv_prp_[sp] / float(n_proc)\n",
    "\n",
    "    if apply_smoothing:\n",
    "    for ifilt in range(filter_passes):\n",
    "      edotv_prp_[sp] = gaussian_filter(edotv_prp_[sp],sigma=sigma_smoothing,axes=(1,2))\n",
    "      edotv_prl_[sp] = gaussian_filter(edotv_prl_[sp],sigma=sigma_smoothing,axes=(1,2))\n",
    "\n",
    "    # average over a rolling window (could also try fixed bin avgs)\n",
    "    vdf_avg.append(xarray.DataArray(vdf_[sp],dims=['t','wprp','wprl']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "    edotv_prp_avg.append(xarray.DataArray(edotv_prp_[sp],dims=['t','wprp','wprl']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "    edotv_prl_avg.append(xarray.DataArray(edotv_prl_[sp],dims=['t','wprp','wprl']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "\n",
    "    edotv_prp_t.append(edotv_prp_[sp]*1.0)\n",
    "    edotv_prl_t.append(edotv_prl_[sp]*1.0)\n",
    "\n",
    "    #computing <df/dwprp>\n",
    "    fvprp_t = np.sum(vdf_[sp]/vprp[sp]*dvprl,axis=2) / np.sum(np.sum(vdf_[sp]/vprp[sp]*dvprl*dvprl,axis=2),axis=1,keepdims=True)\n",
    "    dfdwprp_t.append(np.gradient(fvprp_t,vprp[sp][0,:,0],edge_order=edge_grad_order,axis=1))\n",
    "    dfdwprp_avg.append(xarray.DataArray(dfdwprp_t[sp],dims=['t','wprp']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "\n",
    "\n",
    "    vdf_, time, edotv_prp_, edotv_prl_, vprp, vprl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1d0c96-8b15-4e43-938f-e2e5a978beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### HEATING VS W_PERP (beta = 0.3)\n",
    "#\n",
    "# -> reading simulation data, time averaging, and cooling corrections\n",
    "# -> also: reading spectra of fluctuations, reducing to k_perp spectra, and time averaging\n",
    "#\n",
    "print(\"\\n ### HEATING VS W_PERP ###\")\n",
    "\n",
    "\n",
    "\n",
    "# read in VDF, edotv file saved using jono's scripts\n",
    "vdf_, time, edotv_prp_, edotv_prl_, vprp, vprl = pegr.readmat_vdf(name,itf0,itf1+1,nspecies,plotsp,edv=True,grid=True,verbose=verb_read)\n",
    "\n",
    "time = time[itf0:itf1+1,:]\n",
    "\n",
    "vdf_avg = []\n",
    "edotv_prp_t = []\n",
    "edotv_prl_t = []\n",
    "edotv_prp_avg = []\n",
    "edotv_prl_avg = []\n",
    "dfdwprp_t = []\n",
    "dfdwprp_avg = []\n",
    "\n",
    "for sp in np.arange(nspecies):\n",
    "    if verb_diag:\n",
    "        print(\"\\n\")\n",
    "        print(\"#########################################################\")\n",
    "        print(\"### v-space analysis: distribution function & heating ###\")\n",
    "        print(\"#########################################################\")\n",
    "        print(\"species\",plotsp[sp])\n",
    "\n",
    "    # is assumed dvprp and dvprl are the same for all species later on. (can change that)\n",
    "    dvprp = vprp[sp][0,2,0]-vprp[sp][0,1,0]\n",
    "    dvprl = vprl[sp][0,0,2]-vprl[sp][0,0,1]\n",
    "\n",
    "    #first normalization by number of processors\n",
    "    vdf_[sp] = vdf_[sp] / float(n_proc)\n",
    "    edotv_prl_[sp] = edotv_prl_[sp] / float(n_proc)\n",
    "    edotv_prp_[sp] = edotv_prp_[sp] / float(n_proc)\n",
    "\n",
    "    if apply_smoothing:\n",
    "        for ifilt in range(filter_passes):\n",
    "          edotv_prp_[sp] = gaussian_filter(edotv_prp_[sp],sigma=sigma_smoothing,axes=(1,2))\n",
    "          edotv_prl_[sp] = gaussian_filter(edotv_prl_[sp],sigma=sigma_smoothing,axes=(1,2))\n",
    "\n",
    "    # average over a rolling window (could also try fixed bin avgs)\n",
    "    vdf_avg.append(xarray.DataArray(vdf_[sp],dims=['t','wprp','wprl']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "    edotv_prp_avg.append(xarray.DataArray(edotv_prp_[sp],dims=['t','wprp','wprl']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "    edotv_prl_avg.append(xarray.DataArray(edotv_prl_[sp],dims=['t','wprp','wprl']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "\n",
    "    edotv_prp_t.append(edotv_prp_[sp]*1.0)\n",
    "    edotv_prl_t.append(edotv_prl_[sp]*1.0)\n",
    "\n",
    "    #computing <df/dwprp>\n",
    "    fvprp_t = np.sum(vdf_[sp]/vprp[sp]*dvprl,axis=2) / np.sum(np.sum(vdf_[sp]/vprp[sp]*dvprl*dvprl,axis=2),axis=1,keepdims=True)\n",
    "    dfdwprp_t.append(np.gradient(fvprp_t,vprp[sp][0,:,0],edge_order=edge_grad_order,axis=1))\n",
    "    dfdwprp_avg.append(xarray.DataArray(dfdwprp_t[sp],dims=['t','wprp']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "\n",
    "\n",
    "    vdf_, time, edotv_prp_, edotv_prl_, vprp, vprl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd985bc6-bae3-4deb-a701-5e08c92104a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vdf_[sp]/vprp[sp]\n",
    "#vdf output is actually vperp*f: restoring f\n",
    "# check if jono's script already corrects for this\n",
    "vdf = []\n",
    "for sp in np.arange(nspecies):\n",
    "    vdf.append(vdf_avg[sp] / vprp[sp])\n",
    "    vdf0[sp] = vdf0[sp] / vprp0[sp][0,:,:]\n",
    "\n",
    "edotv_prl = edotv_prl_avg\n",
    "edotv_prp = edotv_prp_avg\n",
    "if (not apply_smoothing):\n",
    "  edotv_prl_smooth = edotv_prl_smooth_avg\n",
    "  edotv_prp_smooth = edotv_prp_smooth_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6613c-c7c6-4124-8f47-7a0124a9a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(\"########################## BETA = 0.3 ##########################\")\n",
    "print(\" (from v space -- before cooling corrections) \")\n",
    "print(\" after 3.5t_A\")\n",
    "for sp in  np.arange(nspecies):\n",
    "    print(\" species \",plotsp[sp])\n",
    "    print(\" 1) integral of <Qperp> (code units): \",np.mean(np.sum(edotv_prp[sp][:,:,:]*dvprp*dvprl,axis=(1,2))))\n",
    "    print(\" 2) integral of <Qpar> (code units): \",np.mean(np.sum(edotv_prl[sp][:,:,:]*dvprp*dvprl,axis=(1,2))))\n",
    "print(\"################################################################\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#computing d<f>/dw_perp\n",
    "#dfdwprp = np.gradient(np.sum(vdf*dvprl,axis=1),vprp)\n",
    "# f_vprp using rolling averaged f, and then calculating dfdwprp\n",
    "f_vprp = []\n",
    "f0_vprp = []\n",
    "dfdwprp = []\n",
    "dfdwprp_finitediff = []\n",
    "gg_tmp = []\n",
    "gg_tmp_smooth = []\n",
    "\n",
    "for sp in np.arange(nspecies):\n",
    "    f_vprp.append(np.sum(vdf[sp]*dvprl,axis=2)/np.abs(  np.sum(np.sum(vdf[sp]*dvprl*dvprp,axis=2),axis=1,keepdims=True)   ))\n",
    "    f0_vprp.append(np.sum(vdf0[sp]*dvprl,axis=1)/np.abs(np.sum(vdf0[sp]*dvprl*dvprp)))\n",
    "    dfdwprp.append(np.gradient(f_vprp[sp],vprp[sp][0,:,0],edge_order=edge_grad_order,axis=1))\n",
    "    dfdwprp_finitediff.append(np.zeros(f_vprp[sp].shape))\n",
    "    dfdwprp_finitediff[sp][:,1:-1] = (f_vprp[sp][:,2:]-f_vprp[sp][:,:-2])/(vprp[sp][:,2:,0]-vprp[sp][:,:-2,0])\n",
    "    dfdwprp_finitediff[sp][:,0] = (f_vprp[sp][:,1]-f_vprp[sp][:,0])/(vprp[sp][:,1,0]-vprp[sp][:,0,0])\n",
    "    dfdwprp_finitediff[sp][:,len(vprp[sp][0,:,0])-1] = (f_vprp[sp][:,len(vprp[sp][0,:,0])-1]-f_vprp[sp][:,len(vprp[sp][0,:,0])-2])/(vprp[sp][:,len(vprp[sp][0,:,0])-1,0]-vprp[sp][:,len(vprp[sp][0,:,0])-2,0])\n",
    "\n",
    "# rolling avg edotv\n",
    "    gg_tmp.append(edotv_prp[sp]/(np.abs( np.abs(np.sum(edotv_prl[sp]*dvprp*dvprl,axis=(1,2),keepdims=True)) + np.abs(np.sum(edotv_prp[sp]*dvprp*dvprl,axis=(1,2),keepdims=True)) )))\n",
    "    edotv_prp_t[sp] /= (np.abs( np.abs(np.sum(edotv_prl_t[sp]*dvprp*dvprl,axis=(1,2),keepdims=True)) + np.abs(np.sum(edotv_prp_t[sp]*dvprp*dvprl,axis=(1,2),keepdims=True)) ))\n",
    "    if (not apply_smoothing):\n",
    "        gg_tmp_smooth.append(edotv_prp_smooth[sp]/(np.abs( np.abs(np.sum(edotv_prl_smooth[sp]*dvprp*dvprl,axis=(1,2),keepdims=True)) + np.abs(np.sum(edotv_prp_smooth[sp]*dvprp*dvprl,axis=(1,2),keepdims=True)) )))\n",
    "        edotv_prp_smooth_t[sp] /= (np.abs( np.abs(np.sum(edotv_prl_smooth_t[sp]*dvprp*dvprl,axis=(1,2),keepdims=True)) + np.abs(np.sum(edotv_prp_smooth_t[sp]*dvprp*dvprl,axis=(1,2),keepdims=True)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c162a8-2c59-4774-9f0c-78f9ff609451",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cooling_corr:\n",
    "    #correcting for numerical cooling\n",
    "    print(\"\\n [ apply cooling correction (vs w_perp) ]\")\n",
    "    \"\"\"\n",
    "    # if not apply_smoothing - store in edotv_prp_smooth arrays etc instead\n",
    "    # can just do everything in one line instead\n",
    "    edotv_prl_corr.append(np.mean(edotv_prl_[sp][it0corr:it1corr+1,:,:],axis=0,keepdims=True))\n",
    "    edotv_prp_corr.append(np.mean(edotv_prp_[sp][it0corr:it1corr+1,:,:],axis=0,keepdims=True))\n",
    "    if (not apply_smoothing):\n",
    "        edotv_prl_smooth_corr.append(gaussian_filter(edotv_prl_[sp][it0corr:it1corr+1,:,:],sigma=sigma_smoothing,axes=(1,2)))\n",
    "        edotv_prp_smooth_corr.append(gaussian_filter(edotv_prp_[sp][it0corr:it1corr+1,:,:],sigma=sigma_smoothing,axes=(1,2)))\n",
    "        for ifilt in range(filter_passes-1):\n",
    "            edotv_prl_smooth_corr[sp] = gaussian_filter(edotv_prl_smooth_corr[sp],sigma=sigma_smoothing,axes=(1,2))\n",
    "            edotv_prp_smooth_corr[sp] = gaussian_filter(edotv_prp_smooth_corr[sp],sigma=sigma_smoothing,axes=(1,2))\n",
    "        edotv_prl_smooth_corr[sp] = np.mean(edotv_prl_smooth_corr[sp],axis=0,keepdims=True)\n",
    "        edotv_prp_smooth_corr[sp] = np.mean(edotv_prp_smooth_corr[sp],axis=0,keepdims=True)\n",
    "    \"\"\"\n",
    "\n",
    "    gg_tmp[sp] -= edotv_prp_corr[sp]/(np.abs( np.abs(np.sum(edotv_prl_corr[sp]*dvprp*dvprl,keepdims=True)) + np.abs(np.sum(edotv_prp_corr[sp]*dvprp*dvprl,keepdims=True)) ))\n",
    "    edotv_prp_t[sp] -= edotv_prp_corr[sp]/(np.abs( np.abs(np.sum(edotv_prl_corr[sp]*dvprp*dvprl,keepdims=True)) + np.abs(np.sum(edotv_prp_corr[sp]*dvprp*dvprl,keepdims=True)) ))\n",
    "\n",
    "    if (not apply_smoothing):\n",
    "        gg_tmp_smooth[sp] -= edotv_prp_smooth_corr[sp]/(np.abs( np.abs(np.sum(edotv_prl_smooth_corr[sp]*dvprp*dvprl,keepdims=True)) + np.abs(np.sum(edotv_prp_smooth_corr[sp]*dvprp*dvprl,keepdims=True)) ))\n",
    "        edotv_prp_smooth_t[sp] -= edotv_prp_smooth_corr[sp]/(np.abs( np.abs(np.sum(edotv_prl_smooth_corr[sp]*dvprp*dvprl,keepdims=True)) + np.abs(np.sum(edotv_prp_smooth_corr[sp]*dvprp*dvprl,keepdims=True)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd517cd1-0b5c-45aa-8e74-48b4d8c4b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qprp_vprp = []\n",
    "Qprp_vprp_t = []\n",
    "Qprp_vprp_t_avg = []\n",
    "Qprp_vprp_smooth = []\n",
    "Qprp_vprp_smooth_t = []\n",
    "Qprp_vprp_smooth_t_avg = []\n",
    "stdQprp_vprp = []\n",
    "stdQprp_vprp_smooth = []\n",
    "Dprpprp = []\n",
    "Dprpprp_sign = []\n",
    "Dprpprp_t = []\n",
    "Dprpprp_t_avg = []\n",
    "Dprpprp_smooth = []\n",
    "Dprpprp_sign_smooth = []\n",
    "Dprpprp_smooth_t = []\n",
    "Dprpprp_smooth_t_avg = []\n",
    "stdDprpprp_vprp = []\n",
    "stdDprpprp_vprp_smooth = []\n",
    "\n",
    "for sp in np.arange(nspecies):\n",
    "    # total perpendicular heating from edotv\n",
    "    # does this need to be normalised by qom? since E field acceleration\n",
    "    Qprp_vprp.append(np.sum(gg_tmp[sp]*dvprl,axis=2))\n",
    "    Qprp_vprp_t.append(np.sum(edotv_prp_t[sp]*dvprl,axis=2))\n",
    "    Qprp_vprp_t_avg.append(xarray.DataArray(Qprp_vprp_t[sp],dims=['t','wprp']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "    if (not apply_smoothing):\n",
    "      Qprp_vprp_smooth.append(np.sum(gg_tmp_smooth[sp]*dvprl,axis=2))\n",
    "      Qprp_vprp_smooth_t.append(np.sum(edotv_prp_smooth_t[sp]*dvprl,axis=2))\n",
    "      Qprp_vprp_smooth_t_avg.append(xarray.DataArray(Qprp_vprp_smooth_t[sp],dims=['t','wprp']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "\n",
    "    #normalize Qprp_sim (after or before computing Dprpprp?)\n",
    "    #normQ_sim[sp] = Qnormalization01/np.sum(np.abs(Qprp_vprp[sp])*dvprp,axis=1,keepdims=True)\n",
    "    #print(\"  -> denom of normQ_sim = \",np.sum(np.abs(Qprp_vprp[sp])*dvprp,axis=1))\n",
    "    Qprp_vprp[sp] *= Qnormalization01/np.sum(np.abs(Qprp_vprp[sp])*dvprp,axis=1,keepdims=True)\n",
    "    #Qprp_vprp_t *= normQ_sim\n",
    "    Qprp_vprp_t[sp] *= Qnormalization01/np.sum(np.abs(Qprp_vprp_t[sp])*dvprp,axis=1,keepdims=True)\n",
    "    #for iit in range(it0,it1+1):\n",
    "    #  Qprp_vprp_t[:,iit-it0] *= Qnormalization01/np.sum(np.abs(Qprp_vprp_t[:,iit-it0])*dvprp)\n",
    "    #Qprp_vprp_t_avg *= normQ_sim\n",
    "    Qprp_vprp_t_avg[sp] *= Qnormalization01/np.sum(np.abs(Qprp_vprp_t_avg[sp])*dvprp,axis=1,keepdims=True)\n",
    "\n",
    "    #std in time\n",
    "    stdQprp_vprp.append(np.std(Qprp_vprp_t[sp],axis=0))\n",
    "\n",
    "    if (not apply_smoothing):\n",
    "        Qprp_vprp_smooth[sp] *= Qnormalization01/np.sum(np.abs(Qprp_vprp_smooth[sp])*dvprp,axis=1,keepdims=True)\n",
    "        Qprp_vprp_smooth_t[sp] *= Qnormalization01/np.sum(np.abs(Qprp_vprp_smooth_t[sp])*dvprp,axis=1,keepdims=True)\n",
    "        Qprp_vprp_smooth_t_avg[sp] *= Qnormalization01/np.sum(np.abs(Qprp_vprp_smooth_t_avg[sp])*dvprp,axis=1,keepdims=True)\n",
    "        stdQprp_vprp_smooth.append(np.std(Qprp_vprp_smooth_t[sp],axis=0))\n",
    "\n",
    "\n",
    "    #computing diff coefficient  heating/dfdw\n",
    "    #Get rid of divisions by zero that we get because of how many wprp we go out to (where there are no particles/f)\n",
    "    #Q is mostly small in these regions...\n",
    "    #dfdw0s = np.ones(dfdwprp[sp].shape)-np.isnan(1./dfdwprp[sp])\n",
    "    #dfdw0s_t = np.ones(dfdwprp_t[sp].shape)-np.isnan(1./dfdwprp_t[sp])\n",
    "    Dprpprp.append(- np.abs(Qprp_vprp[sp]) / dfdwprp[sp])\n",
    "    Dprpprp[sp][np.isinf(1./dfdwprp[sp])]=0\n",
    "    Dprpprp_sign.append(- Qprp_vprp[sp] / dfdwprp[sp])\n",
    "    Dprpprp_sign[sp][np.isinf(1./dfdwprp[sp])]=0\n",
    "    Dprpprp_t.append(- np.abs(Qprp_vprp_t[sp]) / dfdwprp_t[sp])\n",
    "    Dprpprp_t[sp][np.isinf(1./dfdwprp_t[sp])]=0\n",
    "    Dprpprp_t_avg.append(xarray.DataArray(Dprpprp_t[sp],dims=['t','wprp']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "    #Dprpprp_t_avg[sp][np.isnan(Dprpprp_t_avg[sp])]=0\n",
    "    stdDprpprp_vprp.append(np.std(Dprpprp_t[sp],axis=0))\n",
    "\n",
    "    if (not apply_smoothing):\n",
    "      Dprpprp_smooth.append(- np.abs(Qprp_vprp_smooth[sp]) / dfdwprp[sp])\n",
    "      Dprpprp_smooth[sp][np.isinf(1./dfdwprp[sp])]=0\n",
    "      Dprpprp_sign_smooth.append(- Qprp_vprp_smooth[sp] / dfdwprp[sp])\n",
    "      Dprpprp_sign_smooth[sp][np.isinf(1./dfdwprp[sp])]=0\n",
    "      Dprpprp_smooth_t.append(- np.abs(Qprp_vprp_smooth_t[sp]) / dfdwprp_t[sp])\n",
    "      Dprpprp_smooth_t[sp][np.isinf(1./dfdwprp_t[sp])]=0\n",
    "      Dprpprp_smooth_t_avg.append(xarray.DataArray(Dprpprp_smooth_t[sp],dims=['t','wprp']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())\n",
    "      #Dprpprp_smooth_t_avg[sp][np.isnan(Dprpprp_smooth_t_avg[sp])]=0\n",
    "      stdDprpprp_vprp_smooth.append(np.std(Dprpprp_smooth_t[sp],axis=0))\n",
    "\n",
    "    print(\"species \",sp)\n",
    "    print(\"\\n ##### CHECK: integral of simulation curves (beta_i = 0.3) ##### (avg after 3.5t_A)\")\n",
    "    print(\"  -> normQ_sim = \",Qnormalization01/np.mean(np.sum(np.abs(Qprp_vprp[sp])*dvprp,axis=1)[100:]))\n",
    "    print(\"  -> integral of df/dwprp..\")\n",
    "    print(\"     i) ..from np.gradient:\",np.mean(np.sum(dfdwprp[sp]*dvprp,axis=1)[100:]))\n",
    "    print(\"    ii) ..from finite diff:\",np.mean(np.sum(dfdwprp_finitediff[sp]*dvprp,axis=1)[100:]))\n",
    "    print(\"    ..to be compared with f(vprp=0):\",np.mean(f_vprp[sp][100:,0]))\n",
    "    #print(\"   [dfdwprp - dfdwprp_finitediff =\",dfdwprp - dfdwprp_finitediff,\"]\")\n",
    "    print(\"  -> integral of dQprp/dwprp: \",np.mean(np.sum(Qprp_vprp[sp]*dvprp,axis=1)[100:]))\n",
    "    print(\"  -> integral of Dprpprp.. \")\n",
    "    print(\"     i) ..from < dQ/dwprp > / < df/dwprp > :\",np.mean(np.sum(Dprpprp[sp]*dvprp,axis=1)[100:]))\n",
    "    print(\"    ii) ..from < (dQ/dwprp) / (df/dwprp) > :\",np.mean(np.sum(Dprpprp_t_avg[sp]*dvprp,axis=1)[100:]))\n",
    "    print(\" ################################################################\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb21bfb-c452-46d1-bf54-3a2e61b85721",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Qprp_vprp_t_avg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06acbc10-9e94-4164-adfa-a9906bad9c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qprp_vprp_t_avg[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c24cb-0125-4ba2-84b0-73eafaead899",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qprp_t = []\n",
    "Qprp_t_avg = []\n",
    "for sp in np.arange(nspecies):\n",
    "    Qprp_t.append(np.sum(edotv_prp[0][:,:,:]*dvprp*dvprl,axis=(1,2)))\n",
    "    Qprp_t_avg.append(xarray.DataArray(Qprp_t[sp],dims=['t']).rolling(t=rolling_window,min_periods=1, center=True).mean().to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a6e312-685e-497c-8567-c502decf121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Qprp_t_avg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e8e5ce-9c52-49ee-bb33-ca77fb7f96dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read saved Qprps calculated from history dump dT/dt\n",
    "\n",
    "\n",
    "pathToMat = \"../saved-analysis/PlotQ-all.mat\"\n",
    "nspecies = 7\n",
    "# saved .mat using 'v7.3' so need to read using hdf5\n",
    "with h5py.File(pathToMat, \"r\") as f:\n",
    "    # Print all root level object names (aka keys)\n",
    "    # these can be group or dataset names\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    # get first object name/key; may or may NOT be a group\n",
    "    f_group_key = list(f.keys())[1]\n",
    "\n",
    "    # get the object type for a_group_key: usually group or dataset\n",
    "    print(type(f[f_group_key]))\n",
    "\n",
    "    # If a_group_key is a group name,\n",
    "    # this gets the object names in the group and returns as a list\n",
    "    data = list(f[f_group_key])\n",
    "\n",
    "    # If a_group_key is a dataset name,\n",
    "    # this gets the dataset values and returns as a list\n",
    "    data = list(f[f_group_key])\n",
    "    # preferred methods to get dataset values:\n",
    "    #ds_obj = f[a_group_key]      # returns as a h5py dataset object\n",
    "    #ds_arr = f[a_group_key][()]  # returns as a numpy array\n",
    "\n",
    "\n",
    "    #data = list(f[a_group_key]['f0'])\n",
    "    #ds_arr = f[a_group_key]['f0'][()]\n",
    "    #t = f.get('F')['t']\n",
    "    t_hst1 = f[f_group_key]['t1'][()]#[()]\n",
    "    t_hst2 = f[f_group_key]['t2'][()]#[()]\n",
    "\n",
    "    tep1 = []\n",
    "    tel1 = []\n",
    "    tel2 = []\n",
    "    tep2 = []\n",
    "    te1 = []\n",
    "    te2 = []\n",
    "    qp1 = []\n",
    "    ql1 = []\n",
    "    qp2 = []\n",
    "    ql2 = []\n",
    "    #hdf object reference is the key in the original file that refers to a dataset\n",
    "    for i in np.arange(3):\n",
    "        #[i,0]\n",
    "        tep1.append(f[f[f_group_key]['tep1'][i,0]][()])\n",
    "        tel1.append(f[f[f_group_key]['tel1'][i,0]][()])\n",
    "        te1.append(f[f[f_group_key]['te1'][i,0]][()])\n",
    "        qp1.append(f[f[f_group_key]['qp1'][i,0]][()])\n",
    "        ql1.append(f[f[f_group_key]['ql1'][i,0]][()])\n",
    "    for i in np.arange(nspecies):\n",
    "        #[i,0]\n",
    "        tep2.append(f[f[f_group_key]['tep2'][i,0]][()])\n",
    "        tel2.append(f[f[f_group_key]['tel2'][i,0]][()])\n",
    "        te2.append(f[f[f_group_key]['te2'][i,0]][()])\n",
    "        qp2.append(f[f[f_group_key]['qp2'][i,0]][()])\n",
    "        ql2.append(f[f[f_group_key]['ql2'][i,0]][()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97723835-216a-492f-be37-f46be2817ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "ql2[0][0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a224b93b-28b5-41de-873e-a6af9d4b0842",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_hst2[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1de06b-78af-4bfd-9526-cbab61b33c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(qp2[1][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daff769-4ea5-4e8e-ac59-9a83e5fd560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_hst2[0,:],qp2[1][0,:])\n",
    "plt.plot(time,Qprp_t_avg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc94f5-b3f3-4df6-8fe0-5e0448e3e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_t_arr = np.arange(it0,it1+1)*28.90811\n",
    "dfdwprp_t_interp = []\n",
    "for sp in np.arange(nspecies):\n",
    "    dfdwprp_t_interp.append(np.zeros((it1+1-it0,dfdwprp_t[sp].shape[1])))\n",
    "    for ind in range(dfdwprp_t[sp].shape[1]):\n",
    "        dfdwprp_t_interp[sp][:,ind] = np.interp(phi_t_arr, time[:,0], dfdwprp_t[sp][:,ind])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
