{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/lmsys/conversations_and_category_w_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def combine_conversation_steps(conversation):\n",
    "    \"\"\"Combines all steps of a conversation into a single string, keeping only content.\"\"\"\n",
    "\n",
    "    # remove outer brackets\n",
    "    conversation = conversation.strip('[]')\n",
    "\n",
    "    # convert to list of dict string, per line\n",
    "    conversation = conversation.split('\\n')\n",
    "\n",
    "    # convert each line to dict\n",
    "    conversation = [ast.literal_eval(line) for line in conversation]\n",
    "\n",
    "    # Extract content from each step and join with newlines\n",
    "    contents = [f\"## Message by {step.get('role', '')}:\\n\\n{step.get('content', '')}\\n\\n\\n\\n\" for step in conversation if isinstance(step, dict)]\n",
    "\n",
    "    return '\\n'.join(contents)\n",
    "\n",
    "test_conversation = df[\"conversation_a\"][1]\n",
    "print(combine_conversation_steps(test_conversation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the combine_conversation_steps function to both conversation columns\n",
    "df['text_a'] = df['conversation_a'].apply(combine_conversation_steps)\n",
    "df['text_b'] = df['conversation_b'].apply(combine_conversation_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "\n",
    "# Index(['index', 'question_id', 'model_a', 'model_b', 'winner',\n",
    "#        'conversation_a', 'conversation_b', 'turn', 'anony', 'language',\n",
    "#        'tstamp', 'conv_metadata', 'is_code', 'is_refusal', 'dedup_tag',\n",
    "#        'category_tag', 'judge_hash', 'Prompt', 'Topic', 'broad_category_id',\n",
    "#        'broad_category', 'narrower_category_id', 'narrower_category',\n",
    "#        'prompt_count', 'prompt_percentage', 'example_prompt', 'response_a',\n",
    "#        'response_b'],\n",
    "#      dtype='object')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.winner.value_counts())\n",
    "\n",
    "df_subset = df[df.winner.isin(['model_a', 'model_b'])]\n",
    "# should be text_a if winner is model_a, otherwise text_b\n",
    "df_subset[\"preferred_text\"] = df_subset[\"winner\"].map({\"model_a\": \"text_a\", \"model_b\": \"text_b\"})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# date string (nums only)\n",
    "date_str = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "save_path = f\"../data/processed/lmsys/lmsys_arena_explorer_data_w_topics_{date_str}.csv\"\n",
    "\n",
    "# add winner_model and rejected_model columns\n",
    "def get_winner_model(row):\n",
    "    if row[\"winner\"] == \"model_a\":\n",
    "        return row[\"model_a\"]\n",
    "    else:\n",
    "        return row[\"model_b\"]\n",
    "\n",
    "def get_rejected_model(row):\n",
    "    if row[\"winner\"] == \"model_a\":\n",
    "        return row[\"model_b\"]\n",
    "    else:\n",
    "        return row[\"model_a\"]\n",
    "\n",
    "df_subset[\"winner_model\"] = df_subset.apply(get_winner_model, axis=1)\n",
    "df_subset[\"rejected_model\"] = df_subset.apply(get_rejected_model, axis=1)\n",
    "\n",
    "#Â remove conversation columns\n",
    "df_subset = df_subset.drop(columns=[\"conversation_a\", \"conversation_b\"])\n",
    "df_subset.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
