{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate synthetic data \n",
    "\n",
    "Also for use with AlpacaEval\n",
    "\n",
    "Note specific AlpacaEval requirements:\n",
    "- Generator columns must be in data (note this refers to the generator model of output_2, as output_1 would typically be a (always identical) reference model)\n",
    "- The generator column must have more than one value (otherwise correlation metrics fail). Note that due to the non-descript nature of models in our synthetic data, these values should be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure API keys are loaded\n",
    "import dotenv\n",
    "_ = dotenv.load_dotenv(\"../secrets.toml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inverse_cai\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "model = inverse_cai.models.get_model(\"openai/gpt-3.5-turbo\", temp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(instruction, story_generating_prompt, differing_parts, model, num_samples=1):\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        stories = {}\n",
    "        for part in differing_parts:\n",
    "            random_prompt = random.choice([\"Thanks!\", \"I appreciate it.\", \"That's great.\", \"Cheers.\", \"Thanks a lot.\", \"Good stuff.\"])\n",
    "            stories[part] = model.invoke(story_generating_prompt.format(differing_part=part) + \" \" + random_prompt).content\n",
    "\n",
    "        preferred_spot = random.choice([1, 2])\n",
    "        preferred_text = \"text_a\" if preferred_spot == 1 else \"text_b\"\n",
    "        output = {}\n",
    "        output[preferred_spot] = stories[differing_parts[0]]\n",
    "        output[3 - preferred_spot] = stories[differing_parts[1]]\n",
    "\n",
    "        combined_text = \"Instruction: {instruction}\\n\\nOutput: {output}\"\n",
    "\n",
    "        data.append(\n",
    "            {\n",
    "                \"text_a\": combined_text.format(instruction=instruction, output=output[1]),\n",
    "                \"text_b\": combined_text.format(instruction=instruction, output=output[2]),\n",
    "                \"preferred_text\": preferred_text,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # random short id of fixed length\n",
    "    short_id = lambda: \"\".join(random.choices(\"abcdefghijklmnopqrstuvwxyz\", k=5))\n",
    "\n",
    "    # remove non alphanumeric characters\n",
    "    name_string = '_'.join(differing_parts)\n",
    "    name_string = ''.join(e for e in name_string if e.isalnum())\n",
    "\n",
    "    file_path = f\"synthetic_data_{name_string}_{short_id()}.csv\"\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(file_path, index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_combined_data(path: str, datasets: list):\n",
    "    combined_data = pd.concat(datasets)\n",
    "    # reset index\n",
    "    combined_data.reset_index(drop=True, inplace=True)\n",
    "    combined_data.to_csv(path, index=True)\n",
    "    print(\"Data saved.\")\n",
    "\n",
    "short_id = lambda: \"\".join(random.choices(\"abcdefghijklmnopqrstuvwxyz\", k=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Orthogonal data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_data = generate_data(\n",
    "    instruction = \"Please write a funny short story about a human and their pet.\",\n",
    "    story_generating_prompt = \"\"\"\n",
    "    Please write a funny short story about a human and their pet. Their pet is a {differing_part}. Max 5 sentences.\n",
    "    \"\"\",\n",
    "    differing_parts = [\"cat\", \"dog\"],\n",
    "    model = model,\n",
    "    num_samples=NUM_SAMPLES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_data = generate_data(\n",
    "    instruction = \"Should I pick this blue t-shirt or the green one?\",\n",
    "    story_generating_prompt = \"\"\"\n",
    "    Give a short reasoning why I should pick a {differing_part} t-shirt. Mention the color. Max 1 sentences.\n",
    "    \"\"\",\n",
    "    differing_parts = [\"blue\", \"green\"],\n",
    "    model = model,\n",
    "    num_samples=NUM_SAMPLES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_cream_data = generate_data(\n",
    "    instruction = \"Which ice cream flavor should I pick?\",\n",
    "    story_generating_prompt = \"\"\"\n",
    "    Tell me why I should pick the {differing_part} ice cream. Max 1 short sentence. Include the name of the flavor.\n",
    "    \"\"\",\n",
    "    differing_parts = [\"lemon\", \"raspberry\"],\n",
    "    model = model,\n",
    "    num_samples=NUM_SAMPLES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_combined_data(f\"../data/processed/synthetic/crossannotated_synthetic_data_orthogonal_{short_id()}.csv\", [pet_data, color_data, ice_cream_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Aligned data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concise_data = generate_data(\n",
    "    instruction = \"What is the capital of the US?\",\n",
    "    story_generating_prompt = \"\"\"\n",
    "    {differing_part}\n",
    "    \"\"\",\n",
    "    differing_parts = [\"What is the capital of the US? Max 1 sentence.\", \"Give me a made-up reason why Paris is the capital of the US. Max 1 sentence.\"],\n",
    "    model = model,\n",
    "    num_samples=NUM_SAMPLES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "useful_data = generate_data(\n",
    "    instruction = \"What would be an interesting destination to travel to in the UK?\",\n",
    "    story_generating_prompt = \"\"\"\n",
    "    {differing_part}\n",
    "    \"\"\",\n",
    "    differing_parts = [\n",
    "        \"Give me one interesting destination to travel to in the UK. Max 1 sentence.\",\n",
    "        \"Why is it good to travel? Do not mention any specific destination names. Max 1 sentence.\"],\n",
    "    model = model,\n",
    "    num_samples=NUM_SAMPLES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polite_data = generate_data(\n",
    "    instruction = \"Can you help me?\",\n",
    "    story_generating_prompt = \"\"\"\n",
    "    {differing_part}\n",
    "    \"\"\",\n",
    "    differing_parts = [\n",
    "        \"Can you help me?\",\n",
    "        \"How would somebody reply rudely and lazily to a request for help, offering to help but not enthusiastically? Max 1 sentence.\"],\n",
    "    model = model,\n",
    "    num_samples=NUM_SAMPLES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_combined_data(\n",
    "    f\"../data/processed/synthetic/crossannotated_synthetic_data_aligned_{short_id()}.csv\",\n",
    "    [concise_data, useful_data, polite_data]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
