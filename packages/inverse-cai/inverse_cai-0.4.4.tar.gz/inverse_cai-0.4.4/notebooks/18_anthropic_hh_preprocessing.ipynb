{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook to preprocess feedback data for Inverse Consitutional AI algorithm\n",
    "\n",
    "import pathlib\n",
    "import inverse_cai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = pathlib.Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for loading and saving data in same order\n",
    "# create random shuffle of the data\n",
    "# that can be saved and reproduced\n",
    "\n",
    "def save_random_index(df, path, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random_index_series = pd.Series(np.random.permutation(df.index), index=df.index)\n",
    "    random_index_series.to_csv(path, index=False, header=False)\n",
    "\n",
    "def load_random_order_and_apply_to_df(df, path):\n",
    "    rand_index = pd.read_csv(path, header=None).squeeze()\n",
    "    assert len(rand_index) == len(df), f\"Length of random index {len(rand_index)} does not match length of dataframe {len(df)}\"\n",
    "    return df.loc[rand_index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Fetch the anthropic dataset if not downloaded yet\n",
    "import gzip\n",
    "from urllib.request import urlopen\n",
    "dataset_revision = \"354e5c3cb8960630860dd5774a6ac2a58313bf4d\"\n",
    "\n",
    "anthropic_target_dir = DATA_DIR / \"raw/anthropic/anthropic_helpful_base\"\n",
    "anthropic_target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download and unzip the file\n",
    "url = f\"https://github.com/anthropics/hh-rlhf/raw/{dataset_revision}/helpful-base/train.jsonl.gz\"\n",
    "with urlopen(url) as response:\n",
    "    with gzip.open(response, 'rb') as gz:\n",
    "        file_content = gz.read()\n",
    "\n",
    "file_path = anthropic_target_dir / \"train.jsonl\"\n",
    "with open(file_path, 'wb') as f:\n",
    "    f.write(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess feedback data from Anthropic\n",
    "# Origin: https://github.com/anthropics/hh-rlhf\n",
    "\n",
    "for data_type in [\"helpful\", \"harmless\"]:\n",
    "    ANTH_PATH = DATA_DIR / f\"raw/anthropic/anthropic_{data_type}_base/train.jsonl\"\n",
    "    anth_df = inverse_cai.data.loader.anthropic.load_original_jsonl_file(ANTH_PATH )\n",
    "    anth_canonical_order_path = DATA_DIR / f\"meta_data/anthropic/anthropic_{data_type}_base_train_canonical_rand_order.csv\"\n",
    "\n",
    "    # OPTIONAL: save new random order\n",
    "    if not anth_canonical_order_path.exists():\n",
    "        save_random_index(anth_df, anth_canonical_order_path, seed=42)\n",
    "\n",
    "    anth_df_canonical_order = load_random_order_and_apply_to_df(anth_df, anth_canonical_order_path)\n",
    "\n",
    "    # Randomly flip text_a and text_b to balance the dataset\n",
    "    np.random.seed(42)\n",
    "    flip_mask = np.random.rand(len(anth_df_canonical_order)) < 0.5\n",
    "\n",
    "    # Create copy to avoid modifying original\n",
    "    anth_df_canonical_order = anth_df_canonical_order.copy()\n",
    "\n",
    "    # For rows where flip_mask is True, swap text_a and text_b\n",
    "    temp_a = anth_df_canonical_order.loc[flip_mask, 'text_a'].copy()\n",
    "    anth_df_canonical_order.loc[flip_mask, 'text_a'] = anth_df_canonical_order.loc[flip_mask, 'text_b']\n",
    "    anth_df_canonical_order.loc[flip_mask, 'text_b'] = temp_a\n",
    "\n",
    "    # Update preferred_text to match the flips\n",
    "    anth_df_canonical_order.loc[flip_mask, 'preferred_text'] = \"text_b\"\n",
    "    anth_df_canonical_order.loc[~flip_mask, 'preferred_text'] = \"text_a\"\n",
    "\n",
    "    print(f\"Anthropic {data_type} base dataset loaded with {len(anth_df_canonical_order)} samples\")\n",
    "\n",
    "    LEN_PROCESSED = 10000\n",
    "    processed_path = DATA_DIR / f\"processed/anthropic/anthropic_{data_type}_base_train_{LEN_PROCESSED}canonrand_balanced.csv\"\n",
    "    processed_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    anth_df_canonical_order[:LEN_PROCESSED].to_csv(processed_path, index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anth_df_canonical_order[:LEN_PROCESSED].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
