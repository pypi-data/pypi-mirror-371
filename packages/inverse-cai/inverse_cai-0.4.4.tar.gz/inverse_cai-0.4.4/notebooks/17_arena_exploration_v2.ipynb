{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 57477\n",
      "Model counts (appearances as either model A or B):\n",
      "gpt-4-1106-preview                7387\n",
      "gpt-3.5-turbo-0613                7083\n",
      "gpt-4-0613                        6165\n",
      "claude-2.1                        5583\n",
      "claude-instant-1                  4136\n",
      "gpt-4-0314                        4122\n",
      "claude-1                          3978\n",
      "vicuna-33b                        3720\n",
      "mixtral-8x7b-instruct-v0.1        3545\n",
      "vicuna-13b                        3448\n",
      "llama-2-70b-chat                  3428\n",
      "gpt-3.5-turbo-1106                3352\n",
      "mistral-medium                    3315\n",
      "llama-2-13b-chat                  2607\n",
      "claude-2.0                        2456\n",
      "zephyr-7b-beta                    2401\n",
      "palm-2                            1977\n",
      "llama-2-7b-chat                   1793\n",
      "wizardlm-70b                      1644\n",
      "openchat-3.5                      1632\n",
      "mistral-7b-instruct               1617\n",
      "koala-13b                         1598\n",
      "vicuna-7b                         1591\n",
      "wizardlm-13b                      1580\n",
      "oasst-pythia-12b                  1494\n",
      "gemini-pro-dev-api                1486\n",
      "codellama-34b-instruct            1474\n",
      "yi-34b-chat                       1447\n",
      "gemini-pro                        1438\n",
      "pplx-70b-online                   1420\n",
      "alpaca-13b                        1403\n",
      "gpt-3.5-turbo-0314                1302\n",
      "chatglm-6b                        1261\n",
      "pplx-7b-online                    1250\n",
      "tulu-2-dpo-70b                    1200\n",
      "gpt-4-0125-preview                1160\n",
      "RWKV-4-Raven-14B                  1158\n",
      "starling-lm-7b-alpha              1134\n",
      "qwen-14b-chat                     1072\n",
      "fastchat-t5-3b                    1021\n",
      "chatglm3-6b                        989\n",
      "openhermes-2.5-mistral-7b          952\n",
      "mpt-7b-chat                        928\n",
      "stripedhyena-nous-7b               914\n",
      "solar-10.7b-instruct-v1.0          899\n",
      "gpt-3.5-turbo-0125                 861\n",
      "dolly-v2-12b                       800\n",
      "deepseek-llm-67b-chat              795\n",
      "stablelm-tuned-alpha-7b            771\n",
      "guanaco-33b                        684\n",
      "llama2-70b-steerlm-chat            667\n",
      "mpt-30b-chat                       598\n",
      "chatglm2-6b                        564\n",
      "qwen1.5-72b-chat                   551\n",
      "llama-13b                          547\n",
      "zephyr-7b-alpha                    412\n",
      "gpt4all-13b-snoozy                 408\n",
      "dolphin-2.2.1-mistral-7b           373\n",
      "nous-hermes-2-mixtral-8x7b-dpo     325\n",
      "falcon-180b-chat                   286\n",
      "openchat-3.5-0106                  244\n",
      "qwen1.5-7b-chat                    208\n",
      "qwen1.5-4b-chat                    200\n",
      "mistral-7b-instruct-v0.2           100\n",
      "Name: count, dtype: int64\n",
      "Size with na: 8174, size without na: 8172, number of rows removed: 2\n",
      "Error encoding prompt for row 548: 'utf-8' codec can't encode characters in position 162-163: surrogates not allowed\n",
      "Error encoding prompt for row 12339: 'utf-8' codec can't encode characters in position 47-48: surrogates not allowed\n",
      "Error encoding prompt for row 13253: 'utf-8' codec can't encode characters in position 390-391: surrogates not allowed\n",
      "Error encoding prompt for row 23102: 'utf-8' codec can't encode characters in position 85-86: surrogates not allowed\n",
      "Error encoding prompt for row 27806: 'utf-8' codec can't encode characters in position 54-57: surrogates not allowed\n",
      "Error encoding prompt for row 31557: 'utf-8' codec can't encode characters in position 187-188: surrogates not allowed\n",
      "Error encoding prompt for row 36739: 'utf-8' codec can't encode characters in position 146-147: surrogates not allowed\n",
      "Error encoding prompt for row 37936: 'utf-8' codec can't encode characters in position 293-294: surrogates not allowed\n",
      "Error encoding prompt for row 38663: 'utf-8' codec can't encode characters in position 166-167: surrogates not allowed\n",
      "Error encoding prompt for row 41769: 'utf-8' codec can't encode characters in position 141-144: surrogates not allowed\n",
      "Error encoding prompt for row 48439: 'utf-8' codec can't encode characters in position 247-248: surrogates not allowed\n",
      "Error encoding prompt for row 48645: 'utf-8' codec can't encode characters in position 739-740: surrogates not allowed\n",
      "Error encoding prompt for row 49345: 'utf-8' codec can't encode characters in position 10-11: surrogates not allowed\n",
      "Error encoding prompt for row 49379: 'utf-8' codec can't encode characters in position 293-294: surrogates not allowed\n",
      "Error encoding prompt for row 49559: 'utf-8' codec can't encode characters in position 10-11: surrogates not allowed\n",
      "Error encoding prompt for row 55487: 'utf-8' codec can't encode characters in position 33-34: surrogates not allowed\n",
      "Error encoding response_a for row 147: 'utf-8' codec can't encode characters in position 40-43: surrogates not allowed\n",
      "Error encoding response_a for row 440: 'utf-8' codec can't encode characters in position 1655-1662: surrogates not allowed\n",
      "Error encoding response_a for row 1068: 'utf-8' codec can't encode characters in position 147-148: surrogates not allowed\n",
      "Error encoding response_a for row 2085: 'utf-8' codec can't encode characters in position 385-386: surrogates not allowed\n",
      "Error encoding response_a for row 2204: 'utf-8' codec can't encode characters in position 788-789: surrogates not allowed\n",
      "Error encoding response_a for row 2473: 'utf-8' codec can't encode characters in position 11-12: surrogates not allowed\n",
      "Error encoding response_a for row 3123: 'utf-8' codec can't encode characters in position 55-58: surrogates not allowed\n",
      "Error encoding response_a for row 3575: 'utf-8' codec can't encode characters in position 9-10: surrogates not allowed\n",
      "Error encoding response_a for row 4027: 'utf-8' codec can't encode characters in position 87-88: surrogates not allowed\n",
      "Error encoding response_a for row 4740: 'utf-8' codec can't encode characters in position 6-7: surrogates not allowed\n",
      "Error encoding response_a for row 4780: 'utf-8' codec can't encode characters in position 873-876: surrogates not allowed\n",
      "Error encoding response_a for row 5259: 'utf-8' codec can't encode characters in position 171-172: surrogates not allowed\n",
      "Error encoding response_a for row 8121: 'utf-8' codec can't encode characters in position 80-81: surrogates not allowed\n",
      "Error encoding response_a for row 8220: 'utf-8' codec can't encode characters in position 69-70: surrogates not allowed\n",
      "Error encoding response_a for row 8989: 'utf-8' codec can't encode characters in position 2175-2176: surrogates not allowed\n",
      "Error encoding response_a for row 12263: 'utf-8' codec can't encode characters in position 10-11: surrogates not allowed\n",
      "Error encoding response_a for row 13729: 'utf-8' codec can't encode characters in position 0-1: surrogates not allowed\n",
      "Error encoding response_a for row 13785: 'utf-8' codec can't encode characters in position 292-293: surrogates not allowed\n",
      "Error encoding response_a for row 14029: 'utf-8' codec can't encode characters in position 713-718: surrogates not allowed\n",
      "Error encoding response_a for row 14306: 'utf-8' codec can't encode characters in position 92-93: surrogates not allowed\n",
      "Error encoding response_a for row 15668: 'utf-8' codec can't encode characters in position 188-191: surrogates not allowed\n",
      "Error encoding response_a for row 17375: 'utf-8' codec can't encode characters in position 80-81: surrogates not allowed\n",
      "Error encoding response_a for row 18262: 'utf-8' codec can't encode characters in position 90-95: surrogates not allowed\n",
      "Error encoding response_a for row 20145: 'utf-8' codec can't encode characters in position 0-1: surrogates not allowed\n",
      "Error encoding response_a for row 22137: 'utf-8' codec can't encode characters in position 12-13: surrogates not allowed\n",
      "Error encoding response_a for row 23064: 'utf-8' codec can't encode characters in position 130-133: surrogates not allowed\n",
      "Error encoding response_a for row 25602: 'utf-8' codec can't encode characters in position 77-78: surrogates not allowed\n",
      "Error encoding response_a for row 27211: 'utf-8' codec can't encode characters in position 49-50: surrogates not allowed\n",
      "Error encoding response_a for row 28042: 'utf-8' codec can't encode characters in position 2-3: surrogates not allowed\n",
      "Error encoding response_a for row 28432: 'utf-8' codec can't encode characters in position 215-216: surrogates not allowed\n",
      "Error encoding response_a for row 28447: 'utf-8' codec can't encode characters in position 339-340: surrogates not allowed\n",
      "Error encoding response_a for row 29029: 'utf-8' codec can't encode characters in position 2010-2011: surrogates not allowed\n",
      "Error encoding response_a for row 30067: 'utf-8' codec can't encode characters in position 30-31: surrogates not allowed\n",
      "Error encoding response_a for row 30239: 'utf-8' codec can't encode characters in position 11-12: surrogates not allowed\n",
      "Error encoding response_a for row 32216: 'utf-8' codec can't encode characters in position 3-4: surrogates not allowed\n",
      "Error encoding response_a for row 33429: 'utf-8' codec can't encode characters in position 206-207: surrogates not allowed\n",
      "Error encoding response_a for row 34315: 'utf-8' codec can't encode characters in position 3-6: surrogates not allowed\n",
      "Error encoding response_a for row 35027: 'utf-8' codec can't encode characters in position 126-129: surrogates not allowed\n",
      "Error encoding response_a for row 35080: 'utf-8' codec can't encode characters in position 314-315: surrogates not allowed\n",
      "Error encoding response_a for row 35746: 'utf-8' codec can't encode characters in position 283-286: surrogates not allowed\n",
      "Error encoding response_a for row 36125: 'utf-8' codec can't encode characters in position 67-68: surrogates not allowed\n",
      "Error encoding response_a for row 36141: 'utf-8' codec can't encode characters in position 326-327: surrogates not allowed\n",
      "Error encoding response_a for row 37943: 'utf-8' codec can't encode characters in position 0-1: surrogates not allowed\n",
      "Error encoding response_a for row 38376: 'utf-8' codec can't encode characters in position 100-101: surrogates not allowed\n",
      "Error encoding response_a for row 40775: 'utf-8' codec can't encode characters in position 1831-1832: surrogates not allowed\n",
      "Error encoding response_a for row 40992: 'utf-8' codec can't encode characters in position 0-5: surrogates not allowed\n",
      "Error encoding response_a for row 41119: 'utf-8' codec can't encode characters in position 751-752: surrogates not allowed\n",
      "Error encoding response_a for row 44542: 'utf-8' codec can't encode characters in position 173-174: surrogates not allowed\n",
      "Error encoding response_a for row 45713: 'utf-8' codec can't encode characters in position 158-159: surrogates not allowed\n",
      "Error encoding response_a for row 46039: 'utf-8' codec can't encode characters in position 772-773: surrogates not allowed\n",
      "Error encoding response_a for row 46129: 'utf-8' codec can't encode characters in position 124-125: surrogates not allowed\n",
      "Error encoding response_a for row 47291: 'utf-8' codec can't encode characters in position 126-127: surrogates not allowed\n",
      "Error encoding response_a for row 48889: 'utf-8' codec can't encode characters in position 28-29: surrogates not allowed\n",
      "Error encoding response_a for row 50040: 'utf-8' codec can't encode characters in position 78-81: surrogates not allowed\n",
      "Error encoding response_a for row 50703: 'utf-8' codec can't encode characters in position 344-345: surrogates not allowed\n",
      "Error encoding response_a for row 54686: 'utf-8' codec can't encode characters in position 0-57: surrogates not allowed\n",
      "Error encoding response_a for row 55989: 'utf-8' codec can't encode characters in position 774-775: surrogates not allowed\n",
      "Error encoding response_a for row 56126: 'utf-8' codec can't encode characters in position 311-312: surrogates not allowed\n",
      "Error encoding response_a for row 56307: 'utf-8' codec can't encode characters in position 0-1: surrogates not allowed\n",
      "Error encoding response_b for row 2031: 'utf-8' codec can't encode characters in position 0-1: surrogates not allowed\n",
      "Error encoding response_b for row 4424: 'utf-8' codec can't encode characters in position 66-67: surrogates not allowed\n",
      "Error encoding response_b for row 6264: 'utf-8' codec can't encode characters in position 329-330: surrogates not allowed\n",
      "Error encoding response_b for row 10398: 'utf-8' codec can't encode characters in position 1646-1649: surrogates not allowed\n",
      "Error encoding response_b for row 13746: 'utf-8' codec can't encode characters in position 257-258: surrogates not allowed\n",
      "Error encoding response_b for row 14144: 'utf-8' codec can't encode characters in position 298-299: surrogates not allowed\n",
      "Error encoding response_b for row 16091: 'utf-8' codec can't encode characters in position 79-80: surrogates not allowed\n",
      "Error encoding response_b for row 16677: 'utf-8' codec can't encode characters in position 183-184: surrogates not allowed\n",
      "Error encoding response_b for row 18673: 'utf-8' codec can't encode characters in position 394-399: surrogates not allowed\n",
      "Error encoding response_b for row 20251: 'utf-8' codec can't encode characters in position 311-318: surrogates not allowed\n",
      "Error encoding response_b for row 23147: 'utf-8' codec can't encode characters in position 22-27: surrogates not allowed\n",
      "Error encoding response_b for row 26343: 'utf-8' codec can't encode characters in position 1344-1345: surrogates not allowed\n",
      "Error encoding response_b for row 28393: 'utf-8' codec can't encode characters in position 2315-2316: surrogates not allowed\n",
      "Error encoding response_b for row 29543: 'utf-8' codec can't encode characters in position 935-936: surrogates not allowed\n",
      "Error encoding response_b for row 29814: 'utf-8' codec can't encode characters in position 245-246: surrogates not allowed\n",
      "Error encoding response_b for row 30558: 'utf-8' codec can't encode characters in position 44-45: surrogates not allowed\n",
      "Error encoding response_b for row 30645: 'utf-8' codec can't encode characters in position 777-778: surrogates not allowed\n",
      "Error encoding response_b for row 31489: 'utf-8' codec can't encode characters in position 36-41: surrogates not allowed\n",
      "Error encoding response_b for row 32659: 'utf-8' codec can't encode characters in position 36-37: surrogates not allowed\n",
      "Error encoding response_b for row 33807: 'utf-8' codec can't encode characters in position 2078-2079: surrogates not allowed\n",
      "Error encoding response_b for row 33925: 'utf-8' codec can't encode characters in position 361-364: surrogates not allowed\n",
      "Error encoding response_b for row 38941: 'utf-8' codec can't encode characters in position 1666-1669: surrogates not allowed\n",
      "Error encoding response_b for row 40426: 'utf-8' codec can't encode characters in position 282-285: surrogates not allowed\n",
      "Error encoding response_b for row 41958: 'utf-8' codec can't encode characters in position 292-293: surrogates not allowed\n",
      "Error encoding response_b for row 43687: 'utf-8' codec can't encode characters in position 184-185: surrogates not allowed\n",
      "Error encoding response_b for row 46401: 'utf-8' codec can't encode characters in position 163-164: surrogates not allowed\n",
      "Error encoding response_b for row 55589: 'utf-8' codec can't encode characters in position 171-172: surrogates not allowed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/lmsys/chatbot_arena_kaggle2024_train.csv\", dtype={\"prompt\": str, \"response_a\": str, \"response_b\": str, \"model_a\": str, \"model_b\": str})\n",
    "\n",
    "print(f\"Original dataset size: {len(df)}\")\n",
    "\n",
    "# get sum of all appearances of each model\n",
    "vc_a = df[\"model_a\"].value_counts()\n",
    "vc_b = df[\"model_b\"].value_counts()\n",
    "combined_vc = pd.concat([vc_a, vc_b]).groupby(level=0).sum()\n",
    "combined_vc = combined_vc.sort_values(ascending=False)\n",
    "print(\"Model counts (appearances as either model A or B):\")\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(combined_vc)\n",
    "pd.reset_option('display.max_rows')\n",
    "\n",
    "# select datapoints with subset of models\n",
    "model_list = ['gpt-4-1106-preview', 'gpt-3.5-turbo-0613', 'claude-2.1', 'claude-2.0', 'claude-1', 'gpt-4-0314', 'llama-2-70b-chat', 'llama-2-13b-chat', 'llama-2-7b-chat', 'mixtral-8x7b-instruct-v0.1', \"gpt-4-0613\", \"tulu-2-dpo-70b\", \"vicuna-33b\"]\n",
    "df = df[df['model_a'].isin(model_list) & df['model_b'].isin(model_list)]\n",
    "\n",
    "# remove ties\n",
    "df = df[df['winner_tie'] == 0]\n",
    "\n",
    "# get number of prompts and responses per model\n",
    "def convert_to_list(list_str):\n",
    "    try:\n",
    "        # fiz invalid escape sequence issue\n",
    "        list_str = list_str.replace(r'\\/', '/')\n",
    "        return ast.literal_eval(list_str)\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            # replace null with None, note this may very slightly affect the string meaning\n",
    "            list_str = re.sub(\"null\", \"None\", list_str)\n",
    "            return ast.literal_eval(list_str)\n",
    "        except Exception as e2:\n",
    "            print(\"Error parsing:\", list_str)\n",
    "            print(e)\n",
    "            print(e2)\n",
    "            return []\n",
    "\n",
    "for col in [\"prompt\", \"response_a\", \"response_b\"]:\n",
    "    df[col] = df[col].apply(convert_to_list)\n",
    "    df[col + \"_length\"] = df[col].apply(len)\n",
    "    df[col] = df[col].apply(lambda x: x[0] if len(x) > 0 else None)\n",
    "\n",
    "# filter out row with either prompt/response_a/response_b being len more than 1\n",
    "df = df[(df[\"prompt_length\"] == 1) & (df[\"response_a_length\"] == 1) & (df[\"response_b_length\"] == 1)]\n",
    "\n",
    "# drop rows with na in prompt, response_a, response_b\n",
    "size_with_na = len(df)\n",
    "df = df.dropna(subset=[\"prompt\", \"response_a\", \"response_b\"])\n",
    "size_without_na = len(df)\n",
    "print(f\"Size with na: {size_with_na}, size without na: {size_without_na}, number of rows removed: {size_with_na - size_without_na}\")\n",
    "\n",
    "# add winner_model and loser_model columns\n",
    "df['winner_model'] = df.apply(lambda x: x['model_a'] if x['winner_model_a'] == 1 else x['model_b'], axis=1)\n",
    "df['loser_model'] = df.apply(lambda x: x['model_a'] if x['winner_model_a'] == 0 else x['model_b'], axis=1)\n",
    "\n",
    "# check if each col of prompt, response_a, response_b is encodable in utf-8\n",
    "# drop rows that are not encodable\n",
    "import warnings\n",
    "warnings.filterwarnings(\"error\")\n",
    "\n",
    "for col in [\"prompt\", \"response_a\", \"response_b\"]:\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            row[col].encode(\"utf-8\", errors=\"strict\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error encoding {col} for row {i}: {e}\")\n",
    "            df.drop(i, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>prompt_length</th>\n",
       "      <th>response_a_length</th>\n",
       "      <th>response_b_length</th>\n",
       "      <th>winner_model</th>\n",
       "      <th>loser_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2298796</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>claude-2.1</td>\n",
       "      <td>make a haiku on bacon the food</td>\n",
       "      <td>Crisp strips of delight,\\nSizzling dance, morn...</td>\n",
       "      <td>Here is a haiku about bacon:\\n\\nSizzling in pa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>claude-2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2802516</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>i have this: import logo from './ressources/lo...</td>\n",
       "      <td>The navigation is only visible on the root pat...</td>\n",
       "      <td>This is happening because you have defined the...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>claude-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2912862</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>texts = [text.split() for text in df[\"text_pro...</td>\n",
       "      <td>The code snippet you provided is used to creat...</td>\n",
       "      <td>The code you've provided is writing a vocab fi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3499263</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>write the lyrics to a rap song about some dude...</td>\n",
       "      <td>(Verse 1)\\nYo, let's take a minute, prepare to...</td>\n",
       "      <td>Here's an attempt at some rap lyrics about a d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3503031</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>tell me a joke containing Tiger and Mobile phone?</td>\n",
       "      <td>Sure, here's a joke for you:\\n\\nWhy did the ti...</td>\n",
       "      <td>Why don't tigers use mobile phones? \\n\\nBecaus...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57464</th>\n",
       "      <td>4294068603</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>Sarah (female) has three brothers, her brother...</td>\n",
       "      <td>Sarah has two sisters.</td>\n",
       "      <td>Sarah has one sister.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57465</th>\n",
       "      <td>4294081229</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>please describe how the following two statemen...</td>\n",
       "      <td>The two statements can both be correct and not...</td>\n",
       "      <td>These two statements may seem contradictory at...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4-0314</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57467</th>\n",
       "      <td>4294254797</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>can you provide a modular python code that wil...</td>\n",
       "      <td>Certainly! Below is a modular Python example t...</td>\n",
       "      <td>Here is a modular Python code to format SQL co...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>claude-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>4294656694</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>A simple mnemonic for π:\\n\"How I wish I could ...</td>\n",
       "      <td>Sure, let's break it down:\\n\\n1. \"How\" has 3 l...</td>\n",
       "      <td>Here is how that mnemonic represents the digit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>4294692063</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>In python, implement a naive Bayes with gaussi...</td>\n",
       "      <td>Here is an implementation of a naive Bayes cla...</td>\n",
       "      <td>Sure! Here's an implementation of a naive Baye...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8070 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             model_a             model_b  \\\n",
       "33        2298796  gpt-4-1106-preview          claude-2.1   \n",
       "35        2802516          claude-2.0            claude-1   \n",
       "37        2912862  gpt-4-1106-preview          gpt-4-0613   \n",
       "45        3499263          gpt-4-0613            claude-1   \n",
       "46        3503031    llama-2-13b-chat          gpt-4-0613   \n",
       "...           ...                 ...                 ...   \n",
       "57464  4294068603          gpt-4-0613  gpt-3.5-turbo-0613   \n",
       "57465  4294081229          gpt-4-0314          gpt-4-0613   \n",
       "57467  4294254797  gpt-4-1106-preview          claude-2.0   \n",
       "57472  4294656694          gpt-4-0613            claude-1   \n",
       "57473  4294692063          claude-2.0    llama-2-13b-chat   \n",
       "\n",
       "                                                  prompt  \\\n",
       "33                        make a haiku on bacon the food   \n",
       "35     i have this: import logo from './ressources/lo...   \n",
       "37     texts = [text.split() for text in df[\"text_pro...   \n",
       "45     write the lyrics to a rap song about some dude...   \n",
       "46     tell me a joke containing Tiger and Mobile phone?   \n",
       "...                                                  ...   \n",
       "57464  Sarah (female) has three brothers, her brother...   \n",
       "57465  please describe how the following two statemen...   \n",
       "57467  can you provide a modular python code that wil...   \n",
       "57472  A simple mnemonic for π:\\n\"How I wish I could ...   \n",
       "57473  In python, implement a naive Bayes with gaussi...   \n",
       "\n",
       "                                              response_a  \\\n",
       "33     Crisp strips of delight,\\nSizzling dance, morn...   \n",
       "35     The navigation is only visible on the root pat...   \n",
       "37     The code snippet you provided is used to creat...   \n",
       "45     (Verse 1)\\nYo, let's take a minute, prepare to...   \n",
       "46     Sure, here's a joke for you:\\n\\nWhy did the ti...   \n",
       "...                                                  ...   \n",
       "57464                             Sarah has two sisters.   \n",
       "57465  The two statements can both be correct and not...   \n",
       "57467  Certainly! Below is a modular Python example t...   \n",
       "57472  Sure, let's break it down:\\n\\n1. \"How\" has 3 l...   \n",
       "57473  Here is an implementation of a naive Bayes cla...   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "33     Here is a haiku about bacon:\\n\\nSizzling in pa...               1   \n",
       "35     This is happening because you have defined the...               0   \n",
       "37     The code you've provided is writing a vocab fi...               0   \n",
       "45     Here's an attempt at some rap lyrics about a d...               1   \n",
       "46     Why don't tigers use mobile phones? \\n\\nBecaus...               0   \n",
       "...                                                  ...             ...   \n",
       "57464                              Sarah has one sister.               0   \n",
       "57465  These two statements may seem contradictory at...               1   \n",
       "57467  Here is a modular Python code to format SQL co...               1   \n",
       "57472  Here is how that mnemonic represents the digit...               1   \n",
       "57473  Sure! Here's an implementation of a naive Baye...               1   \n",
       "\n",
       "       winner_model_b  winner_tie  prompt_length  response_a_length  \\\n",
       "33                  0           0              1                  1   \n",
       "35                  1           0              1                  1   \n",
       "37                  1           0              1                  1   \n",
       "45                  0           0              1                  1   \n",
       "46                  1           0              1                  1   \n",
       "...               ...         ...            ...                ...   \n",
       "57464               1           0              1                  1   \n",
       "57465               0           0              1                  1   \n",
       "57467               0           0              1                  1   \n",
       "57472               0           0              1                  1   \n",
       "57473               0           0              1                  1   \n",
       "\n",
       "       response_b_length        winner_model         loser_model  \n",
       "33                     1  gpt-4-1106-preview          claude-2.1  \n",
       "35                     1            claude-1          claude-2.0  \n",
       "37                     1          gpt-4-0613  gpt-4-1106-preview  \n",
       "45                     1          gpt-4-0613            claude-1  \n",
       "46                     1          gpt-4-0613    llama-2-13b-chat  \n",
       "...                  ...                 ...                 ...  \n",
       "57464                  1  gpt-3.5-turbo-0613          gpt-4-0613  \n",
       "57465                  1          gpt-4-0314          gpt-4-0613  \n",
       "57467                  1  gpt-4-1106-preview          claude-2.0  \n",
       "57472                  1          gpt-4-0613            claude-1  \n",
       "57473                  1          claude-2.0    llama-2-13b-chat  \n",
       "\n",
       "[8070 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "winner_model\n",
       "gpt-4-1106-preview            1929\n",
       "gpt-4-0613                    1122\n",
       "claude-2.1                     846\n",
       "gpt-3.5-turbo-0613             768\n",
       "gpt-4-0314                     684\n",
       "claude-1                       627\n",
       "vicuna-33b                     474\n",
       "mixtral-8x7b-instruct-v0.1     441\n",
       "llama-2-70b-chat               404\n",
       "claude-2.0                     341\n",
       "llama-2-13b-chat               175\n",
       "tulu-2-dpo-70b                 135\n",
       "llama-2-7b-chat                124\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"winner_model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loser_model\n",
       "claude-2.1                    1472\n",
       "gpt-3.5-turbo-0613            1133\n",
       "gpt-4-0613                    1046\n",
       "gpt-4-1106-preview             639\n",
       "claude-1                       591\n",
       "vicuna-33b                     556\n",
       "mixtral-8x7b-instruct-v0.1     540\n",
       "gpt-4-0314                     540\n",
       "claude-2.0                     457\n",
       "llama-2-70b-chat               408\n",
       "llama-2-13b-chat               283\n",
       "llama-2-7b-chat                215\n",
       "tulu-2-dpo-70b                 190\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"loser_model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8070"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subselect 2k samples\n",
    "# set random seed\n",
    "#df_final = df.sample(2000, random_state=42)\n",
    "df_final = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_bucket\n",
       "0    1009\n",
       "1    1009\n",
       "3    1009\n",
       "4    1009\n",
       "6    1009\n",
       "7    1009\n",
       "2    1008\n",
       "5    1008\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bucket ids into 8 evenly distributed buckets, to detect trends over time\n",
    "df_final[\"id_bucket\"] = pd.qcut(df_final[\"id\"], 8, labels=False)\n",
    "df_final[\"id_bucket\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "#df_final = df_final.rename(columns={\"response_a\": \"text_a\", \"response_b\": \"text_b\"})\n",
    "df_final[\"text_a\"] = df_final[\"response_a\"]\n",
    "df_final[\"text_b\"] = df_final[\"response_b\"]\n",
    "df_final[\"preferred_text\"] = df_final.apply(lambda x: \"text_a\" if x[\"winner_model_a\"] == 1 else \"text_b\", axis=1)\n",
    "\n",
    "# format into correct text\n",
    "# prepend instruction column to both text_a and text_b\n",
    "for col in [\"text_a\", \"text_b\"]:\n",
    "    df_final[col] = \"Instruction:\\n\" + df_final[\"prompt\"] + \"\\n\\n\\nAssistant:\\n\" + df_final[col]\n",
    "\n",
    "# shuffle\n",
    "df_final: pd.DataFrame = df_final.sample(frac=1, random_state=42)\n",
    "\n",
    "df_final.to_csv(f\"../data/processed/lmsys/chatbot_arena_kaggle2024_train_{len(df_final)}random_v3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
