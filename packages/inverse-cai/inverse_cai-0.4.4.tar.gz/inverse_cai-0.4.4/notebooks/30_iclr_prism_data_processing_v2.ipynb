{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "PATH = \"../data/raw/prism/conversations.jsonl\"\n",
    "USER_PATH = \"../data/raw/prism/survey.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_json(path_or_buf=PATH, lines=True)\n",
    "user_df = pd.read_json(path_or_buf=USER_PATH, lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize all dict columns inside dataframe\n",
    "\n",
    "def json_normalize_columns(df):\n",
    "    df = df.copy()\n",
    "    for col in df.columns:\n",
    "        if type(df[col][0]) == dict:\n",
    "            normalized_col = pd.json_normalize(df[col])\n",
    "            normalized_col.columns = [f\"{col}_{sub_col}\" for sub_col in normalized_col.columns]\n",
    "            df = pd.concat([df.drop([col], axis=1), normalized_col], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = json_normalize_columns(user_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs = pd.merge(df, user_df, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chosen_rejected_first_response(row):\n",
    "    conv_hist = row['conversation_history']\n",
    "    first_model_responses = [\n",
    "        response for response in conv_hist if response['turn'] == 0 and response['role'] == 'model'\n",
    "    ]\n",
    "    for response in first_model_responses:\n",
    "        if response['if_chosen'] == True:\n",
    "            chosen_response = response['content']\n",
    "            chosen_model = response['model_name']\n",
    "            break\n",
    "\n",
    "    rejected_responses = []\n",
    "    rejected_models = []\n",
    "\n",
    "    for response in first_model_responses:\n",
    "        if response['if_chosen'] == False:\n",
    "            rejected_responses.append(response['content'])\n",
    "            rejected_models.append(response['model_name'])\n",
    "\n",
    "    # chose rejected response randomly\n",
    "    if len(rejected_responses) > 0:\n",
    "        rejected_index = np.random.choice(len(rejected_responses))\n",
    "        rejected_response = rejected_responses[rejected_index]\n",
    "        rejected_model = rejected_models[rejected_index]\n",
    "    else:\n",
    "        rejected_response = None\n",
    "        rejected_model = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return chosen_response, chosen_model, rejected_responses, rejected_models, rejected_response, rejected_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs['chosen_response'], convs['chosen_model'], convs['rejected_responses'], convs['rejected_models'], convs['rejected_response'], convs['rejected_model'] = zip(*convs.apply(get_chosen_rejected_first_response, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# prepend instruction column to both text_a and text_b\n",
    "\n",
    "def create_texta_textb_preftext(row):\n",
    "    instruction = row[\"opening_prompt\"]\n",
    "    preferred_text = row[\"chosen_response\"]\n",
    "    rejected_text = row[\"rejected_response\"]\n",
    "\n",
    "    preferred_text = \"Instruction:\\n\" + instruction + \"\\n\\n\\nAssistant:\\n\" + preferred_text\n",
    "    rejected_text = \"Instruction:\\n\" + instruction + \"\\n\\n\\nAssistant:\\n\" + rejected_text\n",
    "\n",
    "    text_a_pref = random.choice([True, False])\n",
    "\n",
    "    if text_a_pref:\n",
    "        text_a = preferred_text\n",
    "        text_b = rejected_text\n",
    "        preferred_text = \"text_a\"\n",
    "    else:\n",
    "        text_a = rejected_text\n",
    "        text_b = preferred_text\n",
    "        preferred_text = \"text_b\"\n",
    "\n",
    "    return text_a, text_b, preferred_text\n",
    "\n",
    "convs.dropna(subset=['chosen_response', 'rejected_response'], inplace=True)\n",
    "\n",
    "convs['text_a'], convs['text_b'], convs['preferred_text'] = zip(*convs.apply(create_texta_textb_preftext, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROWS = 2000\n",
    "\n",
    "# shuffle\n",
    "convs = convs.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "if NUM_ROWS is not None:\n",
    "    convs_csv = convs[:NUM_ROWS]\n",
    "    file_name = f\"prism_rand{NUM_ROWS}_incl_metadata_v2.csv\"\n",
    "else:\n",
    "    convs_csv = convs\n",
    "    file_name = \"prism_rand_incl_metadata_v2.csv\"\n",
    "convs_csv.to_csv(f\"../data/processed/prism/{file_name}\", index_label=\"index\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
