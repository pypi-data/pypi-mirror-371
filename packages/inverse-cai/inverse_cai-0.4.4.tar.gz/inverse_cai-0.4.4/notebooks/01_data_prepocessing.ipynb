{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook to preprocess feedback data for Inverse Consitutional AI algorithm\n",
    "\n",
    "import pathlib\n",
    "import inverse_cai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = pathlib.Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for loading and saving data in same order\n",
    "# create random shuffle of the data\n",
    "# that can be saved and reproduced\n",
    "\n",
    "def save_random_index(df, path, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    random_index_series = pd.Series(np.random.permutation(df.index), index=df.index)\n",
    "    random_index_series.to_csv(path, index=False, header=False)\n",
    "\n",
    "def load_random_order_and_apply_to_df(df, path):\n",
    "    rand_index = pd.read_csv(path, header=None).squeeze()\n",
    "    assert len(rand_index) == len(df), f\"Length of random index {len(rand_index)} does not match length of dataframe {len(df)}\"\n",
    "    return df.loc[rand_index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Fetch the anthropic dataset if not downloaded yet\n",
    "import gzip\n",
    "from urllib.request import urlopen\n",
    "dataset_revision = \"354e5c3cb8960630860dd5774a6ac2a58313bf4d\"\n",
    "\n",
    "anthropic_target_dir = DATA_DIR / \"raw/anthropic/anthropic_helpful_base\"\n",
    "anthropic_target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download and unzip the file\n",
    "url = f\"https://github.com/anthropics/hh-rlhf/raw/{dataset_revision}/helpful-base/train.jsonl.gz\"\n",
    "with urlopen(url) as response:\n",
    "    with gzip.open(response, 'rb') as gz:\n",
    "        file_content = gz.read()\n",
    "\n",
    "file_path = anthropic_target_dir / \"train.jsonl\"\n",
    "with open(file_path, 'wb') as f:\n",
    "    f.write(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess feedback data from Anthropic\n",
    "# Origin: https://github.com/anthropics/hh-rlhf\n",
    "ANTH_PATH = DATA_DIR / \"raw/anthropic/anthropic_helpful_base/train.jsonl\"\n",
    "anth_df = inverse_cai.data.loader.anthropic.load_original_jsonl_file(ANTH_PATH )\n",
    "anth_canonical_order_path = DATA_DIR / \"meta_data/anthropic/anthropic_helpful_base_train_canonical_rand_order.csv\"\n",
    "\n",
    "# OPTIONAL: save new random order\n",
    "# save_random_index(anth_df, random_order_path, seed=42)\n",
    "\n",
    "anth_df_canonical_order = load_random_order_and_apply_to_df(anth_df, anth_canonical_order_path)\n",
    "\n",
    "LEN_PROCESSED = 1000\n",
    "processed_path = DATA_DIR / f\"processed/anthropic/anthropic_helpful_base_train_{LEN_PROCESSED}canonrand.csv\"\n",
    "processed_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "anth_df_canonical_order[:LEN_PROCESSED].to_csv(processed_path, index_label='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: load data from HuggingFace if not downloaded yet\n",
    "# Make sure you have run huggingface-cli login, since this dataset is gated\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "dataset = load_dataset(\"lmsys/chatbot_arena_conversations\")\n",
    "chatbot_df = pd.DataFrame(dataset)\n",
    "# Ensure dir exists\n",
    "chatbot_df_path = DATA_DIR / 'raw/lmsys/chatbot_arena_conversations.csv'\n",
    "chatbot_df_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "chatbot_df.to_csv(chatbot_df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepocess feedback data from Chatbot Arena\n",
    "import pandas as pd\n",
    "\n",
    "chatbot_df = inverse_cai.data.loader.lmsys.load_raw(chatbot_df_path, remove_ties=True)\n",
    "\n",
    "chatbot_canonical_order_path = DATA_DIR / \"meta_data/lmsys/chatbot_arena_conversations_canonical_rand_order.csv\"\n",
    "\n",
    "# OPTIONAL: save new random order\n",
    "# save_random_index(chatbot_df, chatbot_canonical_order_path, seed=42)\n",
    "\n",
    "chatbot_df_canonical_order = load_random_order_and_apply_to_df(chatbot_df, chatbot_canonical_order_path)\n",
    "\n",
    "LEN_PROCESSED = 1000\n",
    "processed_path = DATA_DIR / f\"processed/lmsys/chatbot_arena_conversations_{LEN_PROCESSED}canonrand.csv\"\n",
    "processed_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "chatbot_df_canonical_order[:LEN_PROCESSED].to_csv(processed_path, index_label='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alpaca_eval.constants\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the gold cross-annotations dataset\n",
    "df = alpaca_eval.constants.ALPACAFARM_GOLD_CROSSANNOTATIONS()\n",
    "original_df = df.copy(deep=True)\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "### Part 1: combining four preferences into a single consensus preference\n",
    "# NOTE: AlpacaEval has 4 preferences per instruction-output pair, for our purposes\n",
    "# we will combine these into a single preference.\n",
    "\n",
    "TIES = 0\n",
    "\n",
    "# Function to determine the preferred output based on a simple majority vote\n",
    "def majority_vote(group):\n",
    "    counts = group['preference'].value_counts()\n",
    "    if counts.max() == 2:  # Tie (2 vs 2)\n",
    "        global TIES\n",
    "        TIES += 1\n",
    "        return np.random.choice([1,2])\n",
    "    return counts.idxmax()\n",
    "\n",
    "# Group by the unique sets of outputs per instruction and aggregate preferences\n",
    "aggregated_df = df.groupby(['instruction', 'output_1', 'output_2']).apply(majority_vote).reset_index(name='preference')\n",
    "\n",
    "# Add metadata columns from the original DataFrame\n",
    "aggregated_metadata = df[['instruction', 'dataset', 'datasplit', 'time_per_example', 'price_per_example']].drop_duplicates()\n",
    "\n",
    "# Merge the metadata into the aggregated DataFrame\n",
    "print(f\"Number of ties: {TIES}\")\n",
    "df = pd.merge(aggregated_df, aggregated_metadata, on='instruction')\n",
    "\n",
    "\n",
    "### Part 2: move dataset into our standard format\n",
    "\n",
    "df[[\"text_a\", \"text_b\"]] = df[[\"output_1\",\"output_2\"]]\n",
    "\n",
    "# prepend instruction column to both text_a and text_b\n",
    "for col in [\"text_a\", \"text_b\"]:\n",
    "    df[col] = \"Instruction:\\n\" + df[\"instruction\"] + \"\\n\\n\\nAssistant:\\n\" + df[col]\n",
    "\n",
    "# get preferred text column (values text_a, text_b) based on preference column (which has values 1 or 2)\n",
    "df[\"preferred_text\"] = np.where(df['preference'] == 1, 'text_a', 'text_b')\n",
    "\n",
    "# shuffle the data\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "\n",
    "processed_path = DATA_DIR / f\"processed/tatsu_lab/alpacaeval_goldcrossannotations_rand.csv\"\n",
    "processed_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "df[[\"text_a\", \"text_b\", \"preferred_text\"]].to_csv(processed_path, index_label='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "def add_combined_instruction_outputs_column(df):\n",
    "    df['instruction_output'] = df['instruction'] + ' ' + df['output_1'] + ' ' + df['output_2']\n",
    "    return df\n",
    "\n",
    "df = add_combined_instruction_outputs_column(df)\n",
    "original_df = add_combined_instruction_outputs_column(original_df)\n",
    "\n",
    "for i in range(5):\n",
    "    value_counts = original_df['preference'][4*(i):4*(i+1)].value_counts()\n",
    "    instruction_output = original_df['instruction_output'][4*i]\n",
    "    if value_counts.max() == 2:\n",
    "        pass # Tie\n",
    "    else:\n",
    "        assert value_counts.idxmax() == df[df['instruction_output'] == instruction_output]['preference'].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
