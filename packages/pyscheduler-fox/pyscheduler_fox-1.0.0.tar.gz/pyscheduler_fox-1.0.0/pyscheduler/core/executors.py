"""
PyScheduler - Executors Core
============================

Syst√®me d'ex√©cution des t√¢ches avec support multi-threading, async et gestion des priorit√©s.
G√®re l'orchestration et la distribution des t√¢ches selon leur configuration.
"""

import asyncio
import threading
import time
import uuid
from abc import ABC, abstractmethod
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from datetime import datetime
from enum import Enum
from queue import PriorityQueue, Queue, Empty
from typing import Any, Callable, Dict, List, Optional, Set, Union
from dataclasses import dataclass, field

# Import de nos utilitaires (coh√©rence!)
from ..utils import (
    ExecutionError, TaskError, get_default_logger,
    safe_call, format_duration
)
from ..config import Priority
from .task import Task, TaskExecution, TaskStatus


class ExecutorType(Enum):
    """Types d'ex√©cuteurs disponibles"""
    THREAD = "thread"           # Ex√©cution dans des threads
    PROCESS = "process"         # Ex√©cution dans des processus
    ASYNC = "async"            # Ex√©cution asynchrone
    IMMEDIATE = "immediate"     # Ex√©cution imm√©diate (blocking)


@dataclass
class ExecutionRequest:
    """Demande d'ex√©cution d'une t√¢che"""
    task: Task
    priority: Priority
    request_time: datetime = field(default_factory=datetime.now)
    request_id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
    
    def __lt__(self, other):
        """Comparaison pour PriorityQueue (priorit√© plus basse = plus important)"""
        return self.priority.value < other.priority.value


@dataclass
class ExecutorStats:
    """Statistiques d'un ex√©cuteur"""
    total_executions: int = 0
    successful_executions: int = 0
    failed_executions: int = 0
    total_duration: float = 0.0
    active_tasks: int = 0
    queue_size: int = 0
    avg_duration: float = 0.0
    
    def update_execution(self, execution: TaskExecution):
        """Met √† jour les stats avec une ex√©cution"""
        self.total_executions += 1
        self.total_duration += execution.duration
        self.avg_duration = self.total_duration / self.total_executions
        
        if execution.status == TaskStatus.SUCCESS:
            self.successful_executions += 1
        elif execution.status in [TaskStatus.FAILED, TaskStatus.TIMEOUT]:
            self.failed_executions += 1
    
    @property
    def success_rate(self) -> float:
        """Taux de succ√®s (0.0 √† 1.0)"""
        if self.total_executions == 0:
            return 0.0
        return self.successful_executions / self.total_executions
    
    def to_dict(self) -> dict:
        """Convertit en dictionnaire"""
        return {
            'total_executions': self.total_executions,
            'successful_executions': self.successful_executions,
            'failed_executions': self.failed_executions,
            'success_rate': round(self.success_rate * 100, 2),
            'total_duration': round(self.total_duration, 2),
            'avg_duration': round(self.avg_duration, 2),
            'active_tasks': self.active_tasks,
            'queue_size': self.queue_size
        }


class BaseExecutor(ABC):
    """
    Classe de base pour tous les ex√©cuteurs
    
    Un ex√©cuteur g√®re l'ex√©cution des t√¢ches selon une strat√©gie sp√©cifique
    (threads, processus, async, etc.)
    """
    
    def __init__(self, max_workers: int = 10, name: Optional[str] = None):
        """
        Initialise l'ex√©cuteur
        
        Args:
            max_workers: Nombre maximum de workers simultan√©s
            name: Nom de l'ex√©cuteur (pour logging)
        """
        self.max_workers = max_workers
        self.name = name or self.__class__.__name__
        self.logger = get_default_logger()
        
        # √âtat
        self._running = False
        self._stopping = False
        self._lock = threading.RLock()
        
        # Queue des t√¢ches √† ex√©cuter
        self._task_queue = PriorityQueue()
        self._active_tasks: Dict[str, Task] = {}
        
        # Statistiques
        self.stats = ExecutorStats()
        
        # Callbacks
        self._on_task_start: Optional[Callable] = None
        self._on_task_complete: Optional[Callable] = None
        self._on_task_error: Optional[Callable] = None
    
    @abstractmethod
    async def _execute_task(self, task: Task) -> TaskExecution:
        """
        Ex√©cute une t√¢che sp√©cifique √† l'impl√©mentation
        
        Args:
            task: T√¢che √† ex√©cuter
            
        Returns:
            R√©sultat de l'ex√©cution
        """
        pass
    
    @abstractmethod
    def start(self):
        """D√©marre l'ex√©cuteur"""
        pass
    
    @abstractmethod
    def stop(self, timeout: float = 30.0):
        """Arr√™te l'ex√©cuteur proprement"""
        pass
    
    def submit_task(self, task: Task, priority: Optional[Priority] = None) -> str:
        """
        Soumet une t√¢che pour ex√©cution
        
        Args:
            task: T√¢che √† ex√©cuter
            priority: Priorit√© (par d√©faut: priorit√© de la t√¢che)
            
        Returns:
            ID de la demande d'ex√©cution
            
        Raises:
            ExecutionError: Si l'ex√©cuteur n'est pas d√©marr√©
        """
        if not self._running:
            raise ExecutionError("L'ex√©cuteur n'est pas d√©marr√©")
        
        if self._stopping:
            raise ExecutionError("L'ex√©cuteur est en cours d'arr√™t")
        
        # Utiliser la priorit√© de la t√¢che si non sp√©cifi√©e
        task_priority = priority or getattr(task, 'priority', Priority.NORMAL)

        # Cr√©er la demande d'ex√©cution
        request = ExecutionRequest(task=task, priority=task_priority)

        # Ajouter √† la queue
        self._task_queue.put(request)

        with self._lock:
            self.stats.queue_size = self._task_queue.qsize()

        self.logger.debug(
            f"T√¢che '{task.name}' soumise √† l'ex√©cuteur {self.name}",
            request_id=request.request_id,
            priority=task_priority.name if task_priority else 'NORMAL'
        )
        
        return request.request_id
    
    def get_active_tasks(self) -> List[str]:
        """Retourne la liste des t√¢ches en cours d'ex√©cution"""
        with self._lock:
            return list(self._active_tasks.keys())
    
    def get_queue_size(self) -> int:
        """Retourne la taille de la queue"""
        return self._task_queue.qsize()
    
    def is_running(self) -> bool:
        """V√©rifie si l'ex√©cuteur est en marche"""
        return self._running
    
    def set_callbacks(
        self, 
        on_start: Optional[Callable] = None,
        on_complete: Optional[Callable] = None,
        on_error: Optional[Callable] = None
    ):
        """
        Configure les callbacks d'√©v√©nements
        
        Args:
            on_start: Callback appel√© au d√©but d'ex√©cution (task, execution)
            on_complete: Callback appel√© √† la fin d'ex√©cution (task, execution)
            on_error: Callback appel√© en cas d'erreur (task, execution, error)
        """
        self._on_task_start = on_start
        self._on_task_complete = on_complete
        self._on_task_error = on_error
    
    async def _handle_task_execution(self, request: ExecutionRequest):
        """
        G√®re l'ex√©cution compl√®te d'une t√¢che avec callbacks
        
        Args:
            request: Demande d'ex√©cution
        """
        task = request.task
        
        # Marquer comme active
        with self._lock:
            self._active_tasks[task.name] = task
            self.stats.active_tasks = len(self._active_tasks)
        
        try:
            # Callback de d√©but
            if self._on_task_start:
                try:
                    await self._call_callback(self._on_task_start, task, None)
                except Exception as e:
                    self.logger.warning(f"Erreur callback start: {e}")
            
            # Ex√©cution de la t√¢che
            execution = await self._execute_task(task)
            
            # Mettre √† jour les stats
            with self._lock:
                self.stats.update_execution(execution)
            
            # Callback de fin
            if self._on_task_complete:
                try:
                    await self._call_callback(self._on_task_complete, task, execution)
                except Exception as e:
                    self.logger.warning(f"Erreur callback complete: {e}")
            
            # Callback d'erreur si √©chec
            if execution.status in [TaskStatus.FAILED, TaskStatus.TIMEOUT] and self._on_task_error:
                try:
                    await self._call_callback(self._on_task_error, task, execution, execution.error)
                except Exception as e:
                    self.logger.warning(f"Erreur callback error: {e}")
            
            return execution
            
        except Exception as e:
            # Erreur inattendue dans l'ex√©cuteur lui-m√™me
            self.logger.error(f"Erreur ex√©cuteur lors de l'ex√©cution de '{task.name}': {e}")
            
            # Cr√©er un r√©sultat d'erreur
            error_execution = TaskExecution(
                task_name=task.name,
                execution_id=f"error_{request.request_id}",
                status=TaskStatus.FAILED,
                start_time=datetime.now(),
                end_time=datetime.now(),
                error=f"Erreur ex√©cuteur: {e}"
            )
            
            with self._lock:
                self.stats.update_execution(error_execution)
            
            return error_execution
            
        finally:
            # Retirer des t√¢ches actives
            with self._lock:
                self._active_tasks.pop(task.name, None)
                self.stats.active_tasks = len(self._active_tasks)
                self.stats.queue_size = self._task_queue.qsize()
    
    async def _call_callback(self, callback: Callable, *args):
        """Appelle un callback de mani√®re s√©curis√©e"""
        if asyncio.iscoroutinefunction(callback):
            await callback(*args)
        else:
            # Ex√©cuter dans un thread pour ne pas bloquer
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(None, callback, *args)
    
    def get_stats(self) -> dict:
        """Retourne les statistiques de l'ex√©cuteur"""
        with self._lock:
            stats_dict = self.stats.to_dict()
            stats_dict.update({
                'name': self.name,
                'type': self.__class__.__name__,
                'max_workers': self.max_workers,
                'is_running': self._running,
                'is_stopping': self._stopping
            })
            return stats_dict


class ThreadExecutor(BaseExecutor):
    """
    Ex√©cuteur bas√© sur ThreadPoolExecutor
    
    Id√©al pour les t√¢ches I/O bound et la plupart des cas d'usage.
    """
    
    def __init__(self, max_workers: int = 10, name: Optional[str] = None):
        super().__init__(max_workers, name or "ThreadExecutor")
        self._thread_pool: Optional[ThreadPoolExecutor] = None
        self._worker_tasks: Set[asyncio.Task] = set()
    
    # REMPLACE la m√©thode start() dans ThreadExecutor (ligne ~330)

    def start(self):
        """D√©marre l'ex√©cuteur avec pool de threads R√âELS"""
        if self._running:
            self.logger.warning(f"Ex√©cuteur {self.name} d√©j√† d√©marr√©")
            return
        
        self._running = True
        self._stopping = False
        
        # Cr√©er le pool de threads
        self._thread_pool = ThreadPoolExecutor(
            max_workers=self.max_workers,
            thread_name_prefix=f"PyScheduler-{self.name}"
        )
        
        # D√©marrer des workers dans des VRAIS threads (pas async)
        self._worker_threads = []
        for i in range(min(self.max_workers, 5)):
            worker_thread = threading.Thread(
                target=self._sync_worker_loop,
                args=(f"worker-{i}",),
                daemon=True
            )
            worker_thread.start()
            self._worker_threads.append(worker_thread)
            print(f"üêõ DEBUG: Thread worker {i} d√©marr√©")
        
        self.logger.info(f"Ex√©cuteur {self.name} d√©marr√© avec {self.max_workers} threads")

    def _sync_worker_loop(self, worker_name: str):
        """Boucle worker SYNCHRONE dans un thread"""
        print(f"üêõ DEBUG: {worker_name} THREAD D√âMARRE")
        
        while self._running and not self._stopping:
            try:
                # R√©cup√©rer une t√¢che
                try:
                    request = self._task_queue.get(block=True, timeout=1.0)
                except Empty:
                    continue
                
                print(f"üî• {worker_name} traite {request.task.name}")
                
                # Ex√©cuter en mode synchrone
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                try:
                    execution = loop.run_until_complete(request.task.execute())
                    print(f"‚úÖ {worker_name} termin√©: {execution.status}")
                finally:
                    loop.close()
                
                self._task_queue.task_done()
                
            except Exception as e:
                print(f"‚ùå Erreur {worker_name}: {e}")
                import traceback
                traceback.print_exc()
        
        print(f"üêõ DEBUG: {worker_name} THREAD ARR√äT√â")
    
    def stop(self, timeout: float = 30.0):
        """Arr√™te l'ex√©cuteur proprement"""
        if not self._running:
            return
        
        self.logger.info(f"Arr√™t de l'ex√©cuteur {self.name}...")
        self._stopping = True
        
        # Arr√™ter les workers
        for task in self._worker_tasks:
            task.cancel()
        
        # Attendre la fin des workers
        if self._worker_tasks:
            loop = asyncio.get_event_loop()
            try:
                loop.run_until_complete(
                    asyncio.wait_for(
                        asyncio.gather(*self._worker_tasks, return_exceptions=True),
                        timeout=timeout / 2
                    )
                )
            except asyncio.TimeoutError:
                self.logger.warning("Timeout lors de l'arr√™t des workers")
        
        # Arr√™ter le pool de threads
        if self._thread_pool:
            self._thread_pool.shutdown(wait=True)
            self._thread_pool = None
        
        self._running = False
        self.logger.info(f"Ex√©cuteur {self.name} arr√™t√©")
    
    async def _worker_loop(self, worker_name: str):
        """
        Boucle principale d'un worker
        
        Args:
            worker_name: Nom du worker pour logging
        """
        print(f"üêõ DEBUG: {worker_name} D√âMARRE")  # ‚Üê AJOUTE √áA

        self.logger.debug(f"Worker {worker_name} d√©marr√©")
        
        while self._running and not self._stopping:
            try:
                # R√©cup√©rer une t√¢che de la queue (avec timeout)
                try:
                    request = self._task_queue.get(block=True, timeout=1.0)
                except Empty:
                    continue
                
                # Ex√©cuter la t√¢che
                await self._handle_task_execution(request)
                
                # Marquer comme termin√©e
                self._task_queue.task_done()
                
            except asyncio.CancelledError:
                self.logger.debug(f"Worker {worker_name} annul√©")
                break
            except Exception as e:
                self.logger.error(f"Erreur dans worker {worker_name}: {e}")
                await asyncio.sleep(1)  # √âviter les boucles d'erreur
        
        self.logger.debug(f"Worker {worker_name} arr√™t√©")
    
    async def _execute_task(self, task: Task) -> TaskExecution:
        """Ex√©cute une t√¢che dans le pool de threads"""
        if not self._thread_pool:
            raise ExecutionError("Pool de threads non initialis√©")
        
        # D√©l√©guer √† la m√©thode execute de la t√¢che
        return await task.execute()


class AsyncExecutor(BaseExecutor):
    """
    Ex√©cuteur asynchrone natif
    
    Id√©al pour les t√¢ches async et les op√©rations non-bloquantes.
    """
    
    def __init__(self, max_workers: int = 50, name: Optional[str] = None):
        super().__init__(max_workers, name or "AsyncExecutor")
        self._semaphore: Optional[asyncio.Semaphore] = None
        self._worker_tasks: Set[asyncio.Task] = set()
    
    def start(self):
        """D√©marre l'ex√©cuteur async"""
        if self._running:
            self.logger.warning(f"Ex√©cuteur {self.name} d√©j√† d√©marr√©")
            return
        
        self._running = True
        self._stopping = False
        
        # Cr√©er le semaphore pour limiter la concurrence
        self._semaphore = asyncio.Semaphore(self.max_workers)
        
        # D√©marrer les workers
        loop = asyncio.get_event_loop()
        num_workers = min(self.max_workers // 10, 10)  # Moins de workers car async
        for i in range(max(1, num_workers)):
            worker_task = loop.create_task(self._worker_loop(f"async-worker-{i}"))
            self._worker_tasks.add(worker_task)
        
        self.logger.info(f"Ex√©cuteur {self.name} d√©marr√© avec {self.max_workers} slots async")
    
    def stop(self, timeout: float = 30.0):
        """Arr√™te l'ex√©cuteur async"""
        if not self._running:
            return
        
        self.logger.info(f"Arr√™t de l'ex√©cuteur {self.name}...")
        self._stopping = True
        
        # Arr√™ter les workers
        for task in self._worker_tasks:
            task.cancel()
        
        # Attendre la fin
        if self._worker_tasks:
            loop = asyncio.get_event_loop()
            try:
                loop.run_until_complete(
                    asyncio.wait_for(
                        asyncio.gather(*self._worker_tasks, return_exceptions=True),
                        timeout=timeout
                    )
                )
            except asyncio.TimeoutError:
                self.logger.warning("Timeout lors de l'arr√™t des workers async")
        
        self._running = False
        self.logger.info(f"Ex√©cuteur {self.name} arr√™t√©")
    
    async def _worker_loop(self, worker_name: str):
        """Boucle d'un worker async"""
        self.logger.debug(f"Worker async {worker_name} d√©marr√©")
        
        while self._running and not self._stopping:
            try:
                # R√©cup√©rer une t√¢che
                try:
                    request = self._task_queue.get(block=True, timeout=1.0)
                except Empty:
                    continue
                
                # Ex√©cuter avec limitation de concurrence
                async with self._semaphore:
                    await self._handle_task_execution(request)
                
                self._task_queue.task_done()
                
            except asyncio.CancelledError:
                self.logger.debug(f"Worker async {worker_name} annul√©")
                break
            except Exception as e:
                self.logger.error(f"Erreur dans worker async {worker_name}: {e}")
                await asyncio.sleep(1)
        
        self.logger.debug(f"Worker async {worker_name} arr√™t√©")
    
    async def _execute_task(self, task: Task) -> TaskExecution:
        """Ex√©cute une t√¢che de mani√®re asynchrone"""
        return await task.execute()


class ImmediateExecutor(BaseExecutor):
    """
    Ex√©cuteur imm√©diat (bloquant)
    
    Ex√©cute les t√¢ches imm√©diatement dans le thread principal.
    Utile pour les tests et le debugging.
    """
    
    def __init__(self, name: Optional[str] = None):
        super().__init__(max_workers=1, name=name or "ImmediateExecutor")
    
    def start(self):
        """D√©marre l'ex√©cuteur imm√©diat"""
        self._running = True
        self._stopping = False
        self.logger.info(f"Ex√©cuteur {self.name} d√©marr√© (mode imm√©diat)")
    
    def stop(self, timeout: float = 30.0):
        """Arr√™te l'ex√©cuteur imm√©diat"""
        self._running = False
        self.logger.info(f"Ex√©cuteur {self.name} arr√™t√©")
    
    async def _execute_task(self, task: Task) -> TaskExecution:
        """Ex√©cute une t√¢che imm√©diatement"""
        return await task.execute()
    
    def submit_task(self, task: Task, priority: Optional[Priority] = None) -> str:
        """Ex√©cute la t√¢che imm√©diatement au lieu de la mettre en queue"""
        if not self._running:
            raise ExecutionError("L'ex√©cuteur n'est pas d√©marr√©")
        
        request_id = str(uuid.uuid4())[:8]
        
        # Ex√©cution imm√©diate
        loop = asyncio.get_event_loop()
        execution = loop.run_until_complete(self._execute_task(task))
        
        # Mettre √† jour les stats
        with self._lock:
            self.stats.update_execution(execution)
        
        return request_id


class ExecutorManager:
    """
    Gestionnaire des ex√©cuteurs
    
    Orchestre plusieurs ex√©cuteurs et distribue les t√¢ches selon leurs besoins.
    """
    
    def __init__(self):
        self.logger = get_default_logger()
        self._executors: Dict[str, BaseExecutor] = {}
        self._default_executor: Optional[str] = None
        self._task_routing: Dict[str, str] = {}  # task_name -> executor_name
        self._lock = threading.RLock()
    
    def add_executor(self, name: str, executor: BaseExecutor, is_default: bool = False):
        """
        Ajoute un ex√©cuteur
        
        Args:
            name: Nom de l'ex√©cuteur
            executor: Instance de l'ex√©cuteur
            is_default: Utiliser comme ex√©cuteur par d√©faut
        """
        with self._lock:
            self._executors[name] = executor
            
            if is_default or not self._default_executor:
                self._default_executor = name
        
        self.logger.info(f"Ex√©cuteur '{name}' ajout√© ({executor.__class__.__name__})")
    
    def route_task(self, task_name: str, executor_name: str):
        """
        Route une t√¢che vers un ex√©cuteur sp√©cifique
        
        Args:
            task_name: Nom de la t√¢che
            executor_name: Nom de l'ex√©cuteur
        """
        if executor_name not in self._executors:
            raise ExecutionError(f"Ex√©cuteur '{executor_name}' introuvable")
        
        with self._lock:
            self._task_routing[task_name] = executor_name
        
        self.logger.debug(f"T√¢che '{task_name}' rout√©e vers '{executor_name}'")
    
    def submit_task(self, task: Task, executor_name: Optional[str] = None) -> str:
        """
        Soumet une t√¢che √† l'ex√©cuteur appropri√©
        
        Args:
            task: T√¢che √† ex√©cuter
            executor_name: Ex√©cuteur sp√©cifique (optionnel)
            
        Returns:
            ID de la demande
        """
        # D√©terminer l'ex√©cuteur
        target_executor = executor_name
        
        if not target_executor:
            # V√©rifier le routing sp√©cifique √† la t√¢che
            target_executor = self._task_routing.get(task.name)
        
        if not target_executor:
            # Utiliser l'ex√©cuteur par d√©faut
            target_executor = self._default_executor
        
        if not target_executor or target_executor not in self._executors:
            raise ExecutionError("Aucun ex√©cuteur disponible")
        
        executor = self._executors[target_executor]
        return executor.submit_task(task)
    
    def start_all(self):
        """D√©marre tous les ex√©cuteurs"""
        with self._lock:
            for name, executor in self._executors.items():
                try:
                    executor.start()
                except Exception as e:
                    self.logger.error(f"Erreur d√©marrage ex√©cuteur '{name}': {e}")
    
    def stop_all(self, timeout: float = 30.0):
        """Arr√™te tous les ex√©cuteurs"""
        with self._lock:
            for name, executor in self._executors.items():
                try:
                    executor.stop(timeout=timeout / len(self._executors))
                except Exception as e:
                    self.logger.error(f"Erreur arr√™t ex√©cuteur '{name}': {e}")
    
    def get_stats(self) -> Dict[str, dict]:
        """Retourne les stats de tous les ex√©cuteurs"""
        with self._lock:
            return {name: executor.get_stats() for name, executor in self._executors.items()}
    
    def get_executor(self, name: str) -> Optional[BaseExecutor]:
        """Retourne un ex√©cuteur par nom"""
        return self._executors.get(name)
    
    def list_executors(self) -> List[str]:
        """Liste les noms des ex√©cuteurs"""
        with self._lock:
            return list(self._executors.keys())


# Factory pour cr√©er des ex√©cuteurs
class ExecutorFactory:
    """Factory pour cr√©er des ex√©cuteurs selon le type"""
    
    @staticmethod
    def create_executor(
        executor_type: ExecutorType,
        max_workers: int = 10,
        name: Optional[str] = None
    ) -> BaseExecutor:
        """
        Cr√©e un ex√©cuteur selon le type
        
        Args:
            executor_type: Type d'ex√©cuteur
            max_workers: Nombre max de workers
            name: Nom personnalis√©
            
        Returns:
            Instance de l'ex√©cuteur
        """
        if executor_type == ExecutorType.THREAD:
            return ThreadExecutor(max_workers, name)
        elif executor_type == ExecutorType.ASYNC:
            return AsyncExecutor(max_workers, name)
        elif executor_type == ExecutorType.IMMEDIATE:
            return ImmediateExecutor(name)
        else:
            raise ExecutionError(f"Type d'ex√©cuteur non support√©: {executor_type}")