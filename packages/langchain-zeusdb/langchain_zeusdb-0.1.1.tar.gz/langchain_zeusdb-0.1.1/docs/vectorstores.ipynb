{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef1f0986",
   "metadata": {},
   "source": [
    "# ZeusDB Vector Store\n",
    "\n",
    "ZeusDB is a high-performance, Rust-powered vector database with enterprise features like quantization and persistence.\n",
    "\n",
    "This notebook covers how to get started with the ZeusDB Vector Store to efficiently use ZeusDB with LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107c485d-13a3-4309-9fda-5a0440862d3c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fdc060",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d978e3fd-d130-436f-841d-d133c0fae8fb",
   "metadata": {},
   "source": [
    "Install the ZeusDB LangChain integration package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e28aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-zeusdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12fe175-a299-47d3-869f-9367b6aa572d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93df377e",
   "metadata": {},
   "source": [
    "## 1. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37144c-208d-4ab3-9f3a-0407a69fe052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_zeusdb import ZeusDBVectorStore\n",
    "from zeusdb import VectorDatabase\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Create ZeusDB index\n",
    "vdb = VectorDatabase()\n",
    "index = vdb.create(\n",
    "    index_type=\"hnsw\",\n",
    "    dim=1536,\n",
    "    space=\"cosine\"\n",
    ")\n",
    "\n",
    "# Create vector store\n",
    "vector_store = ZeusDBVectorStore(\n",
    "    zeusdb_index=index,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45fa43c-8b54-4a75-b7b0-92ac0ac506c6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6071d4",
   "metadata": {},
   "source": [
    "## 2. Manage Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf53787-ebda-4306-afc3-f7d440dcb1ff",
   "metadata": {},
   "source": [
    "### 2.1 Add items to vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f5efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"ZeusDB is a high-performance vector database\",\n",
    "    metadata={\"source\": \"https://docs.zeusdb.com\"}\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"Product Quantization reduces memory usage significantly\",\n",
    "    metadata={\"source\": \"https://docs.zeusdb.com\"}\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"ZeusDB integrates seamlessly with LangChain\",\n",
    "    metadata={\"source\": \"https://docs.zeusdb.com\"}\n",
    ")\n",
    "\n",
    "documents = [document_1, document_2, document_3]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=[\"1\", \"2\", \"3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c738c3e0",
   "metadata": {},
   "source": [
    "### 2.2 Update items in vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aa8b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_document = Document(\n",
    "    page_content=(\n",
    "        \"ZeusDB now supports advanced Product Quantization \"\n",
    "        \"with 4x-256x compression\"\n",
    "    ),\n",
    "    metadata={\"source\": \"https://docs.zeusdb.com\", \"updated\": True}\n",
    ")\n",
    "\n",
    "vector_store.add_documents([updated_document], ids=[\"1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf1b905",
   "metadata": {},
   "source": [
    "### 2.3 Delete items from vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef61e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.delete(ids=[\"3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0091af-777d-4651-888a-3b346d7990f5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3620501",
   "metadata": {},
   "source": [
    "## 3. Query Vector Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba3fdb2-b7d6-4f0f-b8c9-91f63596018b",
   "metadata": {},
   "source": [
    "### 3.1 Query directly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a9b25-9587-4116-ab59-6888602ec2b1",
   "metadata": {},
   "source": [
    "Performing a simple similarity search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0a16fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    query=\"high performance database\", \n",
    "    k=2\n",
    ")\n",
    "\n",
    "for doc in results:\n",
    "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed9d733",
   "metadata": {},
   "source": [
    "If you want to execute a similarity search and receive the corresponding scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efd2eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    query=\"memory optimization\", \n",
    "    k=2\n",
    ")\n",
    "\n",
    "for doc, score in results:\n",
    "    print(f\"* [SIM={score:.3f}] {doc.page_content} [{doc.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c235cdc",
   "metadata": {},
   "source": [
    "### 3.2 Query by turning into retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59292cb5-5dc8-4158-9137-89d0f6ca711d",
   "metadata": {},
   "source": [
    "You can also transform the vector store into a retriever for easier usage in your chains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3460093",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 2}\n",
    ")\n",
    "\n",
    "retriever.invoke(\"vector database features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2d2b63-99d8-45c4-85e6-6a9409551ada",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistence_section",
   "metadata": {},
   "source": [
    "## 4. ZeusDB-Specific Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "memory_section",
   "metadata": {},
   "source": [
    "### 4.1 Memory-Efficient Setup with Product Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12832d02-d9ea-4c35-a20f-05c85d1d7723",
   "metadata": {},
   "source": [
    "For large datasets, use Product Quantization to reduce memory usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantization_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create memory-optimized vector store\n",
    "quantization_config = {\n",
    "    'type': 'pq',\n",
    "    'subvectors': 8,\n",
    "    'bits': 8,\n",
    "    'training_size': 10000\n",
    "}\n",
    "\n",
    "vdb_quantized = VectorDatabase()\n",
    "quantized_index = vdb_quantized.create(\n",
    "    index_type=\"hnsw\",\n",
    "    dim=1536,\n",
    "    quantization_config=quantization_config\n",
    ")\n",
    "\n",
    "quantized_vector_store = ZeusDBVectorStore(\n",
    "    zeusdb_index=quantized_index,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(f\"Created quantized store: {quantized_index.info()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffe0613-b2a7-484e-9219-1166b65c49c5",
   "metadata": {},
   "source": [
    "### 4.2 Persistence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc323ee-4c6c-43fc-beba-675d820ca078",
   "metadata": {},
   "source": [
    "Save and load your vector store to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d1332b-a7ac-4a4b-a060-f2061599d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the vector store\n",
    "vector_store.save_index(\"my_zeusdb_index.zdb\")\n",
    "\n",
    "# Load the vector store\n",
    "loaded_store = ZeusDBVectorStore.load_index(\n",
    "    path=\"my_zeusdb_index.zdb\",\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(f\"Loaded store with {loaded_store.get_vector_count()} vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610cfe63-d4a8-4ef0-88a8-cf9cc3cbbfce",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901c75dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Usage for Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "For guides on how to use this vector store for retrieval-augmented generation (RAG), see the following sections:\n",
    "\n",
    "- [How-to: Question and answer with RAG](https://python.langchain.com/docs/how_to/#qa-with-rag)\n",
    "- [Retrieval conceptual docs](https://python.langchain.com/docs/concepts/retrieval/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
