"""
OpenAI –ø—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è AI –≤–∞–ª–∏–¥–∞—Ü–∏–∏
"""

import os
import requests
import json
from typing import List, Dict, Optional
from dotenv import load_dotenv
from .base import BaseAIProvider

load_dotenv()

class OpenAIProvider(BaseAIProvider):
    """–ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è OpenAI GPT –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = "gpt-3.5-turbo",
        base_url: str = "https://api.openai.com/v1",
        timeout: int = 30,
        temperature: float = 0.2,
        max_tokens: int = 2000
    ):
        super().__init__("openai", model)
        self.api_key = api_key or os.getenv("AI_TOKEN")
        self.base_url = base_url
        
        self.timeout = timeout
            
        self.temperature = temperature
        self.max_tokens = max_tokens
        
        if not self.api_key:
            raise ValueError(
                "OpenAI API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω. "
                "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é AI_TOKEN –∏–ª–∏ –ø–µ—Ä–µ–¥–∞–π—Ç–µ api_key –ø–∞—Ä–∞–º–µ—Ç—Ä"
            )
    
    def _make_request(self, messages: List[Dict[str, str]]) -> str:
        """–ó–∞–ø—Ä–æ—Å –∫ OpenAI API"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # –ë–∞–∑–æ–≤—ã–π payload
        payload = {
            "model": self.model,
            "messages": messages
        }
        
        # response_format –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
        if self._supports_json_format():
            payload["response_format"] = {"type": "json_object"}
        
        # –£–º–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö GPT –º–æ–¥–µ–ª–µ–π
        self._configure_model_params(payload)
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
        response = requests.post(
            f"{self.base_url}/chat/completions",
            headers=headers,
            json=payload,
            timeout=self.timeout
        )
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
        if response.status_code != 200:
            print(f"üö® OpenAI API Error {response.status_code}:")
            print(f"üì§ Model: {self.model}")
            print(f"üì• Response: {response.text[:500]}...")
        
        response.raise_for_status()
        data = response.json()
        
        return data["choices"][0]["message"]["content"].strip()
    
    def _configure_model_params(self, payload: dict):
        """–ü—Ä–æ—Å—Ç–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –≤—Å–µ—Ö GPT –º–æ–¥–µ–ª–µ–π"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
        payload["max_tokens"] = self.max_tokens
        payload["temperature"] = self.temperature
    
    def _supports_json_format(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–∏ –º–æ–¥–µ–ª—å response_format: json_object"""
        model = self.model.lower()
        
        # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç JSON format
        return any(x in model for x in ['turbo-1106', 'turbo-0125', 'gpt-4-turbo', 'gpt-4o', 'preview'])
