{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train this email search agent, click _Runtime_ and press _Run all_. Make sure you've enabled a free Tesla T4 GPU!\n",
    "\n",
    "<div class=\"align-center\">\n",
    "<a href=\"https://github.com/openpipe/art\"><img src=\"https://github.com/openpipe/art/raw/main/assets/ART_pill.png\" height=\"50\"></a>\n",
    "<a href=\"https://discord.gg/zbBHRUpwf4\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Discord_pill.png\" height=\"50\"></a>\n",
    "<a href=\"https://art.openpipe.ai\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Documentation_pill.png\" height=\"50\"></a>\n",
    "\n",
    "Questions? Join the Discord and ask away! For feature requests or to leave a star, visit our [Github](https://github.com/openpipe/art).\n",
    "\n",
    "</div>\n",
    "\n",
    "<a href=\"https://art.openpipe.ai/\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Header_separator.png\" height=\"5\"></a>\n",
    "\n",
    "**Email Search Agent**\n",
    "\n",
    "In this notebook, you will be using [ART](https://github.com/openpipe/art) to train your own ART•E agent from scratch! If you aren't familiar with ART•E, you can learn more about it in the [blog post](https://openpipe.ai/blog/art-e-mail-agent).\n",
    "\n",
    "Beginning with a Qwen 2.5 7B base model, you will train it to search through emails and answer questions about them. You will learn how to construct an [agentic environment](#Environment), how to define a [rollout](#Rollout), and how to run a [training loop](#Loop). You will also learn how to use [RULER](#ruler) to judge the quality of the agent's answers.\n",
    "\n",
    "**RULER**\n",
    "\n",
    "RULER is a robust technique for evaluating the quality of an agent's answers and training the agent to produce more of its best completions. To learn more about RULER, see the [RULER documentation](https://art.openpipe.ai/fundamentals/ruler).\n",
    "\n",
    "Now let's get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!uv pip install openpipe-art==0.4.7 vllm==0.9.2 langchain-core tenacity datasets \"gql<4\" --prerelease allow --no-cache-dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Environment-Variables\"></a>\n",
    "\n",
    "### Environment Variables\n",
    "\n",
    "**OpenAI (used for RULER judge model)**\n",
    "\n",
    "Our RULER reward function queries third-party models to judge the quality of the agent's performance. Any model supported by LiteLLM works. For this example we'll use OpenAI's o4-mini model, so we'll need to set the `OPENAI_API_KEY` environment variable.\n",
    "\n",
    "**Weights & Biases (optional)**\n",
    "\n",
    "Later on in the notebook, we'll be creating a model that can automatically logs metrics to Weights & Biases and chat completions to Weave. In order to do so, you'll need to provide your Weights & Biases API key as an environment variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Required\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\n",
    "        \"OPENAI_API_KEY is required for RULER functionality when using openai/o4-mini.\"\n",
    "    )\n",
    "\n",
    "# Optional\n",
    "# os.environ[\"WANDB_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "\n",
    "if not os.environ.get(\"WANDB_API_KEY\"):\n",
    "    print(\"WANDB_API_KEY is not set. We'll skip logging metrics to Weights & Biases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Environment\"></a>\n",
    "\n",
    "### Email Search Environment\n",
    "\n",
    "ART allows your agent to learn by interacting with its environment. In this example, we'll create an environment where the agent can search through emails and answer questions about them.\n",
    "\n",
    "The agent will have access to three tools:\n",
    "\n",
    "1. `search_inbox` - Search for emails by keywords\n",
    "2. `read_email` - Read a specific email by message ID\n",
    "3. `return_final_answer` - Return the final answer with source email IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train scenarios from Hugging Face...\n",
      "Loaded 50 scenarios.\n",
      "Email search environment created with full Enron dataset!\n",
      "Database contains the complete email dataset, loaded 50 training scenarios.\n",
      "\n",
      "Sample scenario\n",
      "id: 3296\n",
      "question: Who can I contact for Power Operations when Sally is in London?\n",
      "answer: Stacey White (x31870) and Leslie Reeves (x37962).\n",
      "message_ids: ['<6033065.1075856098960.JavaMail.evans@thyme>']\n",
      "how_realistic: 0.699999988079071\n",
      "inbox_address: louise.kitchen@enron.com\n",
      "query_date: 2001-01-25\n",
      "split: train\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import sqlite3\n",
    "from dataclasses import asdict, dataclass\n",
    "from datetime import datetime\n",
    "from textwrap import dedent\n",
    "from typing import List, Literal, Optional\n",
    "\n",
    "from datasets import Dataset, Features, Sequence, Value, load_dataset\n",
    "from pydantic import BaseModel, Field\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Email and Scenario data models\n",
    "class Email(BaseModel):\n",
    "    message_id: str\n",
    "    date: str  # ISO 8601 string 'YYYY-MM-DD HH:MM:SS'\n",
    "    subject: Optional[str] = None\n",
    "    from_address: Optional[str] = None\n",
    "    to_addresses: List[str] = []  # Populated from recipients table\n",
    "    cc_addresses: List[str] = []  # Populated from recipients table\n",
    "    bcc_addresses: List[str] = []  # Populated from recipients table\n",
    "    body: Optional[str] = None\n",
    "    file_name: Optional[str] = None\n",
    "\n",
    "\n",
    "class Scenario(BaseModel):\n",
    "    id: int\n",
    "    question: str\n",
    "    answer: str\n",
    "    message_ids: List[str]  # message_ids (strings) of referenced emails\n",
    "    how_realistic: float\n",
    "    inbox_address: str\n",
    "    query_date: str\n",
    "    split: Literal[\"train\", \"test\"]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    message_id: str\n",
    "    snippet: str\n",
    "\n",
    "\n",
    "class FinalAnswer(BaseModel):\n",
    "    answer: str\n",
    "    source_ids: list[str]\n",
    "\n",
    "\n",
    "# Database configuration\n",
    "DB_PATH = \"./enron_emails.db\"\n",
    "EMAIL_DATASET_REPO_ID = \"corbt/enron-emails\"\n",
    "SCENARIO_DATASET_REPO_ID = \"corbt/enron_emails_sample_questions\"\n",
    "\n",
    "# Global database connection\n",
    "db_conn = None\n",
    "\n",
    "\n",
    "def create_email_database():\n",
    "    \"\"\"Create the email database from Hugging Face dataset\"\"\"\n",
    "    print(\"Creating email database from Hugging Face dataset...\")\n",
    "    print(\n",
    "        \"This will download and process the full Enron email dataset - this may take several minutes...\"\n",
    "    )\n",
    "\n",
    "    # Database schema\n",
    "    SQL_CREATE_TABLES = \"\"\"\n",
    "    DROP TABLE IF EXISTS recipients;\n",
    "    DROP TABLE IF EXISTS emails_fts;\n",
    "    DROP TABLE IF EXISTS emails;\n",
    "\n",
    "    CREATE TABLE emails (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        message_id TEXT UNIQUE,\n",
    "        subject TEXT,\n",
    "        from_address TEXT,\n",
    "        date TEXT,\n",
    "        body TEXT,\n",
    "        file_name TEXT\n",
    "    );\n",
    "\n",
    "    CREATE TABLE recipients (\n",
    "        email_id TEXT,\n",
    "        recipient_address TEXT,\n",
    "        recipient_type TEXT\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    SQL_CREATE_INDEXES_TRIGGERS = \"\"\"\n",
    "    CREATE INDEX idx_emails_from ON emails(from_address);\n",
    "    CREATE INDEX idx_emails_date ON emails(date);\n",
    "    CREATE INDEX idx_emails_message_id ON emails(message_id);\n",
    "    CREATE INDEX idx_recipients_address ON recipients(recipient_address);\n",
    "    CREATE INDEX idx_recipients_type ON recipients(recipient_type);\n",
    "    CREATE INDEX idx_recipients_email_id ON recipients(email_id);\n",
    "    CREATE INDEX idx_recipients_address_email ON recipients(recipient_address, email_id);\n",
    "\n",
    "    CREATE VIRTUAL TABLE emails_fts USING fts5(\n",
    "        subject,\n",
    "        body,\n",
    "        content='emails',\n",
    "        content_rowid='id'\n",
    "    );\n",
    "\n",
    "    CREATE TRIGGER emails_ai AFTER INSERT ON emails BEGIN\n",
    "        INSERT INTO emails_fts (rowid, subject, body)\n",
    "        VALUES (new.id, new.subject, new.body);\n",
    "    END;\n",
    "\n",
    "    CREATE TRIGGER emails_ad AFTER DELETE ON emails BEGIN\n",
    "        DELETE FROM emails_fts WHERE rowid=old.id;\n",
    "    END;\n",
    "\n",
    "    CREATE TRIGGER emails_au AFTER UPDATE ON emails BEGIN\n",
    "        UPDATE emails_fts SET subject=new.subject, body=new.body WHERE rowid=old.id;\n",
    "    END;\n",
    "    \"\"\"\n",
    "\n",
    "    # Create database\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.executescript(SQL_CREATE_TABLES)\n",
    "    conn.commit()\n",
    "\n",
    "    # Load dataset\n",
    "    print(\"Loading full email dataset...\")\n",
    "    expected_features = Features(\n",
    "        {\n",
    "            \"message_id\": Value(\"string\"),\n",
    "            \"subject\": Value(\"string\"),\n",
    "            \"from\": Value(\"string\"),\n",
    "            \"to\": Sequence(Value(\"string\")),\n",
    "            \"cc\": Sequence(Value(\"string\")),\n",
    "            \"bcc\": Sequence(Value(\"string\")),\n",
    "            \"date\": Value(\"timestamp[us]\"),\n",
    "            \"body\": Value(\"string\"),\n",
    "            \"file_name\": Value(\"string\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    dataset = load_dataset(\n",
    "        EMAIL_DATASET_REPO_ID, features=expected_features, split=\"train\"\n",
    "    )\n",
    "    print(f\"Dataset contains {len(dataset)} total emails\")\n",
    "\n",
    "    # Populate database with ALL emails (not limited to 1000)\n",
    "    print(\"Populating database with all emails...\")\n",
    "    conn.execute(\"PRAGMA synchronous = OFF;\")\n",
    "    conn.execute(\"PRAGMA journal_mode = MEMORY;\")\n",
    "    conn.execute(\"BEGIN TRANSACTION;\")\n",
    "\n",
    "    record_count = 0\n",
    "    skipped_count = 0\n",
    "    duplicate_count = 0\n",
    "    processed_emails = set()  # Track (subject, body, from) tuples for deduplication\n",
    "\n",
    "    for email_data in tqdm(dataset, desc=\"Inserting emails\"):\n",
    "        message_id = email_data[\"message_id\"]\n",
    "        subject = email_data[\"subject\"]\n",
    "        from_address = email_data[\"from\"]\n",
    "        date_obj: datetime = email_data[\"date\"]\n",
    "        body = email_data[\"body\"]\n",
    "        file_name = email_data[\"file_name\"]\n",
    "        to_list = [str(addr) for addr in email_data[\"to\"] if addr]\n",
    "        cc_list = [str(addr) for addr in email_data[\"cc\"] if addr]\n",
    "        bcc_list = [str(addr) for addr in email_data[\"bcc\"] if addr]\n",
    "\n",
    "        # Apply the same filters as the original project\n",
    "        total_recipients = len(to_list) + len(cc_list) + len(bcc_list)\n",
    "\n",
    "        # Filter out very long emails and those with too many recipients\n",
    "        if len(body) > 5000:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        if total_recipients > 30:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        # Deduplication check (same as original project)\n",
    "        email_key = (subject, body, from_address)\n",
    "        if email_key in processed_emails:\n",
    "            duplicate_count += 1\n",
    "            continue\n",
    "        else:\n",
    "            processed_emails.add(email_key)\n",
    "\n",
    "        date_str = date_obj.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        cursor.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO emails (message_id, subject, from_address, date, body, file_name)\n",
    "            VALUES (?, ?, ?, ?, ?, ?)\n",
    "        \"\"\",\n",
    "            (message_id, subject, from_address, date_str, body, file_name),\n",
    "        )\n",
    "\n",
    "        # Insert recipients\n",
    "        recipient_data = []\n",
    "        for addr in to_list:\n",
    "            recipient_data.append((message_id, addr, \"to\"))\n",
    "        for addr in cc_list:\n",
    "            recipient_data.append((message_id, addr, \"cc\"))\n",
    "        for addr in bcc_list:\n",
    "            recipient_data.append((message_id, addr, \"bcc\"))\n",
    "\n",
    "        if recipient_data:\n",
    "            cursor.executemany(\n",
    "                \"\"\"\n",
    "                INSERT INTO recipients (email_id, recipient_address, recipient_type)\n",
    "                VALUES (?, ?, ?)\n",
    "            \"\"\",\n",
    "                recipient_data,\n",
    "            )\n",
    "\n",
    "        record_count += 1\n",
    "\n",
    "    conn.commit()\n",
    "\n",
    "    # Create indexes and triggers\n",
    "    print(\"Creating indexes and FTS...\")\n",
    "    cursor.executescript(SQL_CREATE_INDEXES_TRIGGERS)\n",
    "    cursor.execute('INSERT INTO emails_fts(emails_fts) VALUES(\"rebuild\")')\n",
    "    conn.commit()\n",
    "\n",
    "    print(f\"Successfully created database with {record_count} emails.\")\n",
    "    print(f\"Skipped {skipped_count} emails due to length/recipient limits.\")\n",
    "    print(f\"Skipped {duplicate_count} duplicate emails.\")\n",
    "    return conn\n",
    "\n",
    "\n",
    "def get_db_connection():\n",
    "    \"\"\"Get database connection\"\"\"\n",
    "    global db_conn\n",
    "    if db_conn is None:\n",
    "        if os.path.exists(DB_PATH):\n",
    "            print(f\"Loading existing database from {DB_PATH}\")\n",
    "            db_conn = sqlite3.connect(DB_PATH, check_same_thread=False)\n",
    "        else:\n",
    "            db_conn = create_email_database()\n",
    "    return db_conn\n",
    "\n",
    "\n",
    "def search_emails(\n",
    "    inbox: str,\n",
    "    keywords: List[str],\n",
    "    from_addr: Optional[str] = None,\n",
    "    to_addr: Optional[str] = None,\n",
    "    sent_after: Optional[str] = None,\n",
    "    sent_before: Optional[str] = None,\n",
    "    max_results: int = 10,\n",
    ") -> List[SearchResult]:\n",
    "    \"\"\"Search the email database based on keywords and filters\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    where_clauses: List[str] = []\n",
    "    params: List[str | int] = []\n",
    "\n",
    "    if not keywords:\n",
    "        raise ValueError(\"No keywords provided for search.\")\n",
    "\n",
    "    if max_results > 10:\n",
    "        raise ValueError(\"max_results must be less than or equal to 10.\")\n",
    "\n",
    "    # FTS5 default is AND, so just join keywords. Escape quotes for safety.\n",
    "    fts_query = \" \".join(f\"\"\" \"{k.replace('\"', '\"\"')}\" \"\"\" for k in keywords)\n",
    "    where_clauses.append(\"fts.emails_fts MATCH ?\")\n",
    "    params.append(fts_query)\n",
    "\n",
    "    # Inbox filter\n",
    "    where_clauses.append(\"\"\"\n",
    "        (e.from_address = ? OR EXISTS (\n",
    "            SELECT 1 FROM recipients r_inbox\n",
    "            WHERE r_inbox.recipient_address = ? AND r_inbox.email_id = e.message_id\n",
    "        ))\n",
    "    \"\"\")\n",
    "    params.extend([inbox, inbox])\n",
    "\n",
    "    if from_addr:\n",
    "        where_clauses.append(\"e.from_address = ?\")\n",
    "        params.append(from_addr)\n",
    "\n",
    "    if to_addr:\n",
    "        where_clauses.append(\"\"\"\n",
    "            EXISTS (\n",
    "                SELECT 1 FROM recipients r_to\n",
    "                WHERE r_to.recipient_address = ? AND r_to.email_id = e.message_id\n",
    "            )\n",
    "        \"\"\")\n",
    "        params.append(to_addr)\n",
    "\n",
    "    if sent_after:\n",
    "        where_clauses.append(\"e.date >= ?\")\n",
    "        params.append(f\"{sent_after} 00:00:00\")\n",
    "\n",
    "    if sent_before:\n",
    "        where_clauses.append(\"e.date < ?\")\n",
    "        params.append(f\"{sent_before} 00:00:00\")\n",
    "\n",
    "    sql = f\"\"\"\n",
    "        SELECT\n",
    "            e.message_id,\n",
    "            snippet(emails_fts, -1, '<b>', '</b>', ' ... ', 15) as snippet\n",
    "        FROM\n",
    "            emails e JOIN emails_fts fts ON e.id = fts.rowid\n",
    "        WHERE\n",
    "            {\" AND \".join(where_clauses)}\n",
    "        ORDER BY\n",
    "            e.date DESC\n",
    "        LIMIT ?;\n",
    "    \"\"\"\n",
    "    params.append(max_results)\n",
    "\n",
    "    cursor.execute(sql, params)\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "    return [SearchResult(message_id=row[0], snippet=row[1]) for row in results]\n",
    "\n",
    "\n",
    "def read_email(message_id: str) -> Optional[Email]:\n",
    "    \"\"\"Retrieve a single email by its message_id\"\"\"\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Get email details\n",
    "    cursor.execute(\n",
    "        \"SELECT message_id, date, subject, from_address, body, file_name FROM emails WHERE message_id = ?\",\n",
    "        (message_id,),\n",
    "    )\n",
    "    email_row = cursor.fetchone()\n",
    "\n",
    "    if not email_row:\n",
    "        return None\n",
    "\n",
    "    msg_id, date, subject, from_addr, body, file_name = email_row\n",
    "\n",
    "    # Get recipients\n",
    "    cursor.execute(\n",
    "        \"SELECT recipient_address, recipient_type FROM recipients WHERE email_id = ?\",\n",
    "        (message_id,),\n",
    "    )\n",
    "    recipient_rows = cursor.fetchall()\n",
    "\n",
    "    to_addresses = []\n",
    "    cc_addresses = []\n",
    "    bcc_addresses = []\n",
    "\n",
    "    for addr, type_val in recipient_rows:\n",
    "        if type_val.lower() == \"to\":\n",
    "            to_addresses.append(addr)\n",
    "        elif type_val.lower() == \"cc\":\n",
    "            cc_addresses.append(addr)\n",
    "        elif type_val.lower() == \"bcc\":\n",
    "            bcc_addresses.append(addr)\n",
    "\n",
    "    return Email(\n",
    "        message_id=msg_id,\n",
    "        date=date,\n",
    "        subject=subject,\n",
    "        from_address=from_addr,\n",
    "        to_addresses=to_addresses,\n",
    "        cc_addresses=cc_addresses,\n",
    "        bcc_addresses=bcc_addresses,\n",
    "        body=body,\n",
    "        file_name=file_name,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_training_scenarios(\n",
    "    split: Literal[\"train\", \"test\"] = \"train\",\n",
    "    limit: Optional[int] = None,\n",
    "    max_messages: Optional[int] = 1,\n",
    "    shuffle: bool = False,\n",
    "    seed: Optional[int] = None,\n",
    ") -> List[Scenario]:\n",
    "    \"\"\"Load training scenarios from Hugging Face dataset\"\"\"\n",
    "    print(f\"Loading {split} scenarios from Hugging Face...\")\n",
    "    dataset: Dataset = load_dataset(SCENARIO_DATASET_REPO_ID, split=split)\n",
    "\n",
    "    if max_messages is not None:\n",
    "        dataset = dataset.filter(lambda x: len(x[\"message_ids\"]) <= max_messages)\n",
    "\n",
    "    if shuffle or (seed is not None):\n",
    "        if seed is not None:\n",
    "            dataset = dataset.shuffle(seed=seed)\n",
    "        else:\n",
    "            dataset = dataset.shuffle()\n",
    "\n",
    "    # Convert each row to a Scenario object\n",
    "    scenarios = [Scenario(**row, split=split) for row in dataset]\n",
    "\n",
    "    if max_messages is not None:\n",
    "        scenarios = [s for s in scenarios if len(s.message_ids) <= max_messages]\n",
    "\n",
    "    if shuffle:\n",
    "        if seed is not None:\n",
    "            rng = random.Random(seed)\n",
    "            rng.shuffle(scenarios)\n",
    "        else:\n",
    "            random.shuffle(scenarios)\n",
    "\n",
    "    if limit is not None:\n",
    "        scenarios = scenarios[:limit]\n",
    "\n",
    "    print(f\"Loaded {len(scenarios)} scenarios.\")\n",
    "    return scenarios\n",
    "\n",
    "\n",
    "# Load training scenarios\n",
    "training_scenarios = load_training_scenarios(\n",
    "    split=\"train\", limit=50, max_messages=1, shuffle=True, seed=42\n",
    ")\n",
    "\n",
    "print(\"Email search environment created with full Enron dataset!\")\n",
    "print(\n",
    "    f\"Database contains the complete email dataset, loaded {len(training_scenarios)} training scenarios.\"\n",
    ")\n",
    "\n",
    "# print first scenario\n",
    "print(\"\\nSample scenario\")\n",
    "print(\"id:\", training_scenarios[0].id)\n",
    "print(\"question:\", training_scenarios[0].question)\n",
    "print(\"answer:\", training_scenarios[0].answer)\n",
    "print(\"message_ids:\", training_scenarios[0].message_ids)\n",
    "print(\"how_realistic:\", training_scenarios[0].how_realistic)\n",
    "print(\"inbox_address:\", training_scenarios[0].inbox_address)\n",
    "print(\"query_date:\", training_scenarios[0].query_date)\n",
    "print(\"split:\", training_scenarios[0].split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Model\n",
    "\n",
    "Now that we've defined the rules of our environment, we can create a model that will learn to search emails effectively. We'll use a Qwen 2.5 7B model for this example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import art\n",
    "from art.local import LocalBackend\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Declare the model\n",
    "model = art.TrainableModel(\n",
    "    name=\"email-agent-001\",\n",
    "    project=\"email-search-agent\",\n",
    "    base_model=\"Qwen/Qwen2.5-7B-Instruct\",\n",
    ")\n",
    "\n",
    "# To run on a T4, we need to override some config defaults.\n",
    "if torch.cuda.get_device_properties(0).major < 8:\n",
    "    model._internal_config = art.dev.InternalModelConfig(\n",
    "        init_args=art.dev.InitArgs(\n",
    "            max_seq_length=8192,\n",
    "        ),\n",
    "        engine_args=art.dev.EngineArgs(\n",
    "            enforce_eager=True,\n",
    "            gpu_memory_utilization=0.8,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "# Initialize the server\n",
    "backend = LocalBackend(\n",
    "    # Normally we don't want to run the server in-process, but for the output\n",
    "    # to show up properly on Google Colab we'll enable this.\n",
    "    in_process=True,\n",
    "    path=\"./.art\",\n",
    ")\n",
    "\n",
    "# Register the model with the local Backend (sets up logging, inference, and training)\n",
    "await model.register(backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Rollout\"></a>\n",
    "\n",
    "### Defining a Rollout\n",
    "\n",
    "A rollout is a single episode of an agent performing its task. In this example, the rollout function presents the agent with an email search scenario, and the agent uses the available tools to search for emails and answer the question.\n",
    "\n",
    "When the agent provides a final answer, the `correct` metric is calculated based on whether the answer is correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from litellm import acompletion\n",
    "from tenacity import retry, stop_after_attempt\n",
    "\n",
    "import art\n",
    "from art.utils.litellm import convert_litellm_choice_to_openai\n",
    "\n",
    "if os.getenv(\"WANDB_API_KEY\", \"\"):\n",
    "    weave.init(model.project, settings={\"print_call_link\": False})\n",
    "\n",
    "MAX_TURNS = 10\n",
    "\n",
    "\n",
    "class CorrectnessJudgeResponse(BaseModel):\n",
    "    reasoning: str = Field(description=\"Explanation of the reasoning process.\")\n",
    "    accept: bool = Field(description=\"Whether the AI answer should be accepted.\")\n",
    "\n",
    "\n",
    "@retry(stop=stop_after_attempt(3))\n",
    "async def judge_correctness(\n",
    "    scenario: Scenario, answer: str\n",
    ") -> CorrectnessJudgeResponse:\n",
    "    system_prompt = dedent(\n",
    "        \"\"\"\n",
    "        You are given a question, the reference answer (labelled **Reference answer**), and an answer generated by an AI assistant (labelled **AI answer**).\n",
    "\n",
    "        Your task is to decide whether the AI answer is correct and should be accepted. You should accept the answer if it contains the relevant information from the reference answer. You should not accept the answer if it is missing information relevant to the question, or if it contradicts the reference answer.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"Question: {scenario.question}\\n\"\n",
    "                f\"Reference answer: {scenario.answer}\\n\"\n",
    "                f\"AI answer: {answer}\"\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    response = await acompletion(\n",
    "        model=\"openai/gpt-4.1\",\n",
    "        messages=messages,\n",
    "        response_format=CorrectnessJudgeResponse,\n",
    "    )\n",
    "\n",
    "    first_choice = response.choices[0]\n",
    "    raw_content = first_choice.message.content or \"{}\"\n",
    "\n",
    "    try:\n",
    "        return CorrectnessJudgeResponse.model_validate_json(raw_content)\n",
    "    except Exception as e:\n",
    "        return CorrectnessJudgeResponse(\n",
    "            reasoning=f\"Parse error: {e}\\nRaw: {raw_content}\", accept=False\n",
    "        )\n",
    "\n",
    "\n",
    "class ProjectTrajectory(art.Trajectory):\n",
    "    final_answer: FinalAnswer | None = None\n",
    "\n",
    "\n",
    "class EmailScenario(BaseModel):\n",
    "    step: int\n",
    "    scenario: Scenario\n",
    "\n",
    "\n",
    "@weave.op\n",
    "async def rollout(model: art.Model, email_scenario: EmailScenario) -> ProjectTrajectory:\n",
    "    scenario = email_scenario.scenario\n",
    "\n",
    "    traj = ProjectTrajectory(\n",
    "        reward=0.0,\n",
    "        messages_and_choices=[],\n",
    "        metadata={\n",
    "            \"scenario_id\": scenario.id,\n",
    "            \"step\": email_scenario.step,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    system_prompt = dedent(\n",
    "        f\"\"\"\n",
    "        You are an email search agent. You are given a user query and a list of tools you can use to search the user's email. Use the tools to search the user's emails and find the answer to the user's query. You may take up to {MAX_TURNS} turns to find the answer, so if your first search doesn't find the answer, you can try with different keywords.\n",
    "\n",
    "        User's email address is {scenario.inbox_address}\n",
    "        Today's date is {scenario.query_date}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    traj.messages_and_choices = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": scenario.question},\n",
    "    ]\n",
    "\n",
    "    def search_inbox(keywords: list[str]) -> list[dict]:\n",
    "        \"\"\"Search the inbox for emails matching the given keywords and return\n",
    "        a list of dictionaries so the LLM can easily consume them.\"\"\"\n",
    "        results = search_emails(\n",
    "            inbox=scenario.inbox_address,\n",
    "            keywords=keywords,\n",
    "            sent_before=scenario.query_date,\n",
    "        )\n",
    "        return [asdict(result) for result in results]\n",
    "\n",
    "    def return_final_answer(\n",
    "        answer: str, reference_message_ids: list[str]\n",
    "    ) -> FinalAnswer:\n",
    "        \"\"\"Return the final answer and the message IDs of the emails that were used to generate the answer.\"\"\"\n",
    "        return FinalAnswer(answer=answer, source_ids=reference_message_ids)\n",
    "\n",
    "    tools = [search_inbox, read_email, return_final_answer]\n",
    "    tools_by_name = {t.__name__: t for t in tools}\n",
    "    traj.tools = [convert_to_openai_tool(t) for t in tools]\n",
    "\n",
    "    if model.trainable:\n",
    "        litellm_model_name = f\"hosted_vllm/{model.name}\"\n",
    "    else:\n",
    "        litellm_model_name = model.name\n",
    "\n",
    "    for _ in range(MAX_TURNS):\n",
    "        response = await acompletion(\n",
    "            model=litellm_model_name,\n",
    "            base_url=model.inference_base_url,\n",
    "            api_key=model.inference_api_key,\n",
    "            temperature=1,\n",
    "            messages=traj.messages(),\n",
    "            caching=False,\n",
    "            tools=traj.tools,\n",
    "        )\n",
    "\n",
    "        response_message = response.choices[0].message\n",
    "        traj.messages_and_choices.append(\n",
    "            convert_litellm_choice_to_openai(response.choices[0])\n",
    "        )\n",
    "\n",
    "        if not response_message.tool_calls:\n",
    "            return traj\n",
    "\n",
    "        try:\n",
    "            for tool_call in response_message.tool_calls:\n",
    "                tool_name: str = tool_call.function.name\n",
    "                if tool_name in tools_by_name:\n",
    "                    tool_args = json.loads(tool_call.function.arguments)\n",
    "                    tool_to_call = tools_by_name[tool_name]\n",
    "                    result = tool_to_call(**tool_args)\n",
    "                    traj.messages_and_choices.append(\n",
    "                        {\n",
    "                            \"role\": \"tool\",\n",
    "                            \"tool_call_id\": tool_call.id,\n",
    "                            \"name\": tool_name,\n",
    "                            \"content\": str(result),\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    if tool_name == \"return_final_answer\":\n",
    "                        traj.final_answer = result\n",
    "                        # Score the trajectory\n",
    "                        if traj.final_answer:\n",
    "                            correctness_judge_response = await judge_correctness(\n",
    "                                scenario, traj.final_answer.answer\n",
    "                            )\n",
    "                            traj.metrics[\"correct\"] = float(\n",
    "                                correctness_judge_response.accept\n",
    "                            )\n",
    "                        return traj\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing tool calls: {e}\")\n",
    "            return traj\n",
    "\n",
    "    return traj\n",
    "\n",
    "\n",
    "print(\"Rollout function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"ruler\"></a>\n",
    "\n",
    "### How RULER works\n",
    "\n",
    "**RULER** leverages two key insights:\n",
    "\n",
    "1. Relative scoring is easier than absolute scoring: It's easier for an LLM to rank several solutions relative to each other than to score them in isolation\n",
    "2. GRPO only needs relative scores: Since GRPO normalizes scores within each group, only the relative rankings matter, not absolute values\n",
    "\n",
    "The process:\n",
    "\n",
    "1. Generate N trajectories for a given scenario\n",
    "2. Pass all N trajectories to **RULER**\n",
    "3. **RULER** deduplicates common prefixes (e.g., identical system messages)\n",
    "4. An LLM judge scores each trajectory from 0 to 1 based on goal achievement\n",
    "5. These scores are used directly as rewards in GRPO training\n",
    "\n",
    "To learn more about **RULER**, check out the [RULER docs](https://art.openpipe.ai/fundamentals/ruler).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\">[</span>RULER<span style=\"font-weight: bold\">]</span> Pretty-printed LLM choice JSON:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m[\u001b[0mRULER\u001b[1m]\u001b[0m Pretty-printed LLM choice JSON:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'scores'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'trajectory_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'explanation'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Correctly counts to 10 using numeric symbols as specified by the system.'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'trajectory_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'explanation'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Counts to 10 but uses words instead of numeric symbols, so partially meets the goal.'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'trajectory_id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'3'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'explanation'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Does not count numbers at all, listing letters instead.'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'scores'\u001b[0m: \u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'trajectory_id'\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
       "            \u001b[32m'explanation'\u001b[0m: \u001b[32m'Correctly counts to 10 using numeric symbols as specified by the system.'\u001b[0m,\n",
       "            \u001b[32m'score'\u001b[0m: \u001b[1;36m1.0\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'trajectory_id'\u001b[0m: \u001b[32m'2'\u001b[0m,\n",
       "            \u001b[32m'explanation'\u001b[0m: \u001b[32m'Counts to 10 but uses words instead of numeric symbols, so partially meets the goal.'\u001b[0m,\n",
       "            \u001b[32m'score'\u001b[0m: \u001b[1;36m0.5\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'trajectory_id'\u001b[0m: \u001b[32m'3'\u001b[0m,\n",
       "            \u001b[32m'explanation'\u001b[0m: \u001b[32m'Does not count numbers at all, listing letters instead.'\u001b[0m,\n",
       "            \u001b[32m'score'\u001b[0m: \u001b[1;36m0.0\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rank 1: Score 1.000\n",
      "  Response: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10...\n",
      "\n",
      "Rank 2: Score 0.500\n",
      "  Response: one, two, three, four, five, six, seven, eight, ni...\n",
      "\n",
      "Rank 3: Score 0.000\n",
      "  Response: a, b, c, d, e, f, g, h, i, j...\n"
     ]
    }
   ],
   "source": [
    "import art\n",
    "from art.rewards import ruler_score_group\n",
    "\n",
    "# Test RULER with a simple example\n",
    "base_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You count numbers using numeric symbols.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Count to 10.\"},\n",
    "]\n",
    "\n",
    "good_trajectory = art.Trajectory(\n",
    "    messages_and_choices=[\n",
    "        *base_messages,\n",
    "        {\"role\": \"assistant\", \"content\": \"1, 2, 3, 4, 5, 6, 7, 8, 9, 10\"},\n",
    "    ],\n",
    "    reward=0,\n",
    ")\n",
    "\n",
    "mediocre_trajectory = art.Trajectory(\n",
    "    messages_and_choices=[\n",
    "        *base_messages,\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"one, two, three, four, five, six, seven, eight, nine, ten\",\n",
    "        },\n",
    "    ],\n",
    "    reward=0,\n",
    ")\n",
    "\n",
    "bad_trajectory = art.Trajectory(\n",
    "    messages_and_choices=[\n",
    "        *base_messages,\n",
    "        {\"role\": \"assistant\", \"content\": \"a, b, c, d, e, f, g, h, i, j\"},\n",
    "    ],\n",
    "    reward=0,\n",
    ")\n",
    "\n",
    "sample_group = art.TrajectoryGroup(\n",
    "    trajectories=[\n",
    "        good_trajectory,\n",
    "        mediocre_trajectory,\n",
    "        bad_trajectory,\n",
    "    ]\n",
    ")\n",
    "\n",
    "judged_group = await ruler_score_group(sample_group, \"openai/o4-mini\", debug=True)\n",
    "assert judged_group is not None\n",
    "\n",
    "# Display rankings\n",
    "sorted_trajectories = sorted(\n",
    "    judged_group.trajectories, key=lambda t: t.reward, reverse=True\n",
    ")\n",
    "for rank, traj in enumerate(sorted_trajectories, 1):\n",
    "    messages = traj.messages()\n",
    "    print(f\"\\nRank {rank}: Score {traj.reward:.3f}\")\n",
    "    print(f\"  Response: {messages[-1]['content'][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"Loop\"></a>\n",
    "\n",
    "### Training Loop\n",
    "\n",
    "The training loop is where the magic happens. For each of the 10 steps defined below, the rollout function will be called multiple times in parallel. Each scenario will produce a trajectory, which will be used to update the model.\n",
    "\n",
    "The `gather` step will wait for all of the trajectories to be generated, then it will use RULER to assign relative scores to each trajectory.\n",
    "\n",
    "Our notebook will then delete all but the most recent checkpoint and train the model on the scored trajectories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "from art.utils import iterate_dataset\n",
    "\n",
    "training_config = {\n",
    "    \"groups_per_step\": 2,\n",
    "    \"num_epochs\": 20,\n",
    "    \"rollouts_per_group\": 4,\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"max_steps\": 20,\n",
    "}\n",
    "\n",
    "# Use iterate_dataset with real training scenarios (similar to train.py)\n",
    "training_iterator = iterate_dataset(\n",
    "    training_scenarios,  # Use real scenarios from Hugging Face\n",
    "    groups_per_step=training_config[\"groups_per_step\"],\n",
    "    num_epochs=training_config[\"num_epochs\"],\n",
    "    initial_step=await model.get_step(),\n",
    ")\n",
    "\n",
    "for batch in training_iterator:\n",
    "    print(\n",
    "        f\"Training step {batch.step}, epoch {batch.epoch}, epoch step {batch.epoch_step}\"\n",
    "    )\n",
    "    print(f\"Batch contains {len(batch.items)} scenarios\")\n",
    "\n",
    "    # Create trajectory groups for this batch (similar to train.py)\n",
    "    groups = []\n",
    "    for scenario in batch.items:\n",
    "        groups.append(\n",
    "            art.TrajectoryGroup(\n",
    "                (\n",
    "                    rollout(model, EmailScenario(step=batch.step, scenario=scenario))\n",
    "                    for _ in range(training_config[\"rollouts_per_group\"])\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Gather all trajectory groups\n",
    "    finished_groups = await art.gather_trajectory_groups(\n",
    "        groups,\n",
    "        pbar_desc=\"gather\",\n",
    "        max_exceptions=training_config[\"rollouts_per_group\"] * len(batch.items),\n",
    "    )\n",
    "\n",
    "    judged_groups = []\n",
    "    for group in finished_groups:\n",
    "        # Use RULER to assign relative scores to each trajectory\n",
    "        judged_group = await ruler_score_group(group, \"openai/o4-mini\", debug=True)\n",
    "        judged_groups.append(judged_group)\n",
    "\n",
    "    await model.delete_checkpoints()\n",
    "    await model.train(\n",
    "        judged_groups,\n",
    "        config=art.TrainConfig(learning_rate=training_config[\"learning_rate\"]),\n",
    "        # Lowering the logprob_calculation_chunk_size is a memory saving measure\n",
    "        # to allow longer sequences (up to 8192 tokens) to be processed on a T4.\n",
    "        _config={\"logprob_calculation_chunk_size\": 8},\n",
    "    )\n",
    "\n",
    "    print(f\"Completed training step {batch.step}\")\n",
    "\n",
    "    # Stop after max_steps for demo purposes (adjust as needed)\n",
    "    if batch.step >= training_config[\"max_steps\"]:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Model\n",
    "\n",
    "Just like that, you've trained an agent to search emails and answer questions! Now it's time to use your model outside of the training loop.\n",
    "\n",
    "Check out the code below for a small demo of the model you just trained!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model using the rollout function\n",
    "# This avoids memory issues and uses the same inference path as training\n",
    "\n",
    "print(\"Testing the trained model with a real scenario...\\n\")\n",
    "\n",
    "\n",
    "# Use a scenario from our training set\n",
    "test_scenario = training_scenarios[1]\n",
    "\n",
    "print(f\"Test scenario ID: {test_scenario.id}\")\n",
    "print(f\"Question: {test_scenario.question}\")\n",
    "print(f\"Expected answer: {test_scenario.answer}\")\n",
    "print(f\"Reference message IDs: {test_scenario.message_ids}\")\n",
    "print(f\"Inbox: {test_scenario.inbox_address}\")\n",
    "print(f\"Query date: {test_scenario.query_date}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Run the rollout function with the trained model\n",
    "test_email_scenario = EmailScenario.model_validate(\n",
    "    {\"step\": 0, \"scenario\": test_scenario.model_dump()}\n",
    ")\n",
    "result_trajectory = await rollout(model, test_email_scenario)\n",
    "\n",
    "print(\"Agent's trajectory:\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# Display the conversation\n",
    "messages = result_trajectory.messages()\n",
    "for i, msg in enumerate(messages):\n",
    "    role = msg.get(\"role\", \"unknown\")\n",
    "    content = msg.get(\"content\", \"\")\n",
    "    tool_calls = msg.get(\"tool_calls\", [])\n",
    "\n",
    "    if role == \"system\":\n",
    "        print(\n",
    "            f\"[SYSTEM]: {content[:100]}...\"\n",
    "            if len(content) > 100\n",
    "            else f\"[SYSTEM]: {content}\"\n",
    "        )\n",
    "    elif role == \"user\":\n",
    "        print(f\"[USER]: {content}\")\n",
    "    elif role == \"assistant\":\n",
    "        if tool_calls:\n",
    "            print(f\"[ASSISTANT]: {tool_calls}\")\n",
    "        if content:\n",
    "            print(f\"[ASSISTANT]: {content}\")\n",
    "    elif role == \"tool\":\n",
    "        tool_name = msg.get(\"name\", \"unknown_tool\")\n",
    "        print(\n",
    "            f\"[TOOL - {tool_name}]: {content[:200]}...\"\n",
    "            if len(content) > 200\n",
    "            else f\"[TOOL - {tool_name}]: {content}\"\n",
    "        )\n",
    "\n",
    "    print()\n",
    "\n",
    "print(\"-\" * 50)\n",
    "if result_trajectory.final_answer:\n",
    "    print(f\"Agent's Final Answer: {result_trajectory.final_answer.answer}\")\n",
    "    print(f\"Source IDs Used: {result_trajectory.final_answer.source_ids}\")\n",
    "else:\n",
    "    print(\"No final answer provided by the agent\")\n",
    "\n",
    "print(f\"\\nExpected Answer: {test_scenario.answer}\")\n",
    "print(f\"Expected Source IDs: {test_scenario.message_ids}\")\n",
    "\n",
    "print(\"\\n🎉 Email search agent testing completed!\")\n",
    "print(\n",
    "    \"The agent used the same inference path as during training, avoiding memory issues.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"align-center\">\n",
    "<a href=\"https://github.com/openpipe/art\"><img src=\"https://github.com/openpipe/art/raw/main/assets/ART_pill.png\" height=\"50\"></a>\n",
    "<a href=\"https://discord.gg/zbBHRUpwf4\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Discord_pill.png\" height=\"50\"></a>\n",
    "<a href=\"https://art.openpipe.ai\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Documentation_pill.png\" height=\"50\"></a>\n",
    "\n",
    "Questions? Join the Discord and ask away! For feature requests or to leave a star, visit our [Github](https://github.com/openpipe/art).\n",
    "\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
