"""
Performance Optimizer (RFS v4)

RFS v4 ì„±ëŠ¥ ìµœì í™” ë©”ì¸ ì—”ì§„
- ìë™ ì„±ëŠ¥ ë¶„ì„
- ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±
- ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- ìë™ íŠœë‹ ì‹¤í–‰
"""

import asyncio
import time
import gc
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime
import json
import psutil
import threading

try:
    from rich.console import Console
    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn
    from rich.panel import Panel
    from rich.table import Table
    from rich.live import Live
    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False

from ..core import Result, Success, Failure

if RICH_AVAILABLE:
    console = Console()
else:
    console = None


class OptimizationType(Enum):
    """ìµœì í™” ìœ í˜•"""
    MEMORY = "memory"
    CPU = "cpu"
    IO = "io"
    NETWORK = "network"
    STARTUP = "startup"
    RUNTIME = "runtime"
    CLOUD_RUN = "cloud_run"


class OptimizationCategory(Enum):
    """ìµœì í™” ì¹´í…Œê³ ë¦¬"""
    PERFORMANCE = "performance"
    SCALABILITY = "scalability"
    RELIABILITY = "reliability"
    EFFICIENCY = "efficiency"


class OptimizationPriority(Enum):
    """ìµœì í™” ìš°ì„ ìˆœìœ„"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"


@dataclass
class OptimizationResult:
    """ìµœì í™” ê²°ê³¼"""
    optimization_type: OptimizationType
    name: str
    description: str
    priority: OptimizationPriority
    impact_score: float  # 0-100
    implementation_difficulty: int  # 1-5 (1: ì‰¬ì›€, 5: ì–´ë ¤ì›€)
    estimated_improvement: str
    before_metrics: Dict[str, Any] = field(default_factory=dict)
    after_metrics: Dict[str, Any] = field(default_factory=dict)
    recommendations: List[str] = field(default_factory=list)
    code_changes: List[Dict[str, str]] = field(default_factory=list)
    applied: bool = False
    
    @property
    def roi_score(self) -> float:
        """íˆ¬ì ëŒ€ë¹„ íš¨ê³¼ ì ìˆ˜ ê³„ì‚°"""
        if self.implementation_difficulty == 0:
            return 0
        return self.impact_score / self.implementation_difficulty


@dataclass
class OptimizationSuite:
    """ìµœì í™” ìŠ¤ìœ„íŠ¸"""
    name: str
    target_types: List[OptimizationType] = field(default_factory=list)
    auto_apply: bool = False
    max_impact_threshold: float = 50.0  # ìë™ ì ìš© ì„ê³„ê°’
    include_experimental: bool = False
    timeout: int = 300


class PerformanceOptimizer:
    """ì„±ëŠ¥ ìµœì í™” ë©”ì¸ ì—”ì§„"""
    
    def __init__(self, project_path: Optional[str] = None):
        self.project_path = Path(project_path) if project_path else Path.cwd()
        self.optimization_results: List[OptimizationResult] = []
        self.baseline_metrics: Dict[str, Any] = {}
        self.monitoring_active = False
        self.monitoring_task: Optional[asyncio.Task] = None
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì´í„°
        self.performance_history: List[Dict[str, Any]] = []
        self.max_history_size = 1000
    
    async def run_optimization_analysis(self, suite: OptimizationSuite) -> Result[List[OptimizationResult], str]:
        """ìµœì í™” ë¶„ì„ ì‹¤í–‰"""
        try:
            if console:
                console.print(Panel(
                    f"ğŸš€ RFS v4 ì„±ëŠ¥ ìµœì í™” ë¶„ì„ ì‹œì‘\n\n"
                    f"ğŸ“‹ ìµœì í™” ìŠ¤ìœ„íŠ¸: {suite.name}\n"
                    f"ğŸ¯ ëŒ€ìƒ ìœ í˜•: {', '.join([t.value for t in suite.target_types]) if suite.target_types else 'ëª¨ë“  ìœ í˜•'}\n"
                    f"âš¡ ìë™ ì ìš©: {'ì˜ˆ' if suite.auto_apply else 'ì•„ë‹ˆì˜¤'}\n"
                    f"ğŸ§ª ì‹¤í—˜ì  ê¸°ëŠ¥: {'í¬í•¨' if suite.include_experimental else 'ì œì™¸'}",
                    title="ì„±ëŠ¥ ìµœì í™”",
                    border_style="blue"
                ))
            
            # ê¸°ì¤€ ì„±ëŠ¥ ì¸¡ì •
            if console:
                console.print("ğŸ“Š ê¸°ì¤€ ì„±ëŠ¥ ì¸¡ì • ì¤‘...")
            
            await self._measure_baseline_performance()
            
            # ìµœì í™” ë¶„ì„ ì‹¤í–‰
            optimization_tasks = []
            
            if not suite.target_types or OptimizationType.MEMORY in suite.target_types:
                optimization_tasks.append(self._analyze_memory_optimization(suite))
            
            if not suite.target_types or OptimizationType.CPU in suite.target_types:
                optimization_tasks.append(self._analyze_cpu_optimization(suite))
            
            if not suite.target_types or OptimizationType.IO in suite.target_types:
                optimization_tasks.append(self._analyze_io_optimization(suite))
            
            if not suite.target_types or OptimizationType.STARTUP in suite.target_types:
                optimization_tasks.append(self._analyze_startup_optimization(suite))
            
            if not suite.target_types or OptimizationType.CLOUD_RUN in suite.target_types:
                optimization_tasks.append(self._analyze_cloud_run_optimization(suite))
            
            # ë³‘ë ¬ ë¶„ì„ ì‹¤í–‰
            with Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                BarColumn(),
                console=console
            ) as progress:
                
                for i, task in enumerate(optimization_tasks):
                    task_id = progress.add_task(f"ìµœì í™” ë¶„ì„ {i+1}/{len(optimization_tasks)}", total=100)
                    
                    results = await task
                    if results:
                        self.optimization_results.extend(results)
                    
                    progress.update(task_id, completed=100)
            
            # ê²°ê³¼ ìš°ì„ ìˆœìœ„ ì •ë ¬
            self.optimization_results.sort(key=lambda x: x.roi_score, reverse=True)
            
            # ìë™ ì ìš©
            if suite.auto_apply:
                await self._apply_safe_optimizations(suite)
            
            # ê²°ê³¼ í‘œì‹œ
            if console:
                await self._display_optimization_results()
            
            return Success(self.optimization_results)
            
        except Exception as e:
            return Failure(f"ìµœì í™” ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
    
    async def _measure_baseline_performance(self):
        """ê¸°ì¤€ ì„±ëŠ¥ ì¸¡ì •"""
        try:
            import time
            import psutil
            import os
            
            process = psutil.Process(os.getpid())
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            memory_info = process.memory_info()
            
            # CPU ì‚¬ìš©ëŸ‰ (1ì´ˆê°„ ì¸¡ì •)
            cpu_percent = process.cpu_percent(interval=1)
            
            # ëª¨ë“ˆ ì„í¬íŠ¸ ì‹œê°„ ì¸¡ì •
            start_time = time.time()
            try:
                from .. import core
                import_time = time.time() - start_time
            except:
                import_time = 0
            
            # GC í†µê³„
            gc_stats = {
                f"generation_{i}": gc.get_stats()[i] if i < len(gc.get_stats()) else {}
                for i in range(3)
            }
            
            self.baseline_metrics = {
                'timestamp': datetime.now().isoformat(),
                'memory': {
                    'rss': memory_info.rss,
                    'vms': memory_info.vms,
                    'rss_mb': memory_info.rss / 1024 / 1024,
                    'vms_mb': memory_info.vms / 1024 / 1024
                },
                'cpu': {
                    'percent': cpu_percent,
                    'num_threads': process.num_threads()
                },
                'startup': {
                    'import_time': import_time
                },
                'gc': gc_stats,
                'system': {
                    'python_version': sys.version,
                    'platform': sys.platform
                }
            }
            
        except Exception as e:
            if console:
                console.print(f"âš ï¸  ê¸°ì¤€ ì„±ëŠ¥ ì¸¡ì • ì‹¤íŒ¨: {str(e)}", style="yellow")
            self.baseline_metrics = {}
    
    async def _analyze_memory_optimization(self, suite: OptimizationSuite) -> List[OptimizationResult]:
        """ë©”ëª¨ë¦¬ ìµœì í™” ë¶„ì„"""
        results = []
        
        try:
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
            if 'memory' in self.baseline_metrics:
                memory_mb = self.baseline_metrics['memory']['rss_mb']
                
                if memory_mb > 100:  # 100MB ì´ìƒ
                    results.append(OptimizationResult(
                        optimization_type=OptimizationType.MEMORY,
                        name="ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”",
                        description="ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤",
                        priority=OptimizationPriority.HIGH,
                        impact_score=70.0,
                        implementation_difficulty=3,
                        estimated_improvement="30-50% ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ",
                        before_metrics={'memory_mb': memory_mb},
                        recommendations=[
                            "ë¶ˆí•„ìš”í•œ ì „ì—­ ë³€ìˆ˜ ì œê±°",
                            "ë©”ëª¨ë¦¬ ì§‘ì•½ì ì¸ ì‘ì—…ì— ì œë„ˆë ˆì´í„° ì‚¬ìš©",
                            "ì ì ˆí•œ ì‹œì ì— del ë¬¸ìœ¼ë¡œ ê°ì²´ í•´ì œ",
                            "__slots__ ì‚¬ìš©ìœ¼ë¡œ í´ë˜ìŠ¤ ë©”ëª¨ë¦¬ ìµœì í™”"
                        ],
                        code_changes=[
                            {
                                'file': 'optimization_suggestion.py',
                                'change': '''
# Before: ë©”ëª¨ë¦¬ ë¹„íš¨ìœ¨ì  ì½”ë“œ
data = [expensive_operation(i) for i in range(1000000)]

# After: ì œë„ˆë ˆì´í„° ì‚¬ìš©
data = (expensive_operation(i) for i in range(1000000))

# Before: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°€ëŠ¥ì„±
class DataProcessor:
    def __init__(self):
        self.cache = {}
        self.large_data = load_large_dataset()

# After: __slots__ì™€ ì ì ˆí•œ ì •ë¦¬
class DataProcessor:
    __slots__ = ['cache', 'large_data']
    
    def __init__(self):
        self.cache = {}
        self.large_data = load_large_dataset()
    
    def cleanup(self):
        self.cache.clear()
        del self.large_data
'''
                            }
                        ]
                    ))
                
                # GC ìµœì í™”
                gc_stats = self.baseline_metrics.get('gc', {})
                if gc_stats and any(gen.get('collections', 0) > 100 for gen in gc_stats.values() if isinstance(gen, dict)):
                    results.append(OptimizationResult(
                        optimization_type=OptimizationType.MEMORY,
                        name="ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ íŠœë‹",
                        description="ë¹ˆë²ˆí•œ GC í˜¸ì¶œì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤",
                        priority=OptimizationPriority.MEDIUM,
                        impact_score=40.0,
                        implementation_difficulty=2,
                        estimated_improvement="10-20% GC ì˜¤ë²„í—¤ë“œ ê°ì†Œ",
                        before_metrics=gc_stats,
                        recommendations=[
                            "gc.set_threshold() ì¡°ì •",
                            "ìˆœí™˜ ì°¸ì¡° ì œê±°",
                            "ì ì ˆí•œ ì‹œì ì— gc.collect() í˜¸ì¶œ"
                        ],
                        code_changes=[
                            {
                                'file': 'gc_optimization.py',
                                'change': '''
import gc

# GC ì„ê³„ê°’ ì¡°ì • (ê¸°ë³¸ê°’ë³´ë‹¤ ëœ ê³µê²©ì )
gc.set_threshold(1000, 15, 15)

# ì¤‘ìš”í•œ ì‘ì—… ì „í›„ ëª…ì‹œì  GC
def heavy_processing():
    gc.collect()  # ì²˜ë¦¬ ì „ ì •ë¦¬
    try:
        # ë¬´ê±°ìš´ ì‘ì—… ìˆ˜í–‰
        result = expensive_computation()
    finally:
        gc.collect()  # ì²˜ë¦¬ í›„ ì •ë¦¬
    return result
'''
                            }
                        ]
                    ))
            
        except Exception as e:
            if console:
                console.print(f"âš ï¸  ë©”ëª¨ë¦¬ ìµœì í™” ë¶„ì„ ì‹¤íŒ¨: {str(e)}", style="yellow")
        
        return results
    
    async def _analyze_cpu_optimization(self, suite: OptimizationSuite) -> List[OptimizationResult]:
        """CPU ìµœì í™” ë¶„ì„"""
        results = []
        
        try:
            # ìŠ¤ë ˆë“œ ìˆ˜ í™•ì¸
            if 'cpu' in self.baseline_metrics:
                num_threads = self.baseline_metrics['cpu']['num_threads']
                
                if num_threads > 20:  # ê³¼ë„í•œ ìŠ¤ë ˆë“œ
                    results.append(OptimizationResult(
                        optimization_type=OptimizationType.CPU,
                        name="ìŠ¤ë ˆë“œ ìˆ˜ ìµœì í™”",
                        description=f"ê³¼ë„í•œ ìŠ¤ë ˆë“œ ìˆ˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤ ({num_threads}ê°œ)",
                        priority=OptimizationPriority.HIGH,
                        impact_score=60.0,
                        implementation_difficulty=3,
                        estimated_improvement="20-40% CPU íš¨ìœ¨ì„± í–¥ìƒ",
                        before_metrics={'thread_count': num_threads},
                        recommendations=[
                            "ThreadPoolExecutor ì‚¬ìš©ìœ¼ë¡œ ìŠ¤ë ˆë“œ ìˆ˜ ì œí•œ",
                            "ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°ìœ¼ë¡œ ìŠ¤ë ˆë“œ í•„ìš”ì„± ê°ì†Œ",
                            "ì—°ê²° í’€ë§ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ ì¬ì‚¬ìš©"
                        ],
                        code_changes=[
                            {
                                'file': 'thread_optimization.py',
                                'change': '''
import asyncio
from concurrent.futures import ThreadPoolExecutor
from functools import lru_cache

# Before: ë¬´ì œí•œ ìŠ¤ë ˆë“œ ìƒì„±
import threading

def process_data(data):
    for item in data:
        thread = threading.Thread(target=heavy_task, args=(item,))
        thread.start()

# After: ì œí•œëœ ìŠ¤ë ˆë“œ í’€ ì‚¬ìš©
MAX_WORKERS = min(32, (os.cpu_count() or 1) + 4)

async def process_data_optimized(data):
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        loop = asyncio.get_event_loop()
        tasks = [
            loop.run_in_executor(executor, heavy_task, item)
            for item in data
        ]
        return await asyncio.gather(*tasks)

# LRU ìºì‹œë¡œ ì¤‘ë³µ ê³„ì‚° ë°©ì§€
@lru_cache(maxsize=128)
def expensive_computation(param):
    # ë¹„ìš©ì´ í° ê³„ì‚°
    return result
'''
                            }
                        ]
                    ))
                
                # ë¹„ë™ê¸° ìµœì í™”
                results.append(OptimizationResult(
                    optimization_type=OptimizationType.CPU,
                    name="ë¹„ë™ê¸° ì²˜ë¦¬ ìµœì í™”",
                    description="ë™ê¸° I/O ì‘ì—…ì˜ ë¹„ë™ê¸° ì „í™˜ ê¸°íšŒ",
                    priority=OptimizationPriority.MEDIUM,
                    impact_score=50.0,
                    implementation_difficulty=4,
                    estimated_improvement="2-5ë°° ë™ì‹œ ì²˜ë¦¬ ì„±ëŠ¥ í–¥ìƒ",
                    recommendations=[
                        "ë™ê¸° I/Oë¥¼ ë¹„ë™ê¸°ë¡œ ë³€í™˜",
                        "asyncio.gatherë¡œ ë³‘ë ¬ ì²˜ë¦¬",
                        "ì ì ˆí•œ await ì§€ì  ì„¤ì •"
                    ],
                    code_changes=[
                        {
                            'file': 'async_optimization.py',
                            'change': '''
import asyncio
import aiohttp
import aiofiles

# Before: ë™ê¸° ì²˜ë¦¬
def fetch_data(urls):
    results = []
    for url in urls:
        response = requests.get(url)
        results.append(response.json())
    return results

# After: ë¹„ë™ê¸° ì²˜ë¦¬  
async def fetch_data_async(urls):
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_url(session, url) for url in urls]
        return await asyncio.gather(*tasks)

async def fetch_url(session, url):
    async with session.get(url) as response:
        return await response.json()

# Before: ë™ê¸° íŒŒì¼ ì²˜ë¦¬
def process_files(file_paths):
    results = []
    for path in file_paths:
        with open(path, 'r') as f:
            results.append(f.read())
    return results

# After: ë¹„ë™ê¸° íŒŒì¼ ì²˜ë¦¬
async def process_files_async(file_paths):
    tasks = [read_file_async(path) for path in file_paths]
    return await asyncio.gather(*tasks)

async def read_file_async(path):
    async with aiofiles.open(path, 'r') as f:
        return await f.read()
'''
                        }
                    ]
                ))
            
        except Exception as e:
            if console:
                console.print(f"âš ï¸  CPU ìµœì í™” ë¶„ì„ ì‹¤íŒ¨: {str(e)}", style="yellow")
        
        return results
    
    async def _analyze_io_optimization(self, suite: OptimizationSuite) -> List[OptimizationResult]:
        """I/O ìµœì í™” ë¶„ì„"""
        results = []
        
        try:
            # íŒŒì¼ I/O ìµœì í™”
            results.append(OptimizationResult(
                optimization_type=OptimizationType.IO,
                name="íŒŒì¼ I/O ìµœì í™”",
                description="íŒŒì¼ ì½ê¸°/ì“°ê¸° ì„±ëŠ¥ ìµœì í™” ê¸°íšŒ",
                priority=OptimizationPriority.MEDIUM,
                impact_score=35.0,
                implementation_difficulty=2,
                estimated_improvement="50-100% íŒŒì¼ I/O ì†ë„ í–¥ìƒ",
                recommendations=[
                    "ë²„í¼ë§ ì‚¬ìš©ìœ¼ë¡œ I/O í˜¸ì¶œ ìµœì†Œí™”",
                    "ëŒ€ìš©ëŸ‰ íŒŒì¼ì— mmap ì‚¬ìš©",
                    "ë°°ì¹˜ ì²˜ë¦¬ë¡œ I/O ì§‘ì•½ë„ ìµœì í™”"
                ],
                code_changes=[
                    {
                        'file': 'io_optimization.py',
                        'change': '''
import mmap
import os
from pathlib import Path

# Before: ì‘ì€ ì²­í¬ë¡œ íŒŒì¼ ì½ê¸°
def read_large_file_slow(file_path):
    with open(file_path, 'r') as f:
        lines = []
        while True:
            line = f.readline()
            if not line:
                break
            lines.append(line.strip())
    return lines

# After: ìµœì í™”ëœ íŒŒì¼ ì½ê¸°
def read_large_file_fast(file_path):
    # mmap ì‚¬ìš© (ëŒ€ìš©ëŸ‰ íŒŒì¼)
    if os.path.getsize(file_path) > 10 * 1024 * 1024:  # 10MB ì´ìƒ
        with open(file_path, 'r') as f:
            with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:
                return mm.read().decode().splitlines()
    else:
        # ì‘ì€ íŒŒì¼ì€ í•œ ë²ˆì— ì½ê¸°
        return Path(file_path).read_text().splitlines()

# Before: ê°œë³„ íŒŒì¼ ì“°ê¸°
def write_files_slow(data_dict):
    for filename, content in data_dict.items():
        with open(filename, 'w') as f:
            f.write(content)

# After: ë°°ì¹˜ ì²˜ë¦¬
def write_files_fast(data_dict):
    # ê°™ì€ ë””ë ‰í† ë¦¬ íŒŒì¼ë“¤ ê·¸ë£¹í™”
    dir_groups = {}
    for filename, content in data_dict.items():
        dir_name = os.path.dirname(filename)
        if dir_name not in dir_groups:
            dir_groups[dir_name] = []
        dir_groups[dir_name].append((filename, content))
    
    # ë””ë ‰í† ë¦¬ë³„ ë°°ì¹˜ ì²˜ë¦¬
    for dir_name, files in dir_groups.items():
        os.makedirs(dir_name, exist_ok=True)
        for filename, content in files:
            with open(filename, 'w', buffering=8192) as f:
                f.write(content)
'''
                    }
                ]
            ))
            
            # ë„¤íŠ¸ì›Œí¬ I/O ìµœì í™”
            results.append(OptimizationResult(
                optimization_type=OptimizationType.NETWORK,
                name="ë„¤íŠ¸ì›Œí¬ ì—°ê²° ìµœì í™”",
                description="HTTP ì—°ê²° ë° ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ìµœì í™”",
                priority=OptimizationPriority.HIGH,
                impact_score=65.0,
                implementation_difficulty=3,
                estimated_improvement="3-10ë°° ë„¤íŠ¸ì›Œí¬ ì„±ëŠ¥ í–¥ìƒ",
                recommendations=[
                    "ì—°ê²° í’€ë§ìœ¼ë¡œ ì—°ê²° ì¬ì‚¬ìš©",
                    "ìš”ì²­ ë°°ì¹˜ ì²˜ë¦¬",
                    "ì ì ˆí•œ íƒ€ì„ì•„ì›ƒ ì„¤ì •",
                    "ì••ì¶• ë° ìºì‹± í™œìš©"
                ],
                code_changes=[
                    {
                        'file': 'network_optimization.py',
                        'change': '''
import aiohttp
import asyncio
from aiohttp import ClientTimeout, TCPConnector

# ìµœì í™”ëœ HTTP í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
class OptimizedHTTPClient:
    def __init__(self):
        # ì—°ê²° í’€ ì„¤ì •
        connector = TCPConnector(
            limit=100,  # ì´ ì—°ê²° ìˆ˜ ì œí•œ
            limit_per_host=10,  # í˜¸ìŠ¤íŠ¸ë‹¹ ì—°ê²° ìˆ˜ ì œí•œ
            ttl_dns_cache=300,  # DNS ìºì‹œ TTL
            use_dns_cache=True,
            keepalive_timeout=30,
            enable_cleanup_closed=True
        )
        
        # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        timeout = ClientTimeout(
            total=30,  # ì´ ìš”ì²­ ì‹œê°„
            connect=5,  # ì—°ê²° ì‹œê°„
            sock_read=10  # ì†Œì¼“ ì½ê¸° ì‹œê°„
        )
        
        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers={'Accept-Encoding': 'gzip, deflate'}
        )
    
    async def fetch_multiple(self, urls, batch_size=10):
        """ë°°ì¹˜ ë‹¨ìœ„ë¡œ URL ìš”ì²­"""
        results = []
        
        for i in range(0, len(urls), batch_size):
            batch = urls[i:i + batch_size]
            batch_tasks = [self.fetch_url(url) for url in batch]
            batch_results = await asyncio.gather(*batch_tasks, return_exceptions=True)
            results.extend(batch_results)
            
            # ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
            if i + batch_size < len(urls):
                await asyncio.sleep(0.1)
        
        return results
    
    async def fetch_url(self, url):
        try:
            async with self.session.get(url) as response:
                return await response.json()
        except Exception as e:
            return {'error': str(e), 'url': url}
    
    async def close(self):
        await self.session.close()
'''
                    }
                ]
            ))
            
        except Exception as e:
            if console:
                console.print(f"âš ï¸  I/O ìµœì í™” ë¶„ì„ ì‹¤íŒ¨: {str(e)}", style="yellow")
        
        return results
    
    async def _analyze_startup_optimization(self, suite: OptimizationSuite) -> List[OptimizationResult]:
        """ì‹œì‘ ì‹œê°„ ìµœì í™” ë¶„ì„"""
        results = []
        
        try:
            if 'startup' in self.baseline_metrics:
                import_time = self.baseline_metrics['startup']['import_time']
                
                if import_time > 0.5:  # 500ms ì´ìƒ
                    results.append(OptimizationResult(
                        optimization_type=OptimizationType.STARTUP,
                        name="ëª¨ë“ˆ ì„í¬íŠ¸ ìµœì í™”",
                        description=f"ëŠë¦° ëª¨ë“ˆ ì„í¬íŠ¸ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤ ({import_time:.3f}ì´ˆ)",
                        priority=OptimizationPriority.HIGH,
                        impact_score=80.0,
                        implementation_difficulty=2,
                        estimated_improvement=f"50-70% ì‹œì‘ ì‹œê°„ ë‹¨ì¶• ({import_time*0.3:.3f}ì´ˆ ëª©í‘œ)",
                        before_metrics={'import_time': import_time},
                        recommendations=[
                            "ì§€ì—° ì„í¬íŠ¸ (lazy import) ì‚¬ìš©",
                            "ë¶ˆí•„ìš”í•œ ì „ì—­ ì„í¬íŠ¸ ì œê±°",
                            "ì¡°ê±´ë¶€ ì„í¬íŠ¸ í™œìš©",
                            "ê°€ë²¼ìš´ ëŒ€ì•ˆ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²€í† "
                        ],
                        code_changes=[
                            {
                                'file': 'lazy_import_optimization.py',
                                'change': '''
# Before: ì „ì—­ì—ì„œ ëª¨ë“  ëª¨ë“ˆ ì„í¬íŠ¸
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
import tensorflow as tf

def simple_function():
    return "Hello"

# After: ì§€ì—° ì„í¬íŠ¸ ì‚¬ìš©
def simple_function():
    return "Hello"

def data_analysis_function(data):
    # ì‹¤ì œ ì‚¬ìš©í•  ë•Œë§Œ ì„í¬íŠ¸
    import pandas as pd
    import numpy as np
    
    df = pd.DataFrame(data)
    return df.mean()

def plotting_function(data):
    # ì¡°ê±´ë¶€ ì„í¬íŠ¸
    try:
        import matplotlib.pyplot as plt
    except ImportError:
        raise ImportError("matplotlibì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    plt.plot(data)
    return plt.gcf()

# ì„ íƒì  ê¸°ëŠ¥ì„ ìœ„í•œ ì§€ì—° ë¡œë”©
class MachineLearningModule:
    def __init__(self):
        self._sklearn = None
        self._tensorflow = None
    
    @property
    def sklearn(self):
        if self._sklearn is None:
            import sklearn
            self._sklearn = sklearn
        return self._sklearn
    
    @property
    def tensorflow(self):
        if self._tensorflow is None:
            import tensorflow as tf
            self._tensorflow = tf
        return self._tensorflow
'''
                            }
                        ]
                    ))
                
                # Cold Start ìµœì í™”
                results.append(OptimizationResult(
                    optimization_type=OptimizationType.STARTUP,
                    name="Cold Start ìµœì í™”",
                    description="Cloud Run Cold Start ì‹œê°„ ìµœì†Œí™”",
                    priority=OptimizationPriority.CRITICAL,
                    impact_score=90.0,
                    implementation_difficulty=3,
                    estimated_improvement="50-80% Cold Start ì‹œê°„ ë‹¨ì¶•",
                    recommendations=[
                        "ìµœì†Œí•œì˜ ì „ì—­ ì´ˆê¸°í™”",
                        "í•„ìš” ì‹œì ê¹Œì§€ ì—°ê²° ì§€ì—°",
                        "ì˜ˆì—´ ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„",
                        "ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ í¬ê¸° ìµœì í™”"
                    ],
                    code_changes=[
                        {
                            'file': 'cold_start_optimization.py',
                            'change': '''
import os
from functools import lru_cache

# Before: ì‹œì‘ ì‹œ ëª¨ë“  ì—°ê²° ì´ˆê¸°í™”
database_connection = create_database_connection()
redis_client = create_redis_client()
external_api_client = create_api_client()

def handle_request(request):
    # ìš”ì²­ ì²˜ë¦¬
    pass

# After: ì§€ì—° ì´ˆê¸°í™”
_database_connection = None
_redis_client = None
_external_api_client = None

@lru_cache(maxsize=1)
def get_database_connection():
    global _database_connection
    if _database_connection is None:
        _database_connection = create_database_connection()
    return _database_connection

@lru_cache(maxsize=1)
def get_redis_client():
    global _redis_client
    if _redis_client is None:
        _redis_client = create_redis_client()
    return _redis_client

@lru_cache(maxsize=1)
def get_api_client():
    global _external_api_client
    if _external_api_client is None:
        _external_api_client = create_api_client()
    return _external_api_client

def handle_request(request):
    # í•„ìš”í•  ë•Œë§Œ ì—°ê²° ìƒì„±
    db = get_database_connection()
    # ìš”ì²­ ì²˜ë¦¬
    pass

# ì˜ˆì—´ ì—”ë“œí¬ì¸íŠ¸
def warmup():
    """Cloud Run ì˜ˆì—´ìš© ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # ì¤‘ìš”í•œ ì—°ê²°ë“¤ ë¯¸ë¦¬ ì´ˆê¸°í™”
        get_database_connection()
        get_redis_client()
        return {"status": "warm"}
    except Exception as e:
        return {"status": "error", "message": str(e)}
'''
                        }
                    ]
                ))
            
        except Exception as e:
            if console:
                console.print(f"âš ï¸  ì‹œì‘ ì‹œê°„ ìµœì í™” ë¶„ì„ ì‹¤íŒ¨: {str(e)}", style="yellow")
        
        return results
    
    async def _analyze_cloud_run_optimization(self, suite: OptimizationSuite) -> List[OptimizationResult]:
        """Cloud Run ìµœì í™” ë¶„ì„"""
        results = []
        
        try:
            # Cloud Run í™˜ê²½ ê°ì§€
            is_cloud_run = os.getenv('K_SERVICE') is not None
            
            results.append(OptimizationResult(
                optimization_type=OptimizationType.CLOUD_RUN,
                name="Cloud Run ë¦¬ì†ŒìŠ¤ ìµœì í™”",
                description="Cloud Run ì¸ìŠ¤í„´ìŠ¤ ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„± ìµœì í™”",
                priority=OptimizationPriority.HIGH,
                impact_score=75.0,
                implementation_difficulty=3,
                estimated_improvement="30-50% ë¦¬ì†ŒìŠ¤ ë¹„ìš© ì ˆì•½",
                before_metrics={'is_cloud_run': is_cloud_run},
                recommendations=[
                    "ì ì ˆí•œ CPU ë° ë©”ëª¨ë¦¬ í•œê³„ ì„¤ì •",
                    "ë™ì‹œì„± ì„¤ì • ìµœì í™”", 
                    "ìµœì†Œ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ ì¡°ì •",
                    "ìš”ì²­ íƒ€ì„ì•„ì›ƒ ìµœì í™”"
                ],
                code_changes=[
                    {
                        'file': 'cloud_run_config.yaml',
                        'change': '''
# Cloud Run ì„œë¹„ìŠ¤ ì„¤ì • ìµœì í™”
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: rfs-app
  annotations:
    # ë™ì‹œì„± ì„¤ì • (ê¸°ë³¸ê°’: 100, ìµœì í™”: 1000)
    run.googleapis.com/execution-environment: gen2
    run.googleapis.com/cpu-throttling: "false"
spec:
  template:
    metadata:
      annotations:
        # ë¦¬ì†ŒìŠ¤ ìµœì í™”
        run.googleapis.com/memory: "512Mi"  # ë©”ëª¨ë¦¬ ì œí•œ
        run.googleapis.com/cpu: "1000m"     # CPU ì œí•œ (1 vCPU)
        
        # ë™ì‹œì„± ë° í™•ì¥ ì„¤ì •
        autoscaling.knative.dev/maxScale: "100"
        autoscaling.knative.dev/minScale: "0"
        run.googleapis.com/execution-environment: "gen2"
        
        # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        run.googleapis.com/timeout: "300s"
        
    spec:
      containerConcurrency: 1000  # ì»¨í…Œì´ë„ˆë‹¹ ë™ì‹œ ìš”ì²­ ìˆ˜
      timeoutSeconds: 300
      containers:
      - image: gcr.io/project/rfs-app
        resources:
          limits:
            memory: "512Mi"
            cpu: "1000m"
        env:
        - name: PYTHONUNBUFFERED
          value: "1"
        - name: PYTHONDONTWRITEBYTECODE
          value: "1"
        
        # í—¬ìŠ¤ì²´í¬ ìµœì í™”
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 0
          timeoutSeconds: 1
          periodSeconds: 3
          failureThreshold: 3
        
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 0
          timeoutSeconds: 1
          periodSeconds: 3
          failureThreshold: 1
'''
                    },
                    {
                        'file': 'cloud_run_optimization.py',
                        'change': '''
import os
import logging
from contextlib import asynccontextmanager

# Cloud Run ìµœì í™” ì„¤ì •
class CloudRunOptimizer:
    
    @staticmethod
    def configure_logging():
        """Cloud Run ë¡œê¹… ìµœì í™”"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s %(name)s %(levelname)s %(message)s',
            handlers=[logging.StreamHandler()]
        )
        
        # Cloud Runì—ì„œëŠ” stdout/stderrê°€ ë¡œê·¸ë¡œ ìˆ˜ì§‘ë¨
        if os.getenv('K_SERVICE'):
            # JSON ë¡œê¹… ì„¤ì •
            import json
            import sys
            
            class CloudRunFormatter(logging.Formatter):
                def format(self, record):
                    log_obj = {
                        'timestamp': self.formatTime(record),
                        'severity': record.levelname,
                        'message': record.getMessage(),
                        'module': record.name
                    }
                    return json.dumps(log_obj)
            
            handler = logging.StreamHandler(sys.stdout)
            handler.setFormatter(CloudRunFormatter())
            
            root_logger = logging.getLogger()
            root_logger.handlers = [handler]
    
    @staticmethod
    def get_optimal_workers():
        """ìµœì ì˜ worker ìˆ˜ ê³„ì‚°"""
        cpu_count = os.cpu_count() or 1
        
        # Cloud Runì—ì„œëŠ” ë³´ìˆ˜ì ìœ¼ë¡œ ì„¤ì •
        if os.getenv('K_SERVICE'):
            return min(cpu_count * 2, 4)
        else:
            return cpu_count * 2 + 1
    
    @staticmethod
    @asynccontextmanager
    async def lifespan_manager(app):
        """ì• í”Œë¦¬ì¼€ì´ì…˜ ìˆ˜ëª… ì£¼ê¸° ê´€ë¦¬"""
        # ì‹œì‘ ì‹œ ì´ˆê¸°í™”
        CloudRunOptimizer.configure_logging()
        logger = logging.getLogger(__name__)
        
        logger.info("RFS v4 ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘")
        
        # ì˜ˆì—´ ì‘ì—…
        if os.getenv('K_SERVICE'):
            await CloudRunOptimizer.warmup_services()
        
        yield
        
        # ì¢…ë£Œ ì‹œ ì •ë¦¬
        logger.info("RFS v4 ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ")
        await CloudRunOptimizer.cleanup_services()
    
    @staticmethod
    async def warmup_services():
        """ì„œë¹„ìŠ¤ ì˜ˆì—´"""
        try:
            # ì¤‘ìš”í•œ ì—°ê²°ë“¤ ë¯¸ë¦¬ ì´ˆê¸°í™”
            from rfs_v4.cloud_run import initialize_cloud_run_services
            await initialize_cloud_run_services()
        except Exception as e:
            logging.warning(f"ì„œë¹„ìŠ¤ ì˜ˆì—´ ì‹¤íŒ¨: {e}")
    
    @staticmethod
    async def cleanup_services():
        """ì„œë¹„ìŠ¤ ì •ë¦¬"""
        try:
            from rfs_v4.cloud_run import shutdown_cloud_run_services
            await shutdown_cloud_run_services()
        except Exception as e:
            logging.warning(f"ì„œë¹„ìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {e}")
'''
                    }
                ]
            ))
            
        except Exception as e:
            if console:
                console.print(f"âš ï¸  Cloud Run ìµœì í™” ë¶„ì„ ì‹¤íŒ¨: {str(e)}", style="yellow")
        
        return results
    
    async def _apply_safe_optimizations(self, suite: OptimizationSuite):
        """ì•ˆì „í•œ ìµœì í™” ìë™ ì ìš©"""
        try:
            safe_optimizations = [
                opt for opt in self.optimization_results
                if opt.impact_score <= suite.max_impact_threshold
                and opt.implementation_difficulty <= 2
                and opt.priority in [OptimizationPriority.LOW, OptimizationPriority.MEDIUM]
            ]
            
            for optimization in safe_optimizations:
                try:
                    # ì‹¤ì œ ìµœì í™” ì ìš© ë¡œì§
                    # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
                    await asyncio.sleep(0.1)  # ì ìš© ì‹œë®¬ë ˆì´ì…˜
                    optimization.applied = True
                    
                    if console:
                        console.print(f"âœ… ìë™ ì ìš©: {optimization.name}", style="green")
                        
                except Exception as e:
                    if console:
                        console.print(f"âŒ ìë™ ì ìš© ì‹¤íŒ¨ {optimization.name}: {str(e)}", style="red")
            
        except Exception as e:
            if console:
                console.print(f"âš ï¸  ìë™ ìµœì í™” ì ìš© ì‹¤íŒ¨: {str(e)}", style="yellow")
    
    async def _display_optimization_results(self):
        """ìµœì í™” ê²°ê³¼ í‘œì‹œ"""
        if not console or not self.optimization_results:
            return
        
        # ê²°ê³¼ ìš”ì•½ í…Œì´ë¸”
        summary_table = Table(title="ìµœì í™” ë¶„ì„ ê²°ê³¼", show_header=True, header_style="bold magenta")
        summary_table.add_column("ìš°ì„ ìˆœìœ„", style="cyan", width=10)
        summary_table.add_column("ìµœì í™” í•­ëª©", style="white", width=25)
        summary_table.add_column("ìœ í˜•", style="yellow", width=12)
        summary_table.add_column("ì˜í–¥ë„", justify="right", width=8)
        summary_table.add_column("ë‚œì´ë„", justify="right", width=8)
        summary_table.add_column("ROI", justify="right", width=10)
        summary_table.add_column("ìƒíƒœ", justify="center", width=8)
        
        for opt in self.optimization_results[:10]:  # ìƒìœ„ 10ê°œë§Œ í‘œì‹œ
            priority_colors = {
                OptimizationPriority.CRITICAL: "bright_red",
                OptimizationPriority.HIGH: "red",
                OptimizationPriority.MEDIUM: "yellow",
                OptimizationPriority.LOW: "green"
            }
            
            priority_color = priority_colors.get(opt.priority, "white")
            roi_color = "green" if opt.roi_score > 15 else "yellow" if opt.roi_score > 8 else "red"
            
            summary_table.add_row(
                f"[{priority_color}]{opt.priority.value.upper()}[/{priority_color}]",
                opt.name,
                opt.optimization_type.value,
                f"{opt.impact_score:.0f}%",
                f"{opt.implementation_difficulty}/5",
                f"[{roi_color}]{opt.roi_score:.1f}[/{roi_color}]",
                "âœ…" if opt.applied else "â³"
            )
        
        console.print(summary_table)
        
        # ìƒìœ„ 3ê°œ ìƒì„¸ ì •ë³´
        if len(self.optimization_results) > 0:
            console.print("\nğŸ¯ ìš°ì„  ì ìš© ê¶Œì¥ ìµœì í™”:")
            
            for i, opt in enumerate(self.optimization_results[:3], 1):
                detail_panel = Panel(
                    f"**{opt.description}**\n\n"
                    f"ì˜ˆìƒ ê°œì„ : {opt.estimated_improvement}\n\n"
                    f"**ê¶Œì¥ì‚¬í•­:**\n" + 
                    "\n".join([f"â€¢ {rec}" for rec in opt.recommendations[:3]]) +
                    (f"\n\nâš¡ ì´ {len(opt.code_changes)}ê°œì˜ ì½”ë“œ ë³€ê²½ ì˜ˆì œ í¬í•¨" if opt.code_changes else ""),
                    title=f"{i}. {opt.name} (ì˜í–¥ë„: {opt.impact_score:.0f}%, ë‚œì´ë„: {opt.implementation_difficulty}/5)",
                    border_style="blue"
                )
                console.print(detail_panel)
        
        # ì „ì²´ í†µê³„
        total_impact = sum(opt.impact_score for opt in self.optimization_results)
        applied_count = sum(1 for opt in self.optimization_results if opt.applied)
        
        console.print(Panel(
            f"ğŸ“Š ìµœì í™” ë¶„ì„ ì™„ë£Œ\n\n"
            f"ğŸ” ì‹ë³„ëœ ìµœì í™”: {len(self.optimization_results)}ê°œ\n"
            f"âš¡ ìë™ ì ìš©: {applied_count}ê°œ\n"
            f"ğŸ“ˆ ì´ ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ: {total_impact:.0f}%\n"
            f"ğŸ¯ ìµœê³  ROI: {max(opt.roi_score for opt in self.optimization_results):.1f}" +
            (f"\nğŸ† ê°€ì¥ íš¨ê³¼ì : {max(self.optimization_results, key=lambda x: x.roi_score).name}" if self.optimization_results else ""),
            title="ìµœì í™” ìš”ì•½",
            border_style="green"
        ))
    
    async def start_performance_monitoring(self, interval: int = 60) -> Result[str, str]:
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        try:
            if self.monitoring_active:
                return Failure("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            
            self.monitoring_active = True
            self.monitoring_task = asyncio.create_task(self._performance_monitoring_loop(interval))
            
            return Success("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘ë¨")
            
        except Exception as e:
            return Failure(f"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘ ì‹¤íŒ¨: {str(e)}")
    
    async def stop_performance_monitoring(self) -> Result[str, str]:
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        try:
            self.monitoring_active = False
            
            if self.monitoring_task:
                self.monitoring_task.cancel()
                try:
                    await self.monitoring_task
                except asyncio.CancelledError:
                    pass
                self.monitoring_task = None
            
            return Success("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ë¨")
            
        except Exception as e:
            return Failure(f"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ ì‹¤íŒ¨: {str(e)}")
    
    async def _performance_monitoring_loop(self, interval: int):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while self.monitoring_active:
            try:
                # í˜„ì¬ ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘
                await self._collect_performance_metrics()
                
                # ì£¼ê¸°ì ìœ¼ë¡œ ëŒ€ê¸°
                await asyncio.sleep(interval)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                if console:
                    console.print(f"âš ï¸  ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {str(e)}", style="yellow")
                await asyncio.sleep(interval)
    
    async def _collect_performance_metrics(self):
        """ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘"""
        try:
            import psutil
            import os
            
            process = psutil.Process(os.getpid())
            
            metrics = {
                'timestamp': datetime.now().isoformat(),
                'memory': {
                    'rss_mb': process.memory_info().rss / 1024 / 1024,
                    'percent': process.memory_percent()
                },
                'cpu': {
                    'percent': process.cpu_percent()
                },
                'threads': process.num_threads(),
                'gc': {
                    'collections': [gc.get_stats()[i]['collections'] if i < len(gc.get_stats()) else 0 for i in range(3)]
                }
            }
            
            # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
            self.performance_history.append(metrics)
            
            # íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ
            if len(self.performance_history) > self.max_history_size:
                self.performance_history = self.performance_history[-self.max_history_size:]
                
        except Exception as e:
            if console:
                console.print(f"âš ï¸  ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}", style="yellow")
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ì •ë³´ ì¡°íšŒ"""
        if not self.performance_history:
            return {}
        
        try:
            # ìµœì‹  ì§€í‘œ
            latest = self.performance_history[-1]
            
            # í‰ê·  ê³„ì‚° (ìµœê·¼ 10ê°œ ìƒ˜í”Œ)
            recent_samples = self.performance_history[-10:]
            
            avg_memory = sum(m['memory']['rss_mb'] for m in recent_samples) / len(recent_samples)
            avg_cpu = sum(m['cpu']['percent'] for m in recent_samples) / len(recent_samples)
            
            return {
                'current': latest,
                'averages': {
                    'memory_mb': avg_memory,
                    'cpu_percent': avg_cpu
                },
                'optimization_count': len(self.optimization_results),
                'applied_optimizations': sum(1 for opt in self.optimization_results if opt.applied),
                'monitoring_active': self.monitoring_active,
                'history_size': len(self.performance_history)
            }
            
        except Exception as e:
            return {'error': str(e)}