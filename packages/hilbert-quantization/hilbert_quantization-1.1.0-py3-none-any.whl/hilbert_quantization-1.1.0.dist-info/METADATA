Metadata-Version: 2.4
Name: hilbert-quantization
Version: 1.1.0
Summary: Ultra-fast similarity search with Hilbert curve quantization and MPEG-AI compression
Author-email: Tyler Hess <tylerlhess@gmail.com>
Maintainer-email: Tyler Hess <tylerlhess@gmail.com>
License: MIT License
        
        Copyright (c) 2024 Hilbert Quantization Contributors
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE.
Project-URL: Homepage, https://github.com/Tylerlhess/hilbert-quantization
Project-URL: Documentation, https://hilbert-quantization.readthedocs.io
Project-URL: Repository, https://github.com/Tylerlhess/hilbert-quantization
Project-URL: Bug Tracker, https://github.com/Tylerlhess/hilbert-quantization/issues
Project-URL: Changelog, https://github.com/Tylerlhess/hilbert-quantization/blob/main/CHANGELOG.md
Keywords: similarity-search,vector-database,hilbert-curve,quantization,compression,embeddings,nearest-neighbors,machine-learning,ai
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Database :: Database Engines/Servers
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy>=1.20.0
Requires-Dist: psutil>=5.8.0
Provides-Extra: dev
Requires-Dist: pytest>=6.0; extra == "dev"
Requires-Dist: pytest-cov>=2.0; extra == "dev"
Requires-Dist: black>=21.0; extra == "dev"
Requires-Dist: flake8>=3.8; extra == "dev"
Requires-Dist: mypy>=0.800; extra == "dev"
Requires-Dist: pre-commit>=2.0; extra == "dev"
Provides-Extra: benchmark
Requires-Dist: matplotlib>=3.3.0; extra == "benchmark"
Requires-Dist: seaborn>=0.11.0; extra == "benchmark"
Requires-Dist: pandas>=1.3.0; extra == "benchmark"
Provides-Extra: gpu
Requires-Dist: cupy-cuda11x>=9.0.0; platform_machine == "x86_64" and extra == "gpu"
Requires-Dist: numba>=0.56.0; extra == "gpu"
Dynamic: license-file

# Hilbert Quantization

[![PyPI version](https://badge.fury.io/py/hilbert-quantization.svg)](https://badge.fury.io/py/hilbert-quantization)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Tests](https://github.com/yourusername/hilbert-quantization/workflows/Tests/badge.svg)](https://github.com/yourusername/hilbert-quantization/actions)

**Ultra-fast similarity search with 6x compression and competitive performance**

Hilbert Quantization is a high-performance similarity search library that combines Hilbert curve mapping with MPEG-AI compression to deliver both speed and storage efficiency. It's designed for applications where both search performance and storage costs matter.

## üÜï **New in v1.1.0: Streaming Optimization**

- **Memory-Efficient Processing**: Constant O(1) memory usage regardless of dataset size
- **Streaming Index Generation**: Build hierarchical indices incrementally during processing  
- **Integrated Mapping**: Single-pass Hilbert curve mapping with index generation
- **Automatic Optimization**: Smart approach selection based on dataset characteristics
- **Scalable Architecture**: Handle datasets with millions of parameters

## üöÄ Key Features

- **‚ö° Ultra-fast search**: Sub-millisecond to few-millisecond search times
- **üíæ 6x compression**: Massive storage savings compared to traditional methods
- **üèÜ Competitive performance**: Matches industry leaders like Pinecone and FAISS
- **üìà Scalable**: Better performance on larger datasets
- **üîß Easy to use**: Simple API with sensible defaults
- **üêç Pure Python**: No external dependencies beyond NumPy

## üìä Performance Comparison

| Method | Search Time | Storage Size | Compression | Use Case |
|--------|-------------|--------------|-------------|----------|
| **Hilbert Quantization** | **4.6ms** | **0.02GB** | **6x** | **Best overall** |
| Pinecone (Managed) | 2.1ms | 0.19GB | 1x | Speed-first |
| FAISS (GPT-4 style) | 4.8ms | 0.16GB | 1x | Accuracy-first |
| Brute Force | 5.9ms | 0.14GB | 1x | Simple baseline |

*Benchmark on 25K embeddings (1536D, GPT-4 style)*

## üõ†Ô∏è Installation

```bash
pip install hilbert-quantization
```

### Optional Dependencies

```bash
# For benchmarking and visualization
pip install hilbert-quantization[benchmark]

# For GPU acceleration (experimental)
pip install hilbert-quantization[gpu]

# For development
pip install hilbert-quantization[dev]
```

## üöÄ Quick Start

### Basic Usage

```python
import numpy as np
from hilbert_quantization import HilbertQuantizer

# Initialize quantizer
quantizer = HilbertQuantizer()

# Create some example embeddings
embeddings = [
    np.random.normal(0, 1, 1024).astype(np.float32) 
    for _ in range(10000)
]

# Quantize embeddings (one-time setup)
quantized_models = []
for i, embedding in enumerate(embeddings):
    quantized = quantizer.quantize(embedding, model_id=f"doc_{i}")
    quantized_models.append(quantized)

# Search for similar embeddings
query = np.random.normal(0, 1, 1024).astype(np.float32)
results = quantizer.search(query, quantized_models, max_results=5)

# Print results
for result in results:
    print(f"Model: {result.model.metadata.model_name}")
    print(f"Similarity: {result.similarity_score:.3f}")
```

### üÜï Streaming Optimization (v1.1.0)

For large datasets or memory-constrained environments:

```python
from hilbert_quantization import QuantizationConfig
from hilbert_quantization.core.index_generator import HierarchicalIndexGeneratorImpl
import numpy as np

# Create large dataset
image = np.random.randn(512, 512)  # 262k parameters

# Configure streaming optimization
config = QuantizationConfig(
    use_streaming_optimization=True,    # Enable streaming
    enable_integrated_mapping=True,     # Single-pass processing
    memory_efficient_mode=True          # Optimize for memory
)

# Create generator with streaming enabled
generator = HierarchicalIndexGeneratorImpl(config)

# Generate hierarchical indices with constant memory usage
indices = generator.generate_optimized_indices(image, 1000)

print(f"Processed {image.size:,} parameters with constant memory usage")
print(f"Generated {len(indices)} hierarchical indices")
```

### Cache-Optimized Search (Recommended for Production)

```python
from hilbert_quantization import HilbertQuantizer
from hilbert_quantization.optimized import CacheOptimizedDatabase, CacheOptimizedSearch

# Setup
quantizer = HilbertQuantizer()
search_engine = CacheOptimizedSearch()

# Quantize your embeddings
quantized_models = [quantizer.quantize(emb, f"id_{i}") for i, emb in enumerate(embeddings)]

# Build cache-optimized database (one-time setup)
database = CacheOptimizedDatabase(quantized_models)

# Pre-quantize your query (for multiple searches)
query_quantized = quantizer.quantize(query_embedding, "query")

# Ultra-fast search
results = search_engine.cache_optimized_search(
    query_quantized.hierarchical_indices,
    database,
    max_results=10
)
```

## üéØ Use Cases

### ‚úÖ Ideal For:
- **Large-scale RAG systems** (>100K documents)
- **Edge AI deployments** (storage-constrained environments)
- **Cost-optimized cloud** applications (minimize storage costs)
- **Archival/backup** embedding systems
- **Bandwidth-limited** distributed systems

### ‚ö†Ô∏è Consider Alternatives For:
- **Real-time chat** applications (need <1ms latency)
- **Small datasets** (<10K embeddings)
- **Latency-critical** applications where every millisecond counts

## üìä Performance Comparison

### Streaming vs Traditional Approach

| Dataset Size | Traditional | Streaming | Memory Usage | Recommendation |
|-------------|-------------|-----------|--------------|----------------|
| 1k params | 0.002s | 0.003s | Standard | Traditional |
| 50k params | 0.18s | 0.23s | Standard | Traditional |
| 100k params | 0.79s | 0.98s | **Constant** | **Streaming** |
| 500k params | 3.5s | 4.4s | **Constant** | **Streaming** |
| 2M+ params | Memory Error | 19s | **Constant** | **Streaming** |

### When to Use Streaming Optimization

**‚úÖ Use Streaming For:**
- Large datasets (>100k parameters)
- Memory-constrained environments
- Processing datasets larger than available RAM
- Integrated workflows requiring single-pass processing

**‚ö° Use Traditional For:**
- Small datasets (<50k parameters) 
- Maximum speed requirements
- Simple two-step processing workflows

## üìà Benchmarks

Run the included benchmarks to see performance on your hardware:

```bash
# Quick benchmark
hilbert-benchmark --quick

# Full industry comparison
hilbert-benchmark --industry-comparison

# Large-scale test
hilbert-benchmark --large-scale --size 1GB
```

## üîß Advanced Configuration

```python
from hilbert_quantization import HilbertQuantizer, CompressionConfig

# Custom configuration
config = CompressionConfig(
    quality=0.8,  # Higher quality = better accuracy, larger size
    preserve_index_row=True,  # Preserve important structural information
)

quantizer = HilbertQuantizer(config=config)

# Performance tuning
quantizer.update_configuration(
    similarity_threshold=0.1,  # Lower = more results
    max_results=20,  # Maximum results to return
)
```

## üß™ How It Works

Hilbert Quantization uses a novel approach combining:

1. **Hilbert Curve Mapping**: Maps high-dimensional embeddings to 1D space while preserving locality
2. **Hierarchical Indexing**: Creates multi-level indices for progressive filtering
3. **MPEG-AI Compression**: Applies advanced compression while maintaining searchability
4. **Cache-Optimized Layout**: Structure of Arrays (SoA) for optimal memory access patterns

### Architecture Overview

```
Input Embedding (1024D)
        ‚Üì
Hilbert Curve Mapping
        ‚Üì
Hierarchical Index Generation
        ‚Üì
MPEG-AI Compression (6x smaller)
        ‚Üì
Cache-Optimized Storage
        ‚Üì
Progressive Search (Level 0 ‚Üí Level 1 ‚Üí Level 2 ‚Üí Final)
        ‚Üì
Results (4.6ms average)
```

## üìö Documentation

- [API Reference](https://hilbert-quantization.readthedocs.io/api/)
- [Performance Guide](https://hilbert-quantization.readthedocs.io/performance/)
- [Advanced Usage](https://hilbert-quantization.readthedocs.io/advanced/)
- [Benchmarks](https://hilbert-quantization.readthedocs.io/benchmarks/)

## ü§ù Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Development Setup

```bash
git clone https://github.com/yourusername/hilbert-quantization.git
cd hilbert-quantization
pip install -e ".[dev]"
pre-commit install
```

### Running Tests

```bash
pytest                    # Run all tests
pytest -m "not slow"     # Skip slow tests
pytest --cov             # Run with coverage
```

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- Inspired by research in Hilbert curves and space-filling curves
- MPEG-AI compression techniques
- Performance optimization techniques from the vector database community

## üìû Support

- üêõ [Bug Reports](https://github.com/yourusername/hilbert-quantization/issues)
- üí° [Feature Requests](https://github.com/yourusername/hilbert-quantization/discussions)
- üìß [Email Support](mailto:support@example.com)

---

**Made with ‚ù§Ô∏è for the AI/ML community**
