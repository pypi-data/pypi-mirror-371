# -*- coding: utf-8 -*-
"""
Created on Wed Jul 17 17:01:26 2024

@author: u03132tk
"""
from SyntenyQC.blast_functions import all_vs_all_blast, make_rbh_matrix 
from SyntenyQC.networks import PrunedGraphWriter 
from SyntenyQC.visualisations import write_graph, write_hist 
from SyntenyQC.neighbourhood import Neighbourhood, log_neighbourhood_details, write_results
from Bio import Entrez
from SyntenyQC.helpers import check_motif, initalise_log, log_params, ingest_binary_csv
import os 

'''
This module outlines the collect() and sieve() pipelines
'''



def sieve(input_genbank_dir : str, 
          e_value : float, 
          min_percent_identity : int, 
          max_target_seqs : int,
          similarity_filter : float,
          results_dir : str,
          min_edge_view : float) -> str:
    '''
    Run sieve pipeline to filter redundant neighbourhoods from genbank_folder.
    Redundant neighbourhoods share >= similarity_filter proportion of BLASTP 
    reciprocal best hits.  Hit alignmentss must have >= min_percent_identity 
    and <= e_value.  Only the top max_target_seqs hits are considered for a given 
    query protein. Unfiltered neighbourhoods are written in gbk format to results_dir.
    A network shouing all neighbourhoods and their pairwise similarities is 
    written to results_dir/RBH_graph.html (for similariites >= min_edge_view).
    A histogram showing the distribution of all edge weights > min_edge_view is 
    written to results_dir/RBH_histogram.html.  

    Parameters
    ----------
    input_genbank_dir : str
        Folder with genbanks files represnting neighburhoods to filter.
    e_value : float
        BLASTP alignment evalue threshold.
    min_percent_identity : int
        BLASTP alignment percent identity threshold.
    max_target_seqs : int
        BLASTP max_target_Seqs parameter.
    similarity_filter : float
        Filtering similarity threshold.
    results_dir : str
        Folder for results.
    min_edge_view : float
        Minimum edge weight to show in graph/histogram visualisations. If 
        min_edge_view < similarity_filter, edges will be red 
        (>= similarity_filter) or black (< similarity_filter).  Otherwise, edges 
        will be black.  This setting is purely used for viusalisation and has no 
        impact on graph pruning.

    Raises
    ------
    ValueError
        If there are no genbank files in genbank_folder.

    Returns
    -------
    results_dir : str
        Path to results dir.

    '''

    #define and build dir paths to unique file locations for different sets of 
    #results.  
    
    #Note - this is an update on original solution that saved blastp files 
    #to the location of this script (i.e. the package install location).  
    #This is because files that weren't in the original distribution won't 
    #be removed with pip uninstall syntenyqc.  I could include empty files 
    #in the distribution, and then pip should uninstall them correctly, but 
    #I'm not sure if the database files generated by blastp will be consistent 
    #across blast+ versions (and so any new format files will be added to 
    #the dir and missed by pip uninstall). I could add a step to remove them 
    #myself, but I would then need to handle a lot of exceptions to make sure 
    #the deletion is handled for cases where the program is interrupted 
    #(e.g. due to filespace issues) - I'm not entirely sure what all the 
    #exceptions would be, and I think blastp can give different exit codes 
    #on different systems (https://www.biostars.org/p/443890/#443895), so 
    #this would likely be quite fragile (currently I rely on syntenyqc raising 
    #a foreign error on its own rather than handling it). As I also don't want 
    #to use a bare try/except clause, it is probably safest to have the files 
    #saved seperate to the distribution (i.e. at results_dir\blastp) and then 
    #let the user delete them if they wish. 
    
    output_blast_dir = fr'{results_dir}\blastp'
    output_genbank_dir = fr'{results_dir}\genbank'
    output_vis_dir = fr'{results_dir}\visualisations'
    os.makedirs(output_blast_dir)
    os.makedirs(output_genbank_dir)
    os.makedirs(output_vis_dir)

    #initialise and write params to log file
    logger_name = 'sieve_logger'
    logger = initalise_log(log_file = f'{results_dir}\\log.txt', 
                           logger_name = logger_name)
    log_params(local_vars = locals(), 
               command = 'sieve', 
               logger_name = logger_name)
        
    #perform RBH
    all_v_all_blast_xml = all_vs_all_blast(input_genbank_dir, 
                                           e_value,
                                           max_target_seqs,
                                           output_blast_dir)
    rbh_matrix = make_rbh_matrix(all_v_all_blast_xml, 
                                 min_percent_identity)
    
    #build and prune a similarity network from the RBH results, copy acceptable 
    #neighbourhoods from genbank_folder to results_dir, and log associated information
    pruned_graph = PrunedGraphWriter(input_genbank_dir, 
                                     rbh_matrix,     
                                     similarity_filter,
                                     min_edge_view,
                                     output_genbank_dir,
                                     logger_name)    
    
    #write graph/histogram html visualisations, save to associated path, and log 
    #associated information
    write_graph(graph = pruned_graph.raw_graph, 
                path = f'{output_vis_dir}\\RBH_graph.html', 
                similarity_filter = similarity_filter,
                min_edge_view = min_edge_view, 
                logger_name = logger_name)
    write_hist(graph = pruned_graph.raw_graph,
               path = f'{output_vis_dir}\\RBH_histogram.html',
               logger_name = logger_name)
    return results_dir
    

def collect(binary_path : str, 
            strict_span : bool,
            neighbourhood_size : int, 
            write_genomes : bool, 
            email : str,
            filenames : str,
            results_dir : str) -> str:
    '''
    Binary_file is a binary file from cblaster containing cblaster hit details 
    (record and locii of up/downstream terminii of first/last cblaster hits in 
    record).  This is parsed to define neighbourhood_size bp neighbourhoods, 
    which are written to local files if they can be scraped, written and extracted 
    properly.  Neighbourhood files are named according to either accession or 
    organism of parent record (which can also be written to local files if 
    write_genomes is True).  

    Parameters
    ----------
    binary_path : str
        Path to cblaster binary_path.
    strict_span : bool
        If True, reject neighbourhoods that have a terminus <0 or >length of 
        record.  Otherwise, correct to 0/length of record.
    neighbourhood_size : int
        Size of neighbourhood to build.
    write_genomes : bool
        If true, write parent record from which neighbourhood was defined to a 
        local file.
    email : str
        Required by NCBI for downlaoding files via entrez API.
    filenames : str
        Data to use for naming genome/neighbourhood files (organism or accession).
    results_dir : str
        Folder where results will be written.

    Raises
    ------
    ValueError
        If the cblaster binary file has a motif issue (which may in turn suggest 
        a data integrity issue and should not just be corrected as described for 
        strict_span).

    Returns
    -------
    str
        Folder where results are written.

    '''
    #required for ncbi - set before logging params so it is recorded
    Entrez.email = email
    
    #initialise and write params to log file
    logger_name = 'collect_logger'
    logger = initalise_log(log_file = f'{results_dir}\\log.txt', 
                           logger_name = logger_name)
    log_params(local_vars = locals(), 
               command = 'collect', 
               logger_name = logger_name)
    
    #read in cblaster binary file, check it has expected format (5 columns plus
    #>=1 hit column)
    location_data = ingest_binary_csv(binary_path, logger_name)  
    
    #define number of neighbourhoods for various print/log calls 
    number_of_neighbourhoods = len(location_data['Scaffold'])
    logger.info(f"Extracting {number_of_neighbourhoods} gbks...")
    
    #parse aceession, motif start, motif end.
    neighbourhood_data = zip (location_data['Scaffold'],
                             location_data['Start'],
                             location_data['End'])
    
    #Process each neithbourhood, keeping track of neighbourhood rejection causes 
    #for a final summary string. 
    writtten = 0
    skip_termini = 0
    skip_scrape = 0
    skip_motif = 0
    for index, (accession, motif_start, motif_stop) in enumerate(neighbourhood_data):
        
        #log aceesion, progress and motif details
        logger.info(f'accession {accession} #{index} of {number_of_neighbourhoods - 1}')  
        logger.info(f'motif = {motif_start} -> {motif_stop}')
        
        #sanity check motif read from cblaster file
        error_msg = check_motif(motif_start, motif_stop)
        if error_msg != '':
            logger.error(error_msg) 
            raise ValueError (error_msg)
            
        #define a Neighbourhood
        neighbourhood = Neighbourhood(accession, 
                                      motif_start, 
                                      motif_stop, 
                                      neighbourhood_size, 
                                      strict_span)
        
        
        
        #log neighbourhood span - if the Neighbourhood could not be built, 
        #record why and continue 
        logged_details = log_neighbourhood_details(neighbourhood, 
                                                   logger_name)
        if logged_details != 'success':
            if logged_details == 'scrape_fail':
                skip_scrape += 1
            elif logged_details == 'overlapping_termini':
                skip_termini += 1
            elif logged_details == 'long_motif':
                skip_motif += 1
            continue
        
        #write neighbourhhood record to local file in results_dir with named 
        #according to record organism or accession 
        write_results(results_folder = results_dir, 
                      neighbourhood=neighbourhood, 
                      filenames=filenames, #organism or accession
                      scale = 'neighbourhood', 
                      logger_name = logger_name)
        
        #for a typical usecase (i.e. synteny plot), you only want neighbourhoods.
        #However, if you want the genome as well (e.g. to check for distal associations 
        #shared between neighbourhoods) you can also get the entire record from 
        #which the neighbourhood was defined. Note, this record is not checked - it 
        #will be a contig but may not be an entire genome.
        if write_genomes:
            write_results(results_folder=results_dir, 
                          neighbourhood=neighbourhood, 
                          filenames=filenames, 
                          scale = 'genome',
                          logger_name = logger_name)

        #track number of successful writes for final log entry
        writtten += 1
    
    #summarise run
    logger.info(f'Written {writtten} records to {results_dir} - {skip_scrape} '\
                    f'failed scraping, {skip_termini} had termini that exceeded the '\
                        f'genome boundaries, {skip_motif} had a motif that was too long'
                        )
    
    return results_dir

