{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataAgent LangGraph Integration Example\n",
    "\n",
    "This notebook demonstrates how to integrate DataAgent tools with LangGraph for automated data analysis workflows.\n",
    "\n",
    "## Overview\n",
    "\n",
    "LangGraph is a framework for building stateful, multi-actor applications with LLMs. DataAgent provides tools that can be easily integrated into LangGraph workflows for automated data analysis.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- **State Management**: LangGraph manages state across workflow steps\n",
    "- **Tool Integration**: DataAgent tools can be used as nodes in the workflow\n",
    "- **Automated Analysis**: Complete data analysis pipelines can be automated\n",
    "- **Recommendations**: AI-powered insights and recommendations\n",
    "\n",
    "## Installation\n",
    "\n",
    "```bash\n",
    "pip install datagent[langgraph]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import datagent\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from typing import Dict, Any, TypedDict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"DataAgent version: {datagent.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define State Structure\n",
    "\n",
    "First, let's define the state structure that will be used throughout our LangGraph workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state structure for our LangGraph workflow\n",
    "class AnalysisState(TypedDict):\n",
    "    data: pd.DataFrame\n",
    "    target: pd.Series\n",
    "    analysis_results: Dict[str, Any]\n",
    "    current_step: str\n",
    "    recommendations: list\n",
    "\n",
    "print(\"State structure defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading Step\n",
    "\n",
    "This step loads and prepares the data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(state: AnalysisState) -> AnalysisState:\n",
    "    \"\"\"Load and prepare data\"\"\"\n",
    "    print(\"Loading iris dataset...\")\n",
    "    \n",
    "    iris = load_iris()\n",
    "    X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    y = pd.Series(iris.target)\n",
    "    \n",
    "    state[\"data\"] = X\n",
    "    state[\"target\"] = y\n",
    "    state[\"current_step\"] = \"data_loaded\"\n",
    "    state[\"analysis_results\"] = {}\n",
    "    state[\"recommendations\"] = []\n",
    "    \n",
    "    print(f\"Loaded dataset with shape: {X.shape}\")\n",
    "    print(f\"Target classes: {np.unique(y)}\")\n",
    "    return state\n",
    "\n",
    "# Test the data loading step\n",
    "initial_state = AnalysisState(\n",
    "    data=pd.DataFrame(),\n",
    "    target=pd.Series(),\n",
    "    analysis_results={},\n",
    "    current_step=\"initialized\",\n",
    "    recommendations=[]\n",
    ")\n",
    "\n",
    "state = load_data(initial_state)\n",
    "print(f\"\\nCurrent step: {state['current_step']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sklearn Analysis Step\n",
    "\n",
    "This step performs machine learning analysis using DataAgent's sklearn tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_with_sklearn(state: AnalysisState) -> AnalysisState:\n",
    "    \"\"\"Analyze data using sklearn tools\"\"\"\n",
    "    print(\"Running sklearn analysis...\")\n",
    "    \n",
    "    try:\n",
    "        # Create DataFrame with target column for sklearn tools\n",
    "        df = state[\"data\"].copy()\n",
    "        df['target'] = state[\"target\"]\n",
    "        \n",
    "        # Use DataAgent's sklearn tool\n",
    "        result = datagent.universal_sklearn_estimator(\n",
    "            estimator_name=\"random_forest_classifier\",\n",
    "            data=df,\n",
    "            target_column=\"target\",\n",
    "            test_size=0.2,\n",
    "            random_state=42,\n",
    "            n_estimators=100\n",
    "        )\n",
    "        \n",
    "        state[\"analysis_results\"][\"sklearn\"] = result\n",
    "        state[\"current_step\"] = \"sklearn_completed\"\n",
    "        \n",
    "        # Add recommendations based on results\n",
    "        accuracy = result[\"metrics\"][\"accuracy\"]\n",
    "        if accuracy > 0.95:\n",
    "            state[\"recommendations\"].append(\"Excellent model performance! Consider using this model for production.\")\n",
    "        elif accuracy > 0.85:\n",
    "            state[\"recommendations\"].append(\"Good model performance. Consider hyperparameter tuning for improvement.\")\n",
    "        else:\n",
    "            state[\"recommendations\"].append(\"Model performance could be improved. Consider feature engineering or different algorithms.\")\n",
    "            \n",
    "        print(f\"Sklearn analysis completed. Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in sklearn analysis: {e}\")\n",
    "        state[\"analysis_results\"][\"sklearn\"] = {\"error\": str(e)}\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Test the sklearn analysis step\n",
    "state = analyze_with_sklearn(state)\n",
    "print(f\"\\nCurrent step: {state['current_step']}\")\n",
    "print(f\"Recommendations: {len(state['recommendations'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Statsmodels Analysis Step\n",
    "\n",
    "This step performs statistical analysis using DataAgent's statsmodels tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_with_statsmodels(state: AnalysisState) -> AnalysisState:\n",
    "    \"\"\"Analyze data using statsmodels tools\"\"\"\n",
    "    print(\"Running statsmodels analysis...\")\n",
    "    \n",
    "    try:\n",
    "        # Create a combined dataset for statsmodels\n",
    "        df = state[\"data\"].copy()\n",
    "        df['target'] = state[\"target\"]\n",
    "        \n",
    "        # Use DataAgent's statsmodels tool\n",
    "        result = datagent.universal_linear_models(\n",
    "            model_name=\"ols\",\n",
    "            data=df,\n",
    "            formula=\"target ~ sepal_length + sepal_width + petal_length + petal_width\"\n",
    "        )\n",
    "        \n",
    "        state[\"analysis_results\"][\"statsmodels\"] = result\n",
    "        state[\"current_step\"] = \"statsmodels_completed\"\n",
    "        \n",
    "        # Add recommendations based on results\n",
    "        r_squared = result.get(\"r_squared\", 0)\n",
    "        if r_squared > 0.9:\n",
    "            state[\"recommendations\"].append(\"Strong linear relationship detected. Linear models are appropriate.\")\n",
    "        elif r_squared > 0.7:\n",
    "            state[\"recommendations\"].append(\"Moderate linear relationship. Consider non-linear models for better fit.\")\n",
    "        else:\n",
    "            state[\"recommendations\"].append(\"Weak linear relationship. Consider non-linear models or feature engineering.\")\n",
    "            \n",
    "        print(f\"Statsmodels analysis completed. R-squared: {r_squared:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in statsmodels analysis: {e}\")\n",
    "        state[\"analysis_results\"][\"statsmodels\"] = {\"error\": str(e)}\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Test the statsmodels analysis step\n",
    "state = analyze_with_statsmodels(state)\n",
    "print(f\"\\nCurrent step: {state['current_step']}\")\n",
    "print(f\"Total recommendations: {len(state['recommendations'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Report Generation Step\n",
    "\n",
    "This step generates a comprehensive analysis report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(state: AnalysisState) -> AnalysisState:\n",
    "    \"\"\"Generate a comprehensive analysis report\"\"\"\n",
    "    print(\"Generating analysis report...\")\n",
    "    \n",
    "    report = {\n",
    "        \"summary\": {\n",
    "            \"dataset_shape\": state[\"data\"].shape,\n",
    "            \"target_classes\": len(state[\"target\"].unique()),\n",
    "            \"analysis_steps\": state[\"current_step\"]\n",
    "        },\n",
    "        \"results\": state[\"analysis_results\"],\n",
    "        \"recommendations\": state[\"recommendations\"]\n",
    "    }\n",
    "    \n",
    "    state[\"analysis_results\"][\"report\"] = report\n",
    "    state[\"current_step\"] = \"report_generated\"\n",
    "    \n",
    "    print(\"Report generated successfully!\")\n",
    "    return state\n",
    "\n",
    "# Test the report generation step\n",
    "state = generate_report(state)\n",
    "print(f\"\\nCurrent step: {state['current_step']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Report Display Step\n",
    "\n",
    "This step displays the analysis report in a formatted way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_report(state: AnalysisState) -> AnalysisState:\n",
    "    \"\"\"Print the analysis report\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DATAAGENT ANALYSIS REPORT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    report = state[\"analysis_results\"][\"report\"]\n",
    "    \n",
    "    print(f\"\\nDataset Summary:\")\n",
    "    print(f\"  Shape: {report['summary']['dataset_shape']}\")\n",
    "    print(f\"  Target classes: {report['summary']['target_classes']}\")\n",
    "    \n",
    "    print(f\"\\nAnalysis Results:\")\n",
    "    \n",
    "    # Sklearn results\n",
    "    if \"sklearn\" in report[\"results\"] and \"error\" not in report[\"results\"][\"sklearn\"]:\n",
    "        sklearn_result = report[\"results\"][\"sklearn\"]\n",
    "        print(f\"  Scikit-learn Random Forest:\")\n",
    "        print(f\"    Accuracy: {sklearn_result['metrics']['accuracy']:.4f}\")\n",
    "        print(f\"    Precision: {sklearn_result['metrics']['precision']:.4f}\")\n",
    "        print(f\"    Recall: {sklearn_result['metrics']['recall']:.4f}\")\n",
    "        print(f\"    F1 Score: {sklearn_result['metrics']['f1']:.4f}\")\n",
    "    \n",
    "    # Statsmodels results\n",
    "    if \"statsmodels\" in report[\"results\"] and \"error\" not in report[\"results\"][\"statsmodels\"]:\n",
    "        statsmodels_result = report[\"results\"][\"statsmodels\"]\n",
    "        print(f\"  Statsmodels OLS:\")\n",
    "        print(f\"    R-squared: {statsmodels_result.get('r_squared', 'N/A')}\")\n",
    "        print(f\"    Adjusted R-squared: {statsmodels_result.get('adj_r_squared', 'N/A')}\")\n",
    "        print(f\"    AIC: {statsmodels_result.get('aic', 'N/A')}\")\n",
    "    \n",
    "    print(f\"\\nRecommendations:\")\n",
    "    for i, rec in enumerate(report[\"recommendations\"], 1):\n",
    "        print(f\"  {i}. {rec}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Display the final report\n",
    "state = print_report(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Complete Workflow Execution\n",
    "\n",
    "Now let's run the complete workflow from start to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run the LangGraph-style workflow\"\"\"\n",
    "    print(\"DataAgent LangGraph Integration Example\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Initialize state\n",
    "    state = AnalysisState(\n",
    "        data=pd.DataFrame(),\n",
    "        target=pd.Series(),\n",
    "        analysis_results={},\n",
    "        current_step=\"initialized\",\n",
    "        recommendations=[]\n",
    "    )\n",
    "    \n",
    "    # Run the workflow steps\n",
    "    state = load_data(state)\n",
    "    state = analyze_with_sklearn(state)\n",
    "    state = analyze_with_statsmodels(state)\n",
    "    state = generate_report(state)\n",
    "    state = print_report(state)\n",
    "    \n",
    "    print(\"\\nWorkflow completed successfully!\")\n",
    "    return state\n",
    "\n",
    "# Run the complete workflow\n",
    "final_state = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. LangGraph Integration\n",
    "\n",
    "Here's how you would integrate this with actual LangGraph (if you have it installed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example LangGraph integration (commented out as it requires langgraph installation)\n",
    "\"\"\"\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(AnalysisState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"load_data\", load_data)\n",
    "workflow.add_node(\"sklearn_analysis\", analyze_with_sklearn)\n",
    "workflow.add_node(\"statsmodels_analysis\", analyze_with_statsmodels)\n",
    "workflow.add_node(\"generate_report\", generate_report)\n",
    "workflow.add_node(\"print_report\", print_report)\n",
    "\n",
    "# Define the flow\n",
    "workflow.set_entry_point(\"load_data\")\n",
    "workflow.add_edge(\"load_data\", \"sklearn_analysis\")\n",
    "workflow.add_edge(\"sklearn_analysis\", \"statsmodels_analysis\")\n",
    "workflow.add_edge(\"statsmodels_analysis\", \"generate_report\")\n",
    "workflow.add_edge(\"generate_report\", \"print_report\")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# Run the workflow\n",
    "initial_state = AnalysisState(\n",
    "    data=pd.DataFrame(),\n",
    "    target=pd.Series(),\n",
    "    analysis_results={},\n",
    "    current_step=\"initialized\",\n",
    "    recommendations=[]\n",
    ")\n",
    "\n",
    "result = app.invoke(initial_state)\n",
    "\"\"\"\n",
    "\n",
    "print(\"LangGraph integration example shown above (commented out)\")\n",
    "print(\"To use with LangGraph, install: pip install langgraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "This example demonstrates how DataAgent can be integrated into LangGraph workflows:\n",
    "\n",
    "### Key Benefits:\n",
    "\n",
    "1. **Stateful Workflows**: Each step maintains and updates state\n",
    "2. **Modular Design**: Each analysis step is a separate function\n",
    "3. **Automated Insights**: AI-powered recommendations based on results\n",
    "4. **Comprehensive Analysis**: Both ML and statistical analysis in one workflow\n",
    "5. **Extensible**: Easy to add new analysis steps or modify existing ones\n",
    "\n",
    "### Workflow Steps:\n",
    "\n",
    "1. **Data Loading**: Load and prepare data\n",
    "2. **Sklearn Analysis**: Perform machine learning analysis\n",
    "3. **Statsmodels Analysis**: Perform statistical analysis\n",
    "4. **Report Generation**: Create comprehensive report\n",
    "5. **Report Display**: Format and display results\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. Install LangGraph: `pip install langgraph`\n",
    "2. Uncomment the LangGraph integration code above\n",
    "3. Add more analysis steps (clustering, feature engineering, etc.)\n",
    "4. Integrate with LLM agents for more sophisticated recommendations\n",
    "5. Deploy as a production workflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}