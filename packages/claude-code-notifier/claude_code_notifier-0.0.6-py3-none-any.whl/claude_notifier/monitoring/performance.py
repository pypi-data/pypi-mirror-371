#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æ€§èƒ½ç›‘æ§å™¨
ç›‘æ§ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡ï¼ŒåŒ…æ‹¬CPUã€å†…å­˜ã€å“åº”æ—¶é—´ç­‰
"""

import time
import threading
import logging
import os
import gc
from typing import Dict, Any, List, Optional, Callable, Tuple
from dataclasses import dataclass, field
from enum import Enum
from datetime import datetime, timedelta
from collections import deque, defaultdict

# å¯é€‰ä¾èµ–
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    psutil = None
    PSUTIL_AVAILABLE = False


class PerformanceLevel(Enum):
    """æ€§èƒ½ç­‰çº§"""
    EXCELLENT = "excellent"
    GOOD = "good"
    WARNING = "warning"
    CRITICAL = "critical"
    UNKNOWN = "unknown"


@dataclass
class PerformanceMetric:
    """æ€§èƒ½æŒ‡æ ‡"""
    name: str
    value: float
    unit: str
    level: PerformanceLevel = PerformanceLevel.UNKNOWN
    timestamp: float = field(default_factory=time.time)
    details: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'name': self.name,
            'value': self.value,
            'unit': self.unit,
            'level': self.level.value,
            'timestamp': self.timestamp,
            'formatted_time': datetime.fromtimestamp(self.timestamp).strftime('%Y-%m-%d %H:%M:%S'),
            'details': self.details
        }


@dataclass
class PerformanceThresholds:
    """æ€§èƒ½é˜ˆå€¼é…ç½®"""
    excellent_threshold: float
    good_threshold: float
    warning_threshold: float
    critical_threshold: float
    
    def get_level(self, value: float, reverse: bool = False) -> PerformanceLevel:
        """æ ¹æ®å€¼è·å–æ€§èƒ½ç­‰çº§
        
        Args:
            value: æŒ‡æ ‡å€¼
            reverse: æ˜¯å¦åå‘æ¯”è¾ƒï¼ˆå€¼è¶Šå°è¶Šå¥½ï¼Œå¦‚å“åº”æ—¶é—´ï¼‰
        """
        if reverse:
            if value <= self.excellent_threshold:
                return PerformanceLevel.EXCELLENT
            elif value <= self.good_threshold:
                return PerformanceLevel.GOOD
            elif value <= self.warning_threshold:
                return PerformanceLevel.WARNING
            else:
                return PerformanceLevel.CRITICAL
        else:
            if value >= self.excellent_threshold:
                return PerformanceLevel.EXCELLENT
            elif value >= self.good_threshold:
                return PerformanceLevel.GOOD
            elif value >= self.warning_threshold:
                return PerformanceLevel.WARNING
            else:
                return PerformanceLevel.CRITICAL


class PerformanceMonitor:
    """ç³»ç»Ÿæ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """åˆå§‹åŒ–æ€§èƒ½ç›‘æ§å™¨
        
        Args:
            config: æ€§èƒ½ç›‘æ§é…ç½®
        """
        self.config = config or {}
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # æ€§èƒ½æŒ‡æ ‡å†å²æ•°æ®ï¼ˆä½¿ç”¨dequeé™åˆ¶å¤§å°ï¼‰
        self.metrics_history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=1000))
        
        # å½“å‰æ€§èƒ½æŒ‡æ ‡
        self.current_metrics: Dict[str, PerformanceMetric] = {}
        
        # çº¿ç¨‹å®‰å…¨é”
        self._lock = threading.RLock()
        
        # åå°ç›‘æ§çº¿ç¨‹æ§åˆ¶
        self._running = False
        self._monitor_thread: Optional[threading.Thread] = None
        self._monitor_interval = self.config.get('monitor_interval', 30)  # é»˜è®¤30ç§’
        
        # æ€§èƒ½é˜ˆå€¼é…ç½®
        self.thresholds = self._init_thresholds()
        
        # ç›‘æ§ç»Ÿè®¡
        self.stats = {
            'total_samples': 0,
            'alerts_triggered': 0,
            'performance_degradation_count': 0,
            'last_monitor_time': None,
            'monitoring_overhead': 0.0
        }
        
        # æ³¨å†Œæ€§èƒ½ç›‘æ§å™¨
        self._register_monitors()
        
    def _init_thresholds(self) -> Dict[str, PerformanceThresholds]:
        """åˆå§‹åŒ–æ€§èƒ½é˜ˆå€¼"""
        default_thresholds = {
            'cpu_usage': PerformanceThresholds(80, 60, 40, 20),  # CPUä½¿ç”¨ç‡ (%)
            'memory_usage': PerformanceThresholds(80, 60, 40, 20),  # å†…å­˜ä½¿ç”¨ç‡ (%)
            'disk_usage': PerformanceThresholds(90, 80, 70, 50),  # ç£ç›˜ä½¿ç”¨ç‡ (%)
            'response_time': PerformanceThresholds(100, 500, 1000, 2000),  # å“åº”æ—¶é—´ (ms) - åå‘
            'throughput': PerformanceThresholds(100, 80, 50, 20),  # ååé‡ (req/s)
            'error_rate': PerformanceThresholds(1, 5, 10, 20),  # é”™è¯¯ç‡ (%) - åå‘
            'queue_size': PerformanceThresholds(10, 50, 100, 500)  # é˜Ÿåˆ—å¤§å° - åå‘
        }
        
        # å…è®¸é€šè¿‡é…ç½®è¦†ç›–é˜ˆå€¼
        user_thresholds = self.config.get('thresholds', {})
        for name, user_config in user_thresholds.items():
            if name in default_thresholds and isinstance(user_config, dict):
                default_thresholds[name] = PerformanceThresholds(**user_config)
                
        return default_thresholds
        
    def _register_monitors(self):
        """æ³¨å†Œæ€§èƒ½ç›‘æ§å™¨"""
        self.monitors: Dict[str, Callable[[], Tuple[float, Dict[str, Any]]]] = {
            'cpu_usage': self._monitor_cpu_usage,
            'memory_usage': self._monitor_memory_usage,
            'disk_usage': self._monitor_disk_usage,
            'process_info': self._monitor_process_info,
            'gc_stats': self._monitor_gc_stats
        }
        
    def start_monitoring(self):
        """å¯åŠ¨åå°æ€§èƒ½ç›‘æ§"""
        if self._running:
            self.logger.warning("æ€§èƒ½ç›‘æ§å·²åœ¨è¿è¡Œ")
            return
            
        self._running = True
        self._monitor_thread = threading.Thread(target=self._monitoring_worker, daemon=True)
        self._monitor_thread.start()
        self.logger.info("åå°æ€§èƒ½ç›‘æ§å·²å¯åŠ¨")
        
    def stop_monitoring(self):
        """åœæ­¢åå°æ€§èƒ½ç›‘æ§"""
        self._running = False
        if self._monitor_thread and self._monitor_thread.is_alive():
            self._monitor_thread.join(timeout=5)
        self.logger.info("åå°æ€§èƒ½ç›‘æ§å·²åœæ­¢")
        
    def _monitoring_worker(self):
        """åå°ç›‘æ§å·¥ä½œçº¿ç¨‹"""
        while self._running:
            try:
                start_time = time.time()
                
                # æ”¶é›†æ‰€æœ‰æ€§èƒ½æŒ‡æ ‡
                self.collect_all_metrics()
                
                # è®°å½•ç›‘æ§å¼€é”€
                overhead = time.time() - start_time
                with self._lock:
                    self.stats['monitoring_overhead'] = overhead
                    self.stats['last_monitor_time'] = time.time()
                
                # ä¼‘çœ åˆ°ä¸‹ä¸€ä¸ªç›‘æ§å‘¨æœŸ
                time.sleep(self._monitor_interval)
                
            except Exception as e:
                self.logger.error(f"æ€§èƒ½ç›‘æ§å¼‚å¸¸: {e}")
                time.sleep(10)  # å¼‚å¸¸æ—¶çŸ­æš‚ä¼‘çœ 
                
    def collect_all_metrics(self) -> Dict[str, PerformanceMetric]:
        """æ”¶é›†æ‰€æœ‰æ€§èƒ½æŒ‡æ ‡"""
        metrics = {}
        
        with self._lock:
            for name, monitor_func in self.monitors.items():
                try:
                    value, details = monitor_func()
                    
                    # ç¡®å®šæ€§èƒ½ç­‰çº§
                    level = PerformanceLevel.UNKNOWN
                    if name in self.thresholds:
                        reverse = name in ['response_time', 'error_rate', 'queue_size']
                        level = self.thresholds[name].get_level(value, reverse)
                    
                    # åˆ›å»ºæ€§èƒ½æŒ‡æ ‡
                    metric = PerformanceMetric(
                        name=name,
                        value=value,
                        unit=details.get('unit', ''),
                        level=level,
                        details=details
                    )
                    
                    metrics[name] = metric
                    self.current_metrics[name] = metric
                    
                    # æ·»åŠ åˆ°å†å²æ•°æ®
                    self.metrics_history[name].append({
                        'timestamp': metric.timestamp,
                        'value': metric.value,
                        'level': metric.level.value
                    })
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦æŠ¥è­¦
                    if level in [PerformanceLevel.WARNING, PerformanceLevel.CRITICAL]:
                        self.stats['alerts_triggered'] += 1
                        if level == PerformanceLevel.CRITICAL:
                            self.stats['performance_degradation_count'] += 1
                            
                except Exception as e:
                    self.logger.error(f"æ”¶é›† {name} æŒ‡æ ‡å¤±è´¥: {e}")
                    
            self.stats['total_samples'] += 1
            
        return metrics
        
    def get_current_metrics(self) -> Dict[str, PerformanceMetric]:
        """è·å–å½“å‰æ€§èƒ½æŒ‡æ ‡"""
        with self._lock:
            return self.current_metrics.copy()
            
    def get_metric_history(self, metric_name: str, minutes: int = 60) -> List[Dict[str, Any]]:
        """è·å–æŒ‡æ ‡å†å²æ•°æ®
        
        Args:
            metric_name: æŒ‡æ ‡åç§°
            minutes: è·å–æœ€è¿‘å¤šå°‘åˆ†é’Ÿçš„æ•°æ®
        """
        cutoff_time = time.time() - (minutes * 60)
        
        with self._lock:
            if metric_name not in self.metrics_history:
                return []
                
            history = self.metrics_history[metric_name]
            return [
                record for record in history 
                if record['timestamp'] >= cutoff_time
            ]
            
    def get_performance_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        with self._lock:
            metrics = self.current_metrics
            
            # ç»Ÿè®¡å„ç­‰çº§æŒ‡æ ‡æ•°é‡
            level_counts = defaultdict(int)
            for metric in metrics.values():
                level_counts[metric.level.value] += 1
                
            # è®¡ç®—æ•´ä½“æ€§èƒ½ç­‰çº§
            overall_level = PerformanceLevel.EXCELLENT
            if level_counts.get('critical', 0) > 0:
                overall_level = PerformanceLevel.CRITICAL
            elif level_counts.get('warning', 0) > 0:
                overall_level = PerformanceLevel.WARNING
            elif level_counts.get('good', 0) > 0:
                overall_level = PerformanceLevel.GOOD
                
            # ç”Ÿæˆæ‘˜è¦
            summary = {
                'overall_performance': overall_level.value,
                'total_metrics': len(metrics),
                'level_distribution': dict(level_counts),
                'metrics': {name: metric.to_dict() for name, metric in metrics.items()},
                'stats': self.stats.copy(),
                'monitoring_active': self._running,
                'last_update': max(
                    (m.timestamp for m in metrics.values()), default=None
                )
            }
            
            return summary
            
    def _monitor_cpu_usage(self) -> Tuple[float, Dict[str, Any]]:
        """ç›‘æ§CPUä½¿ç”¨ç‡"""
        if not PSUTIL_AVAILABLE:
            return 0.0, {'unit': '%', 'error': 'psutil not available'}
            
        try:
            cpu_percent = psutil.cpu_percent(interval=1)
            cpu_count = psutil.cpu_count()
            
            details = {
                'unit': '%',
                'cpu_count': cpu_count,
                'per_cpu': psutil.cpu_percent(interval=None, percpu=True)[:4]  # åªæ˜¾ç¤ºå‰4ä¸ªæ ¸å¿ƒ
            }
            
            return cpu_percent, details
            
        except Exception as e:
            return 0.0, {'unit': '%', 'error': str(e)}
            
    def _monitor_memory_usage(self) -> Tuple[float, Dict[str, Any]]:
        """ç›‘æ§å†…å­˜ä½¿ç”¨ç‡"""
        if not PSUTIL_AVAILABLE:
            return 0.0, {'unit': '%', 'error': 'psutil not available'}
            
        try:
            memory = psutil.virtual_memory()
            process = psutil.Process()
            process_memory = process.memory_info()
            
            details = {
                'unit': '%',
                'total_gb': round(memory.total / (1024**3), 2),
                'available_gb': round(memory.available / (1024**3), 2),
                'process_memory_mb': round(process_memory.rss / (1024**2), 2),
                'swap_percent': psutil.swap_memory().percent
            }
            
            return memory.percent, details
            
        except Exception as e:
            return 0.0, {'unit': '%', 'error': str(e)}
            
    def _monitor_disk_usage(self) -> Tuple[float, Dict[str, Any]]:
        """ç›‘æ§ç£ç›˜ä½¿ç”¨ç‡"""
        if not PSUTIL_AVAILABLE:
            return 0.0, {'unit': '%', 'error': 'psutil not available'}
            
        try:
            # ç›‘æ§æ ¹ç›®å½•ç£ç›˜ä½¿ç”¨ç‡
            disk_usage = psutil.disk_usage('/')
            
            details = {
                'unit': '%',
                'total_gb': round(disk_usage.total / (1024**3), 2),
                'free_gb': round(disk_usage.free / (1024**3), 2),
                'used_gb': round(disk_usage.used / (1024**3), 2)
            }
            
            return (disk_usage.used / disk_usage.total) * 100, details
            
        except Exception as e:
            return 0.0, {'unit': '%', 'error': str(e)}
            
    def _monitor_process_info(self) -> Tuple[float, Dict[str, Any]]:
        """ç›‘æ§è¿›ç¨‹ä¿¡æ¯"""
        if not PSUTIL_AVAILABLE:
            return 0.0, {'unit': 'count', 'error': 'psutil not available'}
            
        try:
            process = psutil.Process()
            
            details = {
                'unit': 'count',
                'pid': process.pid,
                'ppid': process.ppid(),
                'threads': process.num_threads(),
                'fds': process.num_fds() if hasattr(process, 'num_fds') else 0,
                'status': process.status(),
                'create_time': process.create_time(),
                'uptime': time.time() - process.create_time()
            }
            
            return float(process.num_threads()), details
            
        except Exception as e:
            return 0.0, {'unit': 'count', 'error': str(e)}
            
    def _monitor_gc_stats(self) -> Tuple[float, Dict[str, Any]]:
        """ç›‘æ§åƒåœ¾å›æ”¶ç»Ÿè®¡"""
        try:
            gc_stats = gc.get_stats()
            gc_counts = gc.get_count()
            
            details = {
                'unit': 'count',
                'generation_0': gc_counts[0],
                'generation_1': gc_counts[1],
                'generation_2': gc_counts[2],
                'total_collections': sum(stat['collections'] for stat in gc_stats),
                'total_collected': sum(stat['collected'] for stat in gc_stats),
                'total_uncollectable': sum(stat['uncollectable'] for stat in gc_stats)
            }
            
            # è¿”å›generation 0çš„å¯¹è±¡æ•°é‡ä½œä¸ºä¸»è¦æŒ‡æ ‡
            return float(gc_counts[0]), details
            
        except Exception as e:
            return 0.0, {'unit': 'count', 'error': str(e)}
            
    def record_custom_metric(self, name: str, value: float, unit: str = '', 
                           details: Optional[Dict[str, Any]] = None):
        """è®°å½•è‡ªå®šä¹‰æ€§èƒ½æŒ‡æ ‡
        
        Args:
            name: æŒ‡æ ‡åç§°
            value: æŒ‡æ ‡å€¼
            unit: å•ä½
            details: è¯¦ç»†ä¿¡æ¯
        """
        with self._lock:
            # ç¡®å®šæ€§èƒ½ç­‰çº§
            level = PerformanceLevel.UNKNOWN
            if name in self.thresholds:
                reverse = name in ['response_time', 'error_rate', 'queue_size']
                level = self.thresholds[name].get_level(value, reverse)
            
            metric = PerformanceMetric(
                name=name,
                value=value,
                unit=unit,
                level=level,
                details=details or {}
            )
            
            self.current_metrics[name] = metric
            self.metrics_history[name].append({
                'timestamp': metric.timestamp,
                'value': metric.value,
                'level': metric.level.value
            })
            
    def get_alerts(self, severity: Optional[str] = None) -> List[Dict[str, Any]]:
        """è·å–æ€§èƒ½æŠ¥è­¦
        
        Args:
            severity: æŠ¥è­¦ä¸¥é‡ç¨‹åº¦è¿‡æ»¤ ('warning', 'critical')
        """
        alerts = []
        
        with self._lock:
            for name, metric in self.current_metrics.items():
                if metric.level in [PerformanceLevel.WARNING, PerformanceLevel.CRITICAL]:
                    if severity is None or metric.level.value == severity:
                        alerts.append({
                            'metric_name': name,
                            'current_value': metric.value,
                            'unit': metric.unit,
                            'level': metric.level.value,
                            'timestamp': metric.timestamp,
                            'message': f"{name} æ€§èƒ½ {metric.level.value}: {metric.value}{metric.unit}",
                            'details': metric.details
                        })
                        
        return sorted(alerts, key=lambda x: x['timestamp'], reverse=True)
        
    def generate_performance_report(self) -> str:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        summary = self.get_performance_summary()
        
        report = []
        report.append("=" * 60)
        report.append("âš¡ Claude Code Notifier æ€§èƒ½ç›‘æ§æŠ¥å‘Š")
        report.append("=" * 60)
        report.append("")
        
        report.append(f"ğŸ“Š æ•´ä½“æ€§èƒ½çŠ¶æ€: {summary['overall_performance'].upper()}")
        report.append(f"ğŸ” ç›‘æ§æŒ‡æ ‡æ•°é‡: {summary['total_metrics']}")
        report.append(f"ğŸ“ˆ ç›‘æ§çŠ¶æ€: {'è¿è¡Œä¸­' if summary['monitoring_active'] else 'å·²åœæ­¢'}")
        
        if summary['last_update']:
            last_update = datetime.fromtimestamp(summary['last_update'])
            report.append(f"ğŸ• æœ€åæ›´æ–°: {last_update.strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # æ€§èƒ½ç­‰çº§åˆ†å¸ƒ
        distribution = summary['level_distribution']
        if distribution:
            report.append("ğŸ“ˆ æ€§èƒ½ç­‰çº§åˆ†å¸ƒ:")
            for level, count in distribution.items():
                report.append(f"  â€¢ {level.capitalize()}: {count}")
            report.append("")
        
        # è¯¦ç»†æŒ‡æ ‡
        report.append("ğŸ“‹ è¯¦ç»†æ€§èƒ½æŒ‡æ ‡:")
        for name, metric in summary['metrics'].items():
            level_icon = {
                'excellent': 'ğŸŸ¢',
                'good': 'ğŸ”µ', 
                'warning': 'ğŸŸ¡',
                'critical': 'ğŸ”´',
                'unknown': 'âšª'
            }.get(metric['level'], 'âšª')
            
            report.append(f"  {level_icon} {name}: {metric['value']}{metric['unit']} ({metric['level']})")
            
        report.append("")
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = summary['stats']
        report.append("ğŸ“Š ç›‘æ§ç»Ÿè®¡:")
        report.append(f"  â€¢ é‡‡æ ·æ€»æ•°: {stats['total_samples']}")
        report.append(f"  â€¢ è§¦å‘æŠ¥è­¦: {stats['alerts_triggered']}")
        report.append(f"  â€¢ æ€§èƒ½é™çº§æ¬¡æ•°: {stats['performance_degradation_count']}")
        report.append(f"  â€¢ ç›‘æ§å¼€é”€: {stats['monitoring_overhead']:.3f}s")
        report.append("")
        
        # å½“å‰æŠ¥è­¦
        alerts = self.get_alerts()
        if alerts:
            report.append("âš ï¸  å½“å‰æ€§èƒ½æŠ¥è­¦:")
            for alert in alerts[:5]:  # åªæ˜¾ç¤ºæœ€è¿‘5ä¸ª
                icon = 'ğŸ”´' if alert['level'] == 'critical' else 'ğŸŸ¡'
                report.append(f"  {icon} {alert['message']}")
            
            if len(alerts) > 5:
                report.append(f"  ... è¿˜æœ‰ {len(alerts) - 5} ä¸ªæŠ¥è­¦")
                
        report.append("")
        report.append("=" * 60)
        
        return '\n'.join(report)
        
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.stop_monitoring()
        
        with self._lock:
            self.metrics_history.clear()
            self.current_metrics.clear()