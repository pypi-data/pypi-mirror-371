# æ‰¹æ¬¡æ“ä½œ

æ‰¹æ¬¡æ“ä½œæ˜¯æå‡ Redis æ•ˆèƒ½çš„é—œéµæŠ€è¡“ï¼Œèƒ½å¤ å¤§å¹…æ¸›å°‘ç¶²è·¯å¾€è¿”æ¬¡æ•¸ï¼Œæé«˜è³‡æ–™è™•ç†æ•ˆç‡ã€‚

## ğŸš€ ç‚ºä»€éº¼éœ€è¦æ‰¹æ¬¡æ“ä½œï¼Ÿ

å–®ç­†æ“ä½œ vs æ‰¹æ¬¡æ“ä½œçš„æ•ˆèƒ½å·®ç•°ï¼š

```python
import time

# âŒ å–®ç­†æ“ä½œï¼šæ•ˆèƒ½ä½ä¸‹
start = time.time()
for i in range(10000):
    toolkit.setter(f"key:{i}", f"value:{i}")
print(f"å–®ç­†æ“ä½œè€—æ™‚: {time.time() - start:.2f} ç§’")

# âœ… æ‰¹æ¬¡æ“ä½œï¼šæ•ˆèƒ½æå‡ 10 å€ä»¥ä¸Š
start = time.time()
batch_data = {f"key:{i}": f"value:{i}" for i in range(10000)}
toolkit.batch_set(batch_data)
print(f"æ‰¹æ¬¡æ“ä½œè€—æ™‚: {time.time() - start:.2f} ç§’")
```

## ğŸ“ æ‰¹æ¬¡æ“ä½œæ–¹æ³•

### batch_set - æ‰¹æ¬¡è¨­å®š

```python
# æº–å‚™æ‰¹æ¬¡è³‡æ–™
users = {
    "user:1001": {"name": "Alice", "score": 95},
    "user:1002": {"name": "Bob", "score": 87},
    "user:1003": {"name": "Charlie", "score": 92}
}

# ä¸€æ¬¡è¨­å®šå¤šå€‹éµå€¼
toolkit.batch_set(users)

# æ”¯æ´è¨­å®šéæœŸæ™‚é–“
toolkit.batch_set(users, ex=3600)  # å…¨éƒ¨è¨­å®š 1 å°æ™‚éæœŸ
```

### batch_get - æ‰¹æ¬¡è®€å–

```python
# æ‰¹æ¬¡è®€å–å¤šå€‹éµ
keys = ["user:1001", "user:1002", "user:1003"]
results = toolkit.batch_get(keys)

# results æ˜¯å­—å…¸æ ¼å¼
for key, value in results.items():
    if value:  # æª¢æŸ¥éµæ˜¯å¦å­˜åœ¨
        print(f"{key}: {value['name']} - åˆ†æ•¸: {value['score']}")
```

## ğŸ”§ ä½¿ç”¨ Pipeline

Pipeline æä¾›æ›´éˆæ´»çš„æ‰¹æ¬¡æ“ä½œæ–¹å¼ï¼š

```python
# å‰µå»ºç®¡ç·š
pipe = toolkit.client.pipeline()

# æ’éšŠå¤šå€‹ä¸åŒé¡å‹çš„å‘½ä»¤
pipe.set("counter", 0)
pipe.incr("counter")
pipe.incr("counter")
pipe.get("counter")

# åŸ·è¡Œæ‰€æœ‰å‘½ä»¤
results = pipe.execute()
print(results)  # [True, 1, 2, b'2']
```

### Pipeline äº‹å‹™æ”¯æ´

```python
# ä½¿ç”¨äº‹å‹™ç¢ºä¿åŸå­æ€§
pipe = toolkit.client.pipeline(transaction=True)

try:
    # ç›£è¦–éµï¼ˆæ¨‚è§€é–ï¼‰
    pipe.watch("account:balance")
    
    # ç²å–ç•¶å‰é¤˜é¡
    balance = int(pipe.get("account:balance") or 0)
    
    # é–‹å§‹äº‹å‹™
    pipe.multi()
    
    # åŸ·è¡Œè½‰å¸³æ“ä½œ
    if balance >= 100:
        pipe.decrby("account:balance", 100)
        pipe.incrby("account:savings", 100)
        pipe.execute()
        print("è½‰å¸³æˆåŠŸ")
    else:
        pipe.reset()  # å–æ¶ˆäº‹å‹™
        print("é¤˜é¡ä¸è¶³")
        
except redis.WatchError:
    print("é¤˜é¡åœ¨äº¤æ˜“æœŸé–“è¢«ä¿®æ”¹")
```

## ğŸ¯ å¯¦ç”¨ç¯„ä¾‹

### æ‰¹æ¬¡æ›´æ–°ç”¨æˆ¶ç©åˆ†

```python
class ScoreManager:
    def __init__(self):
        self.toolkit = RedisToolkit()
    
    def update_scores(self, score_updates):
        """æ‰¹æ¬¡æ›´æ–°ç”¨æˆ¶ç©åˆ†"""
        # å…ˆæ‰¹æ¬¡è®€å–ç¾æœ‰è³‡æ–™
        user_ids = list(score_updates.keys())
        keys = [f"user:{uid}" for uid in user_ids]
        existing_users = self.toolkit.batch_get(keys)
        
        # æ›´æ–°ç©åˆ†
        updated_data = {}
        for uid, score_delta in score_updates.items():
            key = f"user:{uid}"
            user_data = existing_users.get(key, {"score": 0})
            user_data["score"] = user_data.get("score", 0) + score_delta
            updated_data[key] = user_data
        
        # æ‰¹æ¬¡å¯«å›
        self.toolkit.batch_set(updated_data)
        
        return updated_data

# ä½¿ç”¨ç¯„ä¾‹
manager = ScoreManager()

# æ‰¹æ¬¡æ›´æ–°å¤šå€‹ç”¨æˆ¶çš„ç©åˆ†
updates = {
    "1001": 10,   # ç”¨æˆ¶ 1001 åŠ  10 åˆ†
    "1002": -5,   # ç”¨æˆ¶ 1002 æ¸› 5 åˆ†
    "1003": 20    # ç”¨æˆ¶ 1003 åŠ  20 åˆ†
}

result = manager.update_scores(updates)
```

### æ‰¹æ¬¡å¿«å–é ç†±

```python
def cache_warmup(data_loader, cache_keys):
    """æ‰¹æ¬¡é ç†±å¿«å–"""
    # å¾è³‡æ–™ä¾†æºæ‰¹æ¬¡è¼‰å…¥è³‡æ–™
    data = data_loader.load_batch(cache_keys)
    
    # è½‰æ›ç‚º Redis éµå€¼æ ¼å¼
    cache_data = {}
    for item in data:
        key = f"cache:{item['id']}"
        cache_data[key] = item
    
    # æ‰¹æ¬¡å¯«å…¥å¿«å–ï¼Œè¨­å®šéæœŸæ™‚é–“
    toolkit.batch_set(cache_data, ex=3600)
    
    print(f"é ç†±äº† {len(cache_data)} å€‹å¿«å–é …ç›®")
```

## ğŸš€ æ•ˆèƒ½å„ªåŒ–æŠ€å·§

### 1. åˆ†æ‰¹è™•ç†å¤§é‡è³‡æ–™

```python
def batch_process_large_dataset(data, batch_size=1000):
    """åˆ†æ‰¹è™•ç†å¤§å‹è³‡æ–™é›†"""
    total = len(data)
    
    for i in range(0, total, batch_size):
        batch = dict(list(data.items())[i:i + batch_size])
        toolkit.batch_set(batch)
        print(f"å·²è™•ç† {min(i + batch_size, total)}/{total}")
```

### 2. ä¸¦è¡Œæ‰¹æ¬¡æ“ä½œ

```python
from concurrent.futures import ThreadPoolExecutor
import threading

def parallel_batch_operations(datasets):
    """ä¸¦è¡ŒåŸ·è¡Œå¤šå€‹æ‰¹æ¬¡æ“ä½œ"""
    def process_batch(batch_id, data):
        local_toolkit = RedisToolkit()
        local_toolkit.batch_set(data)
        print(f"æ‰¹æ¬¡ {batch_id} å®Œæˆ")
    
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = []
        for i, dataset in enumerate(datasets):
            future = executor.submit(process_batch, i, dataset)
            futures.append(future)
        
        # ç­‰å¾…æ‰€æœ‰æ‰¹æ¬¡å®Œæˆ
        for future in futures:
            future.result()
```

## ğŸ“Š æ•ˆèƒ½æ¯”è¼ƒ

| æ“ä½œé¡å‹ | 10,000 ç­†è³‡æ–™è€—æ™‚ | ç¶²è·¯å¾€è¿”æ¬¡æ•¸ |
|---------|-----------------|-------------|
| å–®ç­†æ“ä½œ | ~5.2 ç§’ | 10,000 æ¬¡ |
| æ‰¹æ¬¡æ“ä½œ | ~0.3 ç§’ | 1 æ¬¡ |
| Pipeline | ~0.4 ç§’ | 1 æ¬¡ |
| åˆ†æ‰¹è™•ç†(1000ç­†/æ‰¹) | ~0.5 ç§’ | 10 æ¬¡ |

## ğŸ¯ æœ€ä½³å¯¦è¸

1. **é¸æ“‡é©ç•¶çš„æ‰¹æ¬¡å¤§å°**
   ```python
   # å»ºè­°æ‰¹æ¬¡å¤§å°ï¼š100-1000 ç­†
   # å¤ªå°ï¼šæ•ˆèƒ½æå‡æœ‰é™
   # å¤ªå¤§ï¼šå¯èƒ½è¶…é Redis é™åˆ¶æˆ–è¨˜æ†¶é«”
   optimal_batch_size = 500
   ```

2. **è™•ç†éƒ¨åˆ†å¤±æ•—**
   ```python
   try:
       toolkit.batch_set(large_batch)
   except Exception as e:
       # é™ç´šç‚ºé€ç­†è™•ç†
       for key, value in large_batch.items():
           try:
               toolkit.setter(key, value)
           except:
               logger.error(f"Failed to set {key}")
   ```

3. **ç›£æ§æ‰¹æ¬¡æ“ä½œ**
   ```python
   import time
   
   start = time.time()
   toolkit.batch_set(data)
   elapsed = time.time() - start
   
   logger.info(f"æ‰¹æ¬¡å¯«å…¥ {len(data)} ç­†ï¼Œè€—æ™‚ {elapsed:.3f} ç§’")
   ```

## ğŸ“š å»¶ä¼¸é–±è®€

- [æ•ˆèƒ½å„ªåŒ–](./performance.md) - æ›´å¤šæ•ˆèƒ½èª¿å„ªæŠ€å·§
- [é€£æ¥æ± ç®¡ç†](./connection-pool.md) - å„ªåŒ–é€£ç·šè³‡æº
- [éŒ¯èª¤è™•ç†](./error-handling.md) - è™•ç†æ‰¹æ¬¡æ“ä½œéŒ¯èª¤

::: tip å°çµ
æ‰¹æ¬¡æ“ä½œæ˜¯æå‡ Redis æ•ˆèƒ½çš„åˆ©å™¨ã€‚è¨˜ä½é¸æ“‡é©ç•¶çš„æ‰¹æ¬¡å¤§å°ï¼Œè™•ç†éŒ¯èª¤æƒ…æ³ï¼Œä¸¦ç›£æ§æ“ä½œæ•ˆèƒ½ï¼
:::