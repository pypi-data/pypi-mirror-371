# (Ï†) src/phicode_engine/benchsuite/bench_phimmuno.Ï†
# Copyright 2025 Baleine Jay
# Licensed under the PhiCode Non-Commercial License (https://banes-lab.com/licensing)
# Commercial use requires a paid license. See link for details.
â‡’ time
â‡’ os
â† phicode_engine.security.phimmuno_validator â‡’ is_content_safe
â† phicode_engine.benchsuite â‡’ report

Æ’ report(name, result):
    Ï€(f"{name}: {result}")

Ï€("SECURITY VALIDATION BENCHMARK")

phimmuno_path = os.path.join(os.path.expanduser("~"), ".phicode", "bin", "phimmuno-engine")
Â¿ os.name == 'nt':
    phimmuno_path += ".exe"

binary_available = os.path.exists(phimmuno_path)
report("Phimmuno binary available", "âœ… Yes" if binary_available else "âŒ No")

Â¿ Â¬ binary_available:
    Ï€("âš ï¸ Running fallback mode (always returns safe)")
    Ï€("ğŸ’¡ Install âˆ¥: phicode --security-install")

safe_patterns = [
    "Ï€('Hello World')",
    "x = 1 + 2",
    "âˆ€ i âˆˆ range(10): Ï€(i)",
    "Æ’ hello(): âŸ² 'world'",
    "â‡’ math; Ï€(math.pi)",
]

dangerous_patterns = [
    "eval('malicious_code')",
    "exec(user_input)",
    "subprocess.call(['rm', '-rf'])",
    "os.system('dangerous')",
    "__import__('subprocess')",
    "getattr(__builtins__, 'eval')",
    "compile(source, '<string>', 'exec')",
    "globals()['eval']",
]

Ï€("\nTesting Safe Patterns...")
safe_blocked = 0
âˆ€ i, pattern âˆˆ enumerate(safe_patterns):
    result = is_content_safe(pattern)
    status = "âœ… Allowed" if result else "âŒ Blocked"
    Ï€(f"  Safe #{i+1}: {status}")
    Â¿ Â¬ result:
        safe_blocked += 1

safe_pass_rate = ((len(safe_patterns) - safe_blocked) / len(safe_patterns)) * 100
report("Safe pattern pass rate", f"{safe_pass_rate:.1f}%")

Ï€("\nTesting Dangerous Patterns...")
dangerous_allowed = 0
âˆ€ i, pattern âˆˆ enumerate(dangerous_patterns):
    result = is_content_safe(pattern)
    status = "âœ… Blocked" Â¿ Â¬ result â‹„ "âŒ Allowed"
    Ï€(f"  Threat #{i+1}: {status}")
    Â¿ result:
        dangerous_allowed += 1

threat_block_rate = ((len(dangerous_patterns) - dangerous_allowed) / len(dangerous_patterns)) * 100
report("Threat block rate", f"{threat_block_rate:.1f}%")

Ï€("\nTesting Performance...")

start = time.perf_counter()
âˆ€ _ âˆˆ range(1000):
    is_content_safe("print('test')")
end = time.perf_counter()
small_avg = (end - start) / 1000 * 1000

large_pattern = "print('test')\n" * 100
start = time.perf_counter()
âˆ€ _ âˆˆ range(100):
    is_content_safe(large_pattern)
end = time.perf_counter()
large_avg = (end - start) / 100 * 1000

Ï€("Testing concurrent validation...")
patterns_mix = safe_patterns + dangerous_patterns
start = time.perf_counter()
âˆ€ pattern âˆˆ patterns_mix * 10:
    is_content_safe(pattern)
end = time.perf_counter()
concurrent_avg = (end - start) / (len(patterns_mix) * 10) * 1000

report("Small pattern avg time", f"{small_avg:.3f}ms")
report("Large pattern avg time", f"{large_avg:.3f}ms")
report("Mixed workload avg time", f"{concurrent_avg:.3f}ms")

Â¿ binary_available:
    Â¿ small_avg < 1.0 âˆ§ large_avg < 5.0:
        Ï€("âœ… Performance excellent")
    â¤· small_avg < 2.0 âˆ§ large_avg < 10.0:
        Ï€("âœ… Performance good")
    â‹„:
        Ï€("âš ï¸ Performance may need optimization")
â‹„:
    Ï€("â„¹ï¸ Performance test skipped (binary not available)")

# Summary
Ï€(f"\nSUMMARY:")
Ï€(f"  Safe patterns: {len(safe_patterns) - safe_blocked}/{len(safe_patterns)} passed")
Ï€(f"  Threats blocked: {len(dangerous_patterns) - dangerous_allowed}/{len(dangerous_patterns)}")
Ï€(f"  Binary status: {'Available' if binary_available else 'Missing'}")

overall_score = (safe_pass_rate + threat_block_rate) / 2
Â¿ overall_score >= 95:
    Ï€("âœ… Security system working excellently")
â¤· overall_score >= 85:
    Ï€("âœ… Security system working well")
â‹„:
    Ï€("âš ï¸ Security system needs attention")