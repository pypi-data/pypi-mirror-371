{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robustness evaluation for calibration\n",
    "\n",
    "Evaluating the robustness of your calibration ensures that your weights will generalize well to related targets not explicitly used during calibration. This notebook demonstrates how to use the robustness evaluation feature to assess and improve calibration stability.\n",
    "\n",
    "## What is robustness evaluation\n",
    "\n",
    "Robustness evaluation uses holdout validation to test how well the calibration performs on unseen targets. The process:\n",
    "1. Randomly holds out a subset of targets\n",
    "2. Calibrates on the remaining targets\n",
    "3. Evaluates performance on the held-out targets\n",
    "4. Repeats multiple times to assess consistency\n",
    "\n",
    "This helps identify whether your calibration is overfitting to specific targets or if it will generalize well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from microcalibrate import Calibration\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "calibration_logger = logging.getLogger(\"microcalibrate.calibration\")\n",
    "calibration_logger.setLevel(logging.WARNING)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a test dataset\n",
    "\n",
    "We'll create a dataset with correlated targets to demonstrate the robustness evaluation. Some targets will be combinations of others, making them easier to predict from partial information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 5000 records\n",
      "Number of targets: 23\n",
      "Target categories:\n",
      "  - State-level: 12 targets (4 states × 3 metrics)\n",
      "  - Gender: 4 targets (2 genders × 2 metrics)\n",
      "  - Age groups: 4 targets\n",
      "  - Overall: 3 targets\n",
      "\n",
      "Note: Many targets overlap (e.g., total_income = sum of state incomes)\n"
     ]
    }
   ],
   "source": [
    "# Create synthetic data with structure\n",
    "n_samples = 5000\n",
    "\n",
    "# Demographics\n",
    "age = np.random.randint(18, 80, n_samples)\n",
    "gender = np.random.choice(['M', 'F'], n_samples)\n",
    "state = np.random.choice(['CA', 'NY', 'TX', 'FL'], n_samples, p=[0.35, 0.25, 0.25, 0.15])\n",
    "\n",
    "# Income (correlated with age and state)\n",
    "base_income = 30000\n",
    "state_multiplier = {'CA': 1.3, 'NY': 1.2, 'TX': 1.0, 'FL': 0.95}\n",
    "income = (base_income + (age - 18) * 800).astype(float)  # Ensure float type\n",
    "for s in ['CA', 'NY', 'TX', 'FL']:\n",
    "    mask = state == s\n",
    "    income[mask] *= state_multiplier[s]\n",
    "income += np.random.normal(0, 10000, n_samples)\n",
    "income = np.maximum(income, 15000)\n",
    "\n",
    "# Employment (correlated with age)\n",
    "emp_prob = 0.8 - np.maximum(0, (age - 60) / 20)\n",
    "emp_prob = np.clip(emp_prob, 0, 1)  # Ensure valid probability range\n",
    "employed = np.random.binomial(1, emp_prob)\n",
    "\n",
    "# Create estimate matrix with various overlapping targets\n",
    "estimate_matrix = pd.DataFrame()\n",
    "\n",
    "# State-level targets\n",
    "for s in ['CA', 'NY', 'TX', 'FL']:\n",
    "    mask = state == s\n",
    "    estimate_matrix[f'pop_{s}'] = mask.astype(float)\n",
    "    estimate_matrix[f'income_{s}'] = mask * income\n",
    "    estimate_matrix[f'employed_{s}'] = mask * employed\n",
    "\n",
    "# Gender targets\n",
    "for g in ['M', 'F']:\n",
    "    mask = gender == g\n",
    "    estimate_matrix[f'pop_{g}'] = mask.astype(float)\n",
    "    estimate_matrix[f'income_{g}'] = mask * income\n",
    "\n",
    "# Age group targets\n",
    "age_groups = pd.cut(age, bins=[0, 35, 50, 65, 100], labels=['18-35', '36-50', '51-65', '65+'])\n",
    "for ag in age_groups.unique():\n",
    "    mask = age_groups == ag\n",
    "    estimate_matrix[f'pop_age_{ag}'] = mask.astype(float)\n",
    "\n",
    "# Overall targets\n",
    "estimate_matrix['total_population'] = 1.0\n",
    "estimate_matrix['total_income'] = income\n",
    "estimate_matrix['total_employed'] = employed\n",
    "\n",
    "# Create realistic targets\n",
    "true_totals = estimate_matrix.sum().values\n",
    "# Add some noise to make calibration non-trivial\n",
    "noise = np.random.normal(1.0, 0.03, len(true_totals))\n",
    "targets = true_totals * noise\n",
    "\n",
    "print(f\"Dataset: {n_samples} records\")\n",
    "print(f\"Number of targets: {len(targets)}\")\n",
    "print(f\"Target categories:\")\n",
    "print(f\"  - State-level: 12 targets (4 states × 3 metrics)\")\n",
    "print(f\"  - Gender: 4 targets (2 genders × 2 metrics)\")\n",
    "print(f\"  - Age groups: 4 targets\")\n",
    "print(f\"  - Overall: 3 targets\")\n",
    "print(f\"\\nNote: Many targets overlap (e.g., total_income = sum of state incomes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic robustness evaluation\n",
    "\n",
    "Let's evaluate the robustness of a standard calibration without regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data leakage warning: Targets often share overlapping information (e.g., geographic breakdowns like 'snap in CA' and 'snap in US'). Holdout validation may not provide complete isolation between training and validation sets. The robustness metrics should be interpreted with this limitation in mind - they may overestimate the model's true generalization performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating calibration robustness...\n",
      "This will perform multiple rounds of holdout validation.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reweighting progress: 100%|██████████| 200/200 [00:00<00:00, 1703.46epoch/s, loss=16.4, weights_mean=5.08, weights_std=2.41, weights_min=0.84] \n",
      "Reweighting progress: 100%|██████████| 200/200 [00:00<00:00, 1172.65epoch/s, loss=15.7, weights_mean=4.98, weights_std=2.41, weights_min=0.84] \n",
      "Reweighting progress: 100%|██████████| 200/200 [00:00<00:00, 1848.77epoch/s, loss=16.5, weights_mean=5.02, weights_std=2.41, weights_min=0.839]\n",
      "Reweighting progress: 100%|██████████| 200/200 [00:00<00:00, 1536.10epoch/s, loss=16.3, weights_mean=5.03, weights_std=2.44, weights_min=0.844]\n",
      "Reweighting progress: 100%|██████████| 200/200 [00:00<00:00, 2512.73epoch/s, loss=16.4, weights_mean=5.01, weights_std=2.42, weights_min=0.839]\n",
      "Reweighting progress: 100%|██████████| 200/200 [00:00<00:00, 2495.60epoch/s, loss=16.1, weights_mean=5.03, weights_std=2.42, weights_min=0.84]\n",
      "Reweighting progress: 100%|██████████| 200/200 [00:00<00:00, 2466.74epoch/s, loss=16.1, weights_mean=5.06, weights_std=2.42, weights_min=0.839]\n",
      "Reweighting progress: 100%|██████████| 200/200 [00:00<00:00, 2451.46epoch/s, loss=16.2, weights_mean=5.02, weights_std=2.4, weights_min=0.84]\n",
      "Reweighting progress: 100%|██████████| 200/200 [00:00<00:00, 1529.99epoch/s, loss=16.6, weights_mean=5.05, weights_std=2.43, weights_min=0.842]\n",
      "Reweighting progress: 100%|██████████| 200/200 [00:00<00:00, 2534.02epoch/s, loss=16.7, weights_mean=5.05, weights_std=2.4, weights_min=0.846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Robustness evaluation complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize calibration\n",
    "weights_init = np.ones(n_samples)\n",
    "\n",
    "cal = Calibration(\n",
    "    weights=weights_init,\n",
    "    targets=targets,\n",
    "    estimate_matrix=estimate_matrix,\n",
    "    epochs=200,\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "\n",
    "print(\"Evaluating calibration robustness...\")\n",
    "print(\"This will perform multiple rounds of holdout validation.\\n\")\n",
    "\n",
    "# Evaluate robustness\n",
    "robustness_results = cal.evaluate_holdout_robustness(\n",
    "    n_holdout_sets=10,    # Number of random holdout sets to test\n",
    "    holdout_fraction=0.3,   # Hold out 30% of targets each round\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Robustness evaluation complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing robustness results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall robustness metrics:\n",
      "  Average holdout accuracy: 0.0%\n",
      "  Std dev of accuracies: 0.0%\n",
      "  Worst holdout accuracy: 0.0%\n",
      "  Best holdout accuracy: 0.0%\n",
      "\n",
      "Generalization gap:\n",
      "  Average training accuracy: 0.0%\n",
      "  Average holdout accuracy: 0.0%\n",
      "  Gap: 0.0%\n",
      "\n",
      "Consistency score: 1.00/1.00\n",
      "  (Higher is better - measures stability across rounds)\n"
     ]
    }
   ],
   "source": [
    "# Display overall metrics\n",
    "metrics = robustness_results['overall_metrics']\n",
    "print(\"Overall robustness metrics:\")\n",
    "print(f\"  Average holdout accuracy: {metrics['mean_holdout_accuracy']:.1%}\")\n",
    "print(f\"  Std dev of accuracies: {metrics['std_holdout_accuracy']:.1%}\")\n",
    "print(f\"  Worst holdout accuracy: {metrics['worst_holdout_accuracy']:.1%}\")\n",
    "print(f\"  Best holdout accuracy: {metrics['best_holdout_accuracy']:.1%}\")\n",
    "print()\n",
    "print(f\"Generalization gap:\")\n",
    "print(f\"  Average training accuracy: {metrics['mean_train_accuracy']:.1%}\")\n",
    "print(f\"  Average holdout accuracy: {metrics['mean_holdout_accuracy']:.1%}\")\n",
    "print(f\"  Gap: {metrics['mean_train_accuracy'] - metrics['mean_holdout_accuracy']:.1%}\")\n",
    "print()\n",
    "# Calculate consistency score (1 - coefficient of variation)\n",
    "consistency_score = 1 - (metrics['std_holdout_accuracy'] / max(metrics['mean_holdout_accuracy'], 0.01))\n",
    "print(f\"Consistency score: {consistency_score:.2f}/1.00\")\n",
    "print(f\"  (Higher is better - measures stability across rounds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most difficult targets to predict (when held out):\n",
      "target_name  holdout_accuracy_rate  times_held_out\n",
      "     pop_CA                    0.0               2\n",
      "  income_CA                    0.0               3\n",
      "employed_CA                    0.0               2\n",
      "  income_NY                    0.0               1\n",
      "employed_NY                    0.0               3\n",
      "     pop_TX                    0.0               3\n",
      "  income_TX                    0.0               2\n",
      "employed_TX                    0.0               1\n",
      "     pop_FL                    0.0               6\n",
      "  income_FL                    0.0               3\n",
      "\n",
      "Easiest targets to predict (when held out):\n",
      "     target_name  holdout_accuracy_rate  times_held_out\n",
      "   pop_age_36-50                    0.0               2\n",
      "   pop_age_18-35                    0.0               1\n",
      "total_population                    0.0               1\n",
      "    total_income                    0.0               3\n",
      "  total_employed                    0.0               3\n"
     ]
    }
   ],
   "source": [
    "# Show target-level difficulty\n",
    "target_robustness = robustness_results['target_robustness']\n",
    "\n",
    "# Sort by accuracy (lower accuracy = higher difficulty)\n",
    "target_robustness = target_robustness.sort_values('holdout_accuracy_rate', ascending=True)\n",
    "\n",
    "print(\"\\nMost difficult targets to predict (when held out):\")\n",
    "print(target_robustness.head(10)[['target_name', 'holdout_accuracy_rate', 'times_held_out']].to_string(index=False))\n",
    "\n",
    "print(\"\\nEasiest targets to predict (when held out):\")\n",
    "print(target_robustness.tail(5)[['target_name', 'holdout_accuracy_rate', 'times_held_out']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the recommendation\n",
    "\n",
    "The robustness evaluation provides actionable recommendations based on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBUSTNESS EVALUATION RECOMMENDATION\n",
      "============================================================\n",
      "❌ POOR ROBUSTNESS: The calibration shows weak generalization.\n",
      "On average, 0.0% of held-out targets are within 10% of their true values.\n",
      " ⚠️ Worst-case scenario: Only 0.0% accuracy in some holdout sets.\n",
      "\n",
      "📊 Targets with poor holdout performance (<50% accuracy):\n",
      "  - pop_CA: 0.0% accuracy\n",
      "  - total_population: 0.0% accuracy\n",
      "  - pop_age_18-35: 0.0% accuracy\n",
      "  - pop_age_36-50: 0.0% accuracy\n",
      "  - pop_age_65+: 0.0% accuracy\n",
      "\n",
      "💡 RECOMMENDATIONS:\n",
      "  1. Consider enabling L0 regularization for better generalization\n",
      "  2. Increase the noise_level parameter to improve robustness\n",
      "  3. Try increasing dropout_rate to reduce overfitting\n",
      "  4. Investigate why these targets are hard to predict: pop_CA, total_population, pop_age_18-35\n",
      "  5. Consider if these targets have sufficient support in the microdata\n",
      "  6. Generalization gap of 0.1811 suggests some overfitting - consider regularization\n",
      "============================================================\n",
      "\n",
      "Additional suggestions for poor robustness:\n",
      "1. Consider using L0 regularization to reduce overfitting\n",
      "2. Review targets with highest difficulty scores\n",
      "3. Check for data quality issues in difficult targets\n",
      "4. Consider removing highly correlated redundant targets\n"
     ]
    }
   ],
   "source": [
    "print(\"ROBUSTNESS EVALUATION RECOMMENDATION\")\n",
    "print(\"=\"*60)\n",
    "print(robustness_results['recommendation'])\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Additional analysis based on results\n",
    "metrics = robustness_results['overall_metrics']\n",
    "if metrics['mean_holdout_accuracy'] < 0.8:\n",
    "    print(\"\\nAdditional suggestions for poor robustness:\")\n",
    "    print(\"1. Consider using L0 regularization to reduce overfitting\")\n",
    "    print(\"2. Review targets with highest difficulty scores\")\n",
    "    print(\"3. Check for data quality issues in difficult targets\")\n",
    "    print(\"4. Consider removing highly correlated redundant targets\")\n",
    "elif metrics['std_holdout_accuracy'] > 0.1:\n",
    "    print(\"\\nAdditional suggestions for high variability:\")\n",
    "    print(\"1. Some target combinations may be inherently difficult\")\n",
    "    print(\"2. Consider grouping related targets\")\n",
    "    print(\"3. Increase epochs to ensure convergence\")\n",
    "else:\n",
    "    print(\"\\nYour calibration shows good robustness!\")\n",
    "    print(\"Consider saving these settings for production use.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Custom holdout strategies\n",
    "\n",
    "You can implement custom holdout strategies for specific evaluation needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 2407.43epoch/s, loss=20.1, weights_mean=5.5, weights_std=2.64, weights_min=0.918]\n",
      "Reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 2500.32epoch/s, loss=20.4, weights_mean=5.5, weights_std=2.62, weights_min=0.919]\n",
      "Reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 2694.62epoch/s, loss=21, weights_mean=5.56, weights_std=2.67, weights_min=0.918]\n",
      "Reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 2461.17epoch/s, loss=20, weights_mean=5.43, weights_std=2.68, weights_min=0.917]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robustness by target category:\n",
      "      Category  N targets Mean error Max error Within 10%\n",
      " State targets         12     449.3%    494.2%         0%\n",
      "Gender targets          7     445.0%    477.2%         0%\n",
      "   Age targets          4     450.4%    470.4%         0%\n",
      " Total targets          3     422.9%    425.1%         0%\n",
      "\n",
      "Interpretation:\n",
      "- Lower errors indicate targets that can be predicted from others\n",
      "- High errors suggest independent information in those targets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example: Evaluate robustness by holding out entire target categories\n",
    "def evaluate_by_category():\n",
    "    categories = {\n",
    "        'State targets': [i for i, name in enumerate(estimate_matrix.columns) \n",
    "                         if any(s in name for s in ['CA', 'NY', 'TX', 'FL'])],\n",
    "        'Gender targets': [i for i, name in enumerate(estimate_matrix.columns) \n",
    "                          if any(g in name for g in ['_M', '_F'])],\n",
    "        'Age targets': [i for i, name in enumerate(estimate_matrix.columns) \n",
    "                       if 'age' in name],\n",
    "        'Total targets': [i for i, name in enumerate(estimate_matrix.columns) \n",
    "                         if 'total' in name],\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for category, indices in categories.items():\n",
    "        if len(indices) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Create masks for train and holdout\n",
    "        train_mask = np.ones(len(targets), dtype=bool)\n",
    "        train_mask[indices] = False\n",
    "        \n",
    "        # Skip if too few training targets remain\n",
    "        if train_mask.sum() < 3:\n",
    "            continue\n",
    "        \n",
    "        # Calibrate on subset\n",
    "        cal_temp = Calibration(\n",
    "            weights=weights_init.copy(),\n",
    "            targets=targets[train_mask],\n",
    "            estimate_matrix=estimate_matrix.iloc[:, train_mask],\n",
    "            epochs=100,\n",
    "            learning_rate=1e-3,\n",
    "        )\n",
    "        \n",
    "        # Suppress logging for cleaner output\n",
    "        import logging\n",
    "        original_level = logging.getLogger().level\n",
    "        logging.getLogger().setLevel(logging.WARNING)\n",
    "        \n",
    "        try:\n",
    "            cal_temp.calibrate()\n",
    "            \n",
    "            # Evaluate on holdout\n",
    "            holdout_estimates = (estimate_matrix.iloc[:, indices].T * cal_temp.weights).sum(axis=1).values\n",
    "            holdout_targets = targets[indices]\n",
    "            holdout_errors = np.abs((holdout_estimates - holdout_targets) / holdout_targets)\n",
    "            \n",
    "            results.append({\n",
    "                'Category': category,\n",
    "                'N targets': len(indices),\n",
    "                'Mean error': f\"{np.mean(holdout_errors):.1%}\",\n",
    "                'Max error': f\"{np.max(holdout_errors):.1%}\",\n",
    "                'Within 10%': f\"{100*np.mean(holdout_errors < 0.1):.0f}%\"\n",
    "            })\n",
    "        finally:\n",
    "            # Restore logging level\n",
    "            logging.getLogger().setLevel(original_level)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "category_results = evaluate_by_category()\n",
    "print(\"Robustness by target category:\")\n",
    "print(category_results.to_string(index=False))\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Lower errors indicate targets that can be predicted from others\")\n",
    "print(\"- High errors suggest independent information in those targets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best practices for robustness evaluation\n",
    "\n",
    "### 1. Choose appropriate holdout parameters\n",
    "- **Holdout fraction**: 20-30% is typically good\n",
    "- **Number of rounds**: At least 5-10 for reliable estimates\n",
    "- **Epochs per round**: Enough to converge (check loss curves)\n",
    "\n",
    "### 2. Interpret results carefully\n",
    "- **High variability**: Indicates unstable calibration\n",
    "- **Large generalization gap**: Suggests overfitting\n",
    "- **Low consistency**: Some target combinations are problematic\n",
    "\n",
    "### 3. Be aware of data leakage\n",
    "Since many calibration targets share information (e.g., 'total_income' includes all state incomes), holdout validation may give optimistic results. The evaluation includes a warning about this.\n",
    "\n",
    "### 4. Use results to improve calibration\n",
    "- Add regularization if overfitting is detected\n",
    "- Remove or combine highly correlated targets\n",
    "- Investigate targets with high difficulty scores\n",
    "- Consider different optimization parameters\n",
    "\n",
    "### 5. Document your evaluation\n",
    "Save robustness results along with your calibration parameters for reproducibility and comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "After evaluating robustness:\n",
    "\n",
    "1. If robustness is poor, try:\n",
    "   - Hyperparameter tuning to find better L0 parameters\n",
    "   - Reviewing and cleaning your targets\n",
    "   - Increasing the dataset size\n",
    "\n",
    "2. If robustness is good:\n",
    "   - Save your calibration configuration\n",
    "   - Apply to production data\n",
    "   - Monitor performance over time\n",
    "\n",
    "3. For specific issues:\n",
    "   - High difficulty targets → Check data quality\n",
    "   - Large generalization gap → Add regularization\n",
    "   - High variability → Increase epochs or adjust learning rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pe3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
