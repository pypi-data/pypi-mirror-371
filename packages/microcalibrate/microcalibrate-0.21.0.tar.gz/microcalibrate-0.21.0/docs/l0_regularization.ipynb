{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L0 regularization for sparse weights\n",
    "\n",
    "L0 regularization is a powerful technique that creates sparse weights during calibration, effectively reducing the dataset size by setting many weights to zero. This is particularly useful when:\n",
    "\n",
    "- You need to reduce computational costs in downstream processing\n",
    "- You want to identify the most important records in your dataset\n",
    "- You need a smaller, representative sample that still matches population targets\n",
    "\n",
    "## How L0 regularization works\n",
    "\n",
    "L0 regularization adds a penalty term to the calibration loss that encourages weights to be exactly zero. Unlike L1 regularization (which shrinks weights), L0 creates truly sparse solutions by using a differentiable approximation of the L0 norm through the Hard Concrete distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from microcalibrate import Calibration\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "calibration_logger = logging.getLogger(\"microcalibrate.calibration\")\n",
    "calibration_logger.setLevel(logging.WARNING)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Basic L0 regularization\n",
    "\n",
    "Let's create a synthetic dataset and apply L0 regularization to reduce its size while maintaining calibration accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 5000 records\n",
      "Number of targets: 10\n",
      "Target names: ['income_18-30', 'employed_18-30', 'income_31-50', 'employed_31-50', 'income_51-65', 'employed_51-65', 'income_65+', 'employed_65+', 'total_income', 'total_employed']\n"
     ]
    }
   ],
   "source": [
    "# Create synthetic data\n",
    "n_samples = 5000\n",
    "n_targets = 10\n",
    "\n",
    "# Generate random data with some structure\n",
    "age_groups = np.random.choice(['18-30', '31-50', '51-65', '65+'], n_samples)\n",
    "income = np.random.lognormal(10.5, 0.8, n_samples)  # Log-normal income distribution\n",
    "employed = np.random.binomial(1, 0.65, n_samples)\n",
    "\n",
    "# Create estimate matrix with various demographic combinations\n",
    "estimate_matrix = pd.DataFrame()\n",
    "for age in ['18-30', '31-50', '51-65', '65+']:\n",
    "    mask = age_groups == age\n",
    "    estimate_matrix[f'income_{age}'] = mask * income\n",
    "    estimate_matrix[f'employed_{age}'] = mask * employed\n",
    "\n",
    "estimate_matrix['total_income'] = income\n",
    "estimate_matrix['total_employed'] = employed\n",
    "\n",
    "# Set realistic targets (scaled population values)\n",
    "targets = estimate_matrix.sum().values * 1.1  # 10% higher than unweighted\n",
    "\n",
    "print(f\"Dataset size: {n_samples} records\")\n",
    "print(f\"Number of targets: {len(targets)}\")\n",
    "print(f\"Target names: {list(estimate_matrix.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing standard vs L0 calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running standard calibration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reweighting progress: 100%|██████████| 200/200 [00:00<00:00, 2660.14epoch/s, loss=13.2, weights_mean=5.1, weights_std=2.42, weights_min=0.842]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standard calibration results:\n",
      "Non-zero weights: 5000 (100.0%)\n",
      "Weight range: [0.835, 9.164]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Standard calibration (no sparsity)\n",
    "weights_init = np.ones(n_samples)\n",
    "\n",
    "cal_standard = Calibration(\n",
    "    weights=weights_init.copy(),\n",
    "    targets=targets,\n",
    "    estimate_matrix=estimate_matrix,\n",
    "    epochs=200,\n",
    "    learning_rate=1e-3,\n",
    "    regularize_with_l0=False\n",
    ")\n",
    "\n",
    "print(\"Running standard calibration...\")\n",
    "perf_standard = cal_standard.calibrate()\n",
    "weights_standard = cal_standard.weights\n",
    "\n",
    "print(f\"\\nStandard calibration results:\")\n",
    "print(f\"Non-zero weights: {np.sum(weights_standard != 0)} ({100*np.mean(weights_standard != 0):.1f}%)\")\n",
    "print(f\"Weight range: [{weights_standard.min():.3f}, {weights_standard.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running L0 regularized calibration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reweighting progress: 100%|██████████| 200/200 [00:00<00:00, 1776.92epoch/s, loss=13.5, weights_mean=5.13, weights_std=2.43, weights_min=0.84] \n",
      "Sparse reweighting progress: 100%|██████████| 400/400 [00:00<00:00, 722.65epoch/s, loss=0.0103, loss_rel_change=-0.691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L0 calibration results:\n",
      "Non-zero weights: 1998 (40.0%)\n",
      "Dataset reduction: 60.0%\n",
      "Weight range: [0.010, 14.061]\n"
     ]
    }
   ],
   "source": [
    "# L0 regularized calibration\n",
    "cal_l0 = Calibration(\n",
    "    weights=weights_init.copy(),\n",
    "    targets=targets,\n",
    "    estimate_matrix=estimate_matrix,\n",
    "    epochs=200,\n",
    "    learning_rate=1e-3,\n",
    "    regularize_with_l0=True,\n",
    "    l0_lambda=5e-6,      # Regularization strength\n",
    "    init_mean=0.999,     # Start with most weights active\n",
    "    temperature=0.5,     # Controls sparsity gradient\n",
    ")\n",
    "\n",
    "print(\"Running L0 regularized calibration...\")\n",
    "perf_l0 = cal_l0.calibrate()\n",
    "weights_l0 = cal_l0.sparse_weights\n",
    "\n",
    "print(f\"\\nL0 calibration results:\")\n",
    "print(f\"Non-zero weights: {np.sum(weights_l0 != 0)} ({100*np.mean(weights_l0 != 0):.1f}%)\")\n",
    "print(f\"Dataset reduction: {100*(1 - np.mean(weights_l0 != 0)):.1f}%\")\n",
    "print(f\"Weight range: [{weights_l0[weights_l0>0].min():.3f}, {weights_l0.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning for L0 regularization\n",
    "\n",
    "Finding the optimal L0 regularization parameters is crucial for achieving the right balance between sparsity and calibration accuracy. This notebook demonstrates how to use the automatic hyperparameter tuning feature to find the best parameters for your specific dataset.\n",
    "\n",
    "## Why hyperparameter tuning matters\n",
    "\n",
    "L0 regularization has three key parameters that interact in complex ways:\n",
    "- **l0_lambda**: Controls the strength of sparsity penalty\n",
    "- **init_mean**: Sets the initial proportion of active weights\n",
    "- **temperature**: Determines how \"hard\" the sparsity decisions are\n",
    "\n",
    "Manual tuning can be time-consuming and may miss optimal combinations. The automatic tuning uses Optuna to efficiently search the parameter space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic hyperparameter tuning\n",
    "\n",
    "Let's start with a simple tuning run to find good L0 parameters. The tuning process will:\n",
    "1. Create multiple holdout sets for cross-validation\n",
    "2. Try different parameter combinations\n",
    "3. Evaluate each combination on both training and validation targets\n",
    "4. Select the best parameters based on a multi-objective criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:microcalibrate.hyperparameter_tuning:Multi-holdout hyperparameter tuning:\n",
      "  - 3 holdout sets\n",
      "  - 2 targets per holdout (20.0%)\n",
      "  - Aggregation: mean\n",
      "\n",
      "WARNING:microcalibrate.hyperparameter_tuning:Data leakage warning: Targets often share overlapping information (e.g., geographic breakdowns like 'snap in CA' and 'snap in US'). Holdout validation may not provide complete isolation between training and validation sets. The robustness metrics should be interpreted with this limitation in mind - they may overestimate the model's true generalization performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter tuning...\n",
      "This will take a few minutes as it explores different parameter combinations.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fd8b3742ea4b07b12ca58d3ea857ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1549.46epoch/s, loss=17.2, weights_mean=5.7, weights_std=2.74, weights_min=0.962]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 347.13epoch/s, loss=0.0279, loss_rel_change=-0.485]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1961.55epoch/s, loss=68, weights_mean=10.2, weights_std=3.83, weights_min=1.05]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 357.60epoch/s, loss=0.0297, loss_rel_change=-0.998]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1983.82epoch/s, loss=148, weights_mean=14.5, weights_std=4.58, weights_min=1.48]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 296.82epoch/s, loss=0.0652, loss_rel_change=-0.999]\n",
      "INFO:microcalibrate.hyperparameter_tuning:Trial 0:\n",
      "  Objectives by holdout: ['109.9197', '110.0278', '10.0005']\n",
      "  Mean objective: 76.6493\n",
      "  Mean val accuracy: 33.33% (±47.14%)\n",
      "  Sparsity: 0.00%\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1506.98epoch/s, loss=252, weights_mean=18.6, weights_std=5.22, weights_min=2.08]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 342.20epoch/s, loss=0.0483, loss_rel_change=-0.999]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1877.67epoch/s, loss=377, weights_mean=22.5, weights_std=5.71, weights_min=6.05]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 293.54epoch/s, loss=0.0579, loss_rel_change=-0.999]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 760.92epoch/s, loss=519, weights_mean=26.3, weights_std=6.09, weights_min=6.69]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 285.17epoch/s, loss=0.122, loss_rel_change=-0.999]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1814.74epoch/s, loss=680, weights_mean=29.9, weights_std=6.44, weights_min=8.01]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 333.69epoch/s, loss=0.012, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1365.93epoch/s, loss=850, weights_mean=33.2, weights_std=6.73, weights_min=9.59]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 306.98epoch/s, loss=0.00717, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 684.75epoch/s, loss=1.03e+3, weights_mean=36.5, weights_std=7.01, weights_min=14.7]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 330.39epoch/s, loss=0.0122, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1853.43epoch/s, loss=1.22e+3, weights_mean=39.6, weights_std=7.17, weights_min=15.2]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 270.74epoch/s, loss=0.18, loss_rel_change=-0.999]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1673.64epoch/s, loss=1.41e+3, weights_mean=42.5, weights_std=7.37, weights_min=17.3]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 314.66epoch/s, loss=0.162, loss_rel_change=-0.999]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1858.19epoch/s, loss=1.61e+3, weights_mean=45.4, weights_std=7.5, weights_min=17.6]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 300.71epoch/s, loss=0.148, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1888.00epoch/s, loss=1.81e+3, weights_mean=48, weights_std=7.69, weights_min=19.8]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 320.72epoch/s, loss=0.154, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1826.56epoch/s, loss=2e+3, weights_mean=50.5, weights_std=7.84, weights_min=25.2]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 345.48epoch/s, loss=0.144, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1912.76epoch/s, loss=2.2e+3, weights_mean=52.9, weights_std=8.03, weights_min=25.7]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 346.88epoch/s, loss=0.139, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1808.84epoch/s, loss=2.41e+3, weights_mean=55.2, weights_std=8.14, weights_min=27]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 297.11epoch/s, loss=0.0109, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 2018.82epoch/s, loss=2.6e+3, weights_mean=57.4, weights_std=8.17, weights_min=31.8]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 266.95epoch/s, loss=0.0126, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1980.28epoch/s, loss=2.81e+3, weights_mean=59.5, weights_std=8.27, weights_min=31.4]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 311.84epoch/s, loss=0.0114, loss_rel_change=-1]\n",
      "INFO:microcalibrate.hyperparameter_tuning:Trial 5:\n",
      "  Objectives by holdout: ['110.2807', '110.2407', '110.2354']\n",
      "  Mean objective: 110.2523\n",
      "  Mean val accuracy: 0.00% (±0.00%)\n",
      "  Sparsity: 3.16%\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 2016.38epoch/s, loss=3.01e+3, weights_mean=61.5, weights_std=8.41, weights_min=30.5]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 300.27epoch/s, loss=0.0303, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1813.63epoch/s, loss=3.19e+3, weights_mean=63.3, weights_std=8.48, weights_min=30.6]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 348.51epoch/s, loss=0.0383, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1943.34epoch/s, loss=3.39e+3, weights_mean=65.1, weights_std=8.49, weights_min=34]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 291.53epoch/s, loss=0.0413, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1881.48epoch/s, loss=3.58e+3, weights_mean=66.9, weights_std=8.61, weights_min=37.4]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 354.18epoch/s, loss=0.0203, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1999.21epoch/s, loss=3.75e+3, weights_mean=68.5, weights_std=8.63, weights_min=37.6]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 355.29epoch/s, loss=0.00945, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 731.52epoch/s, loss=3.94e+3, weights_mean=70.2, weights_std=8.67, weights_min=38.7]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 318.25epoch/s, loss=0.0231, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 2034.75epoch/s, loss=4.12e+3, weights_mean=71.7, weights_std=8.75, weights_min=41.7]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 297.68epoch/s, loss=0.658, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1994.67epoch/s, loss=4.27e+3, weights_mean=73.2, weights_std=8.79, weights_min=40.8]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 316.13epoch/s, loss=0.665, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 737.44epoch/s, loss=4.44e+3, weights_mean=74.5, weights_std=8.83, weights_min=42.8]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 311.54epoch/s, loss=0.825, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1816.41epoch/s, loss=4.6e+3, weights_mean=75.8, weights_std=8.89, weights_min=43.2]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 283.56epoch/s, loss=0.359, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1865.69epoch/s, loss=4.75e+3, weights_mean=77, weights_std=8.86, weights_min=44.9]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 369.63epoch/s, loss=0.402, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 2012.95epoch/s, loss=4.91e+3, weights_mean=78.2, weights_std=8.88, weights_min=44.9]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 319.55epoch/s, loss=0.463, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 2031.77epoch/s, loss=5.05e+3, weights_mean=79.3, weights_std=8.87, weights_min=48.5]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 296.65epoch/s, loss=0.386, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1906.16epoch/s, loss=5.18e+3, weights_mean=80.4, weights_std=8.89, weights_min=51.5]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 262.07epoch/s, loss=0.375, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1541.84epoch/s, loss=5.32e+3, weights_mean=81.4, weights_std=8.93, weights_min=51]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 221.70epoch/s, loss=0.472, loss_rel_change=-1]\n",
      "INFO:microcalibrate.hyperparameter_tuning:Trial 10:\n",
      "  Objectives by holdout: ['110.1258', '110.1155', '110.1133']\n",
      "  Mean objective: 110.1182\n",
      "  Mean val accuracy: 0.00% (±0.00%)\n",
      "  Sparsity: 0.08%\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1374.11epoch/s, loss=5.45e+3, weights_mean=82.4, weights_std=8.92, weights_min=52.2]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 224.13epoch/s, loss=3.02, loss_rel_change=-0.999]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1509.43epoch/s, loss=5.57e+3, weights_mean=83.3, weights_std=8.89, weights_min=50]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 232.38epoch/s, loss=3.29, loss_rel_change=-0.999]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1050.00epoch/s, loss=5.69e+3, weights_mean=84.1, weights_std=8.96, weights_min=50.8]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 227.71epoch/s, loss=3.33, loss_rel_change=-0.999]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1599.43epoch/s, loss=5.79e+3, weights_mean=84.9, weights_std=8.94, weights_min=53.9]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 232.27epoch/s, loss=3.73, loss_rel_change=-0.999]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1640.21epoch/s, loss=5.9e+3, weights_mean=85.7, weights_std=9, weights_min=52.3]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 205.89epoch/s, loss=3.88, loss_rel_change=-0.999]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1071.53epoch/s, loss=6.03e+3, weights_mean=86.5, weights_std=9.03, weights_min=56.3]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 178.22epoch/s, loss=3.88, loss_rel_change=-0.999]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1378.17epoch/s, loss=6.13e+3, weights_mean=87.2, weights_std=9.02, weights_min=58.2]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 187.56epoch/s, loss=1.11, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 990.38epoch/s, loss=6.22e+3, weights_mean=88, weights_std=9.08, weights_min=58.1]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 235.56epoch/s, loss=1.28, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1169.07epoch/s, loss=6.34e+3, weights_mean=88.6, weights_std=9.05, weights_min=56.1]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 189.05epoch/s, loss=1.24, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1263.08epoch/s, loss=6.42e+3, weights_mean=89.2, weights_std=9, weights_min=59.5]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 186.46epoch/s, loss=1.8, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1296.58epoch/s, loss=6.5e+3, weights_mean=89.8, weights_std=9.05, weights_min=59.1]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 187.17epoch/s, loss=1.74, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1361.70epoch/s, loss=6600.0, weights_mean=90.4, weights_std=9.1, weights_min=59.8]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 208.56epoch/s, loss=1.91, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1469.60epoch/s, loss=6.67e+3, weights_mean=90.9, weights_std=9.05, weights_min=57.9]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 192.95epoch/s, loss=1.39, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1604.42epoch/s, loss=6.74e+3, weights_mean=91.4, weights_std=9.13, weights_min=59]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 193.51epoch/s, loss=1.31, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1444.58epoch/s, loss=6.83e+3, weights_mean=91.9, weights_std=9.18, weights_min=62.7]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 189.72epoch/s, loss=1.39, loss_rel_change=-1]\n",
      "INFO:microcalibrate.hyperparameter_tuning:Trial 15:\n",
      "  Objectives by holdout: ['9.9997', '10.0021', '9.9987']\n",
      "  Mean objective: 10.0001\n",
      "  Mean val accuracy: 100.00% (±0.00%)\n",
      "  Sparsity: 0.04%\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 862.93epoch/s, loss=6.91e+3, weights_mean=92.4, weights_std=9.19, weights_min=63.2]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 186.64epoch/s, loss=1.34, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 986.41epoch/s, loss=6.97e+3, weights_mean=92.9, weights_std=9.12, weights_min=63.4]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 162.70epoch/s, loss=1.33, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1075.04epoch/s, loss=7.05e+3, weights_mean=93.4, weights_std=9.14, weights_min=61.7]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 195.61epoch/s, loss=1.39, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1250.63epoch/s, loss=7.1e+3, weights_mean=93.7, weights_std=9.12, weights_min=62.1]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 162.61epoch/s, loss=1.02, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1480.33epoch/s, loss=7.16e+3, weights_mean=94.1, weights_std=9.16, weights_min=64.4]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 213.27epoch/s, loss=1.09, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1535.44epoch/s, loss=7.21e+3, weights_mean=94.4, weights_std=9.22, weights_min=63.9]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 226.69epoch/s, loss=0.932, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1697.40epoch/s, loss=7.27e+3, weights_mean=94.8, weights_std=9.26, weights_min=63.5]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 195.13epoch/s, loss=1.27, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1298.33epoch/s, loss=7.3e+3, weights_mean=95.1, weights_std=9.23, weights_min=64.6]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 218.78epoch/s, loss=1.2, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1068.55epoch/s, loss=7.36e+3, weights_mean=95.4, weights_std=9.22, weights_min=66.3]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 199.13epoch/s, loss=1.38, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1222.49epoch/s, loss=7.4e+3, weights_mean=95.6, weights_std=9.21, weights_min=66.4]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 173.33epoch/s, loss=0.891, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1347.59epoch/s, loss=7.41e+3, weights_mean=95.9, weights_std=9.22, weights_min=63.8]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 194.97epoch/s, loss=0.814, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 50/50 [00:00<00:00, 1135.51epoch/s, loss=7.48e+3, weights_mean=96.2, weights_std=9.25, weights_min=65.2]\n",
      "Sparse reweighting progress: 100%|██████████| 100/100 [00:00<00:00, 188.28epoch/s, loss=0.814, loss_rel_change=-1]\n",
      "INFO:microcalibrate.hyperparameter_tuning:\n",
      "Multi-holdout tuning completed!\n",
      "Best parameters:\n",
      "  - l0_lambda: 7.43e-05\n",
      "  - init_mean: 0.8443\n",
      "  - temperature: 1.7891\n",
      "Performance across 3 holdouts:\n",
      "  - Mean val loss: 0.002145 (±0.000429)\n",
      "  - Mean val accuracy: 100.00% (±0.00%)\n",
      "  - Individual objectives: ['9.9997', '10.0021', '9.9987']\n",
      "  - Sparsity: 0.04%\n",
      "\n",
      "Evaluation history saved with 60 records across 20 trials.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Tuning completed!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Initialize calibration object\n",
    "weights_init = np.ones(n_samples)\n",
    "\n",
    "cal = Calibration(\n",
    "    weights=weights_init,\n",
    "    targets=targets,\n",
    "    estimate_matrix=estimate_matrix,\n",
    "    epochs=100,  # Will be overridden during tuning\n",
    "    learning_rate=1e-3,\n",
    ")\n",
    "\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "print(\"This will take a few minutes as it explores different parameter combinations.\\n\")\n",
    "\n",
    "# Run hyperparameter tuning\n",
    "best_params = cal.tune_l0_hyperparameters(\n",
    "    n_trials=20,  # Number of parameter combinations to try\n",
    "    objectives_balance={\n",
    "        'loss': 1.0,       # Weight for calibration loss\n",
    "        'accuracy': 100.0, # Weight for accuracy (targets within 10%)\n",
    "        'sparsity': 10.0,  # Weight for sparsity\n",
    "    },\n",
    "    n_holdout_sets=3,      # Number of cross-validation folds\n",
    "    holdout_fraction=0.2,  # Fraction of targets to hold out\n",
    "    epochs_per_trial=50,   # Epochs per trial (faster for tuning)\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Tuning completed!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing tuning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      "  l0_lambda: 7.43e-05\n",
      "  init_mean: 0.8443\n",
      "  temperature: 1.79\n",
      "\n",
      "Performance metrics:\n",
      "  Mean validation loss: 0.002145 (±0.000429)\n",
      "  Mean validation accuracy: 100.0% (±0.0%)\n",
      "  Sparsity achieved: 0.0%\n",
      "\n",
      "Cross-validation results:\n",
      "  Holdout objectives: [np.float64(9.999662299386227), np.float64(10.002067347057164), np.float64(9.998705346327275)]\n",
      "  Number of holdout sets: 3\n",
      "  Aggregation method: mean\n"
     ]
    }
   ],
   "source": [
    "# Display best parameters\n",
    "print(\"Best parameters found:\")\n",
    "print(f\"  l0_lambda: {best_params['l0_lambda']:.2e}\")\n",
    "print(f\"  init_mean: {best_params['init_mean']:.4f}\")\n",
    "print(f\"  temperature: {best_params['temperature']:.2f}\")\n",
    "print()\n",
    "print(\"Performance metrics:\")\n",
    "print(f\"  Mean validation loss: {best_params['mean_val_loss']:.6f} (±{best_params['std_val_loss']:.6f})\")\n",
    "print(f\"  Mean validation accuracy: {best_params['mean_val_accuracy']:.1%} (±{best_params['std_val_accuracy']:.1%})\")\n",
    "print(f\"  Sparsity achieved: {best_params['sparsity']:.1%}\")\n",
    "print()\n",
    "print(\"Cross-validation results:\")\n",
    "print(f\"  Holdout objectives: {best_params['holdout_objectives']}\")\n",
    "print(f\"  Number of holdout sets: {best_params['n_holdout_sets']}\")\n",
    "print(f\"  Aggregation method: {best_params['aggregation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the best parameters\n",
    "\n",
    "Now let's apply the best parameters found through tuning and compare with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating with tuned parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reweighting progress: 100%|██████████| 200/200 [00:00<00:00, 2654.50epoch/s, loss=12.8, weights_mean=5.02, weights_std=2.41, weights_min=0.84]\n",
      "Sparse reweighting progress: 100%|██████████| 400/400 [00:00<00:00, 678.76epoch/s, loss=0.105, loss_rel_change=-0.786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating with default parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reweighting progress: 100%|██████████| 200/200 [00:00<00:00, 2813.69epoch/s, loss=13.1, weights_mean=5.09, weights_std=2.43, weights_min=0.842]\n",
      "Sparse reweighting progress: 100%|██████████| 400/400 [00:00<00:00, 593.57epoch/s, loss=0.0103, loss_rel_change=-0.691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison complete!\n"
     ]
    }
   ],
   "source": [
    "# Calibration with tuned parameters\n",
    "cal_tuned = Calibration(\n",
    "    weights=weights_init.copy(),\n",
    "    targets=targets,\n",
    "    estimate_matrix=estimate_matrix,\n",
    "    epochs=200,\n",
    "    learning_rate=1e-3,\n",
    "    regularize_with_l0=True,\n",
    "    l0_lambda=best_params['l0_lambda'],\n",
    "    init_mean=best_params['init_mean'],\n",
    "    temperature=best_params['temperature'],\n",
    ")\n",
    "\n",
    "print(\"Calibrating with tuned parameters...\")\n",
    "perf_tuned = cal_tuned.calibrate()\n",
    "weights_tuned = cal_tuned.sparse_weights\n",
    "\n",
    "# Calibration with default parameters\n",
    "cal_default = Calibration(\n",
    "    weights=weights_init.copy(),\n",
    "    targets=targets,\n",
    "    estimate_matrix=estimate_matrix,\n",
    "    epochs=200,\n",
    "    learning_rate=1e-3,\n",
    "    regularize_with_l0=True,\n",
    "    l0_lambda=5e-6,  # Default\n",
    "    init_mean=0.999,  # Default\n",
    "    temperature=0.5,  # Default\n",
    ")\n",
    "\n",
    "print(\"Calibrating with default parameters...\")\n",
    "perf_default = cal_default.calibrate()\n",
    "weights_default = cal_default.sparse_weights\n",
    "\n",
    "print(\"\\nComparison complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameter comparison:\n",
      "         Label  Non-zero weights Sparsity Mean rel error Max rel error Within 1% Within 5% Within 10%\n",
      "Default params              1998    60.0%         0.0250        0.0620     30.0%     90.0%     100.0%\n",
      "  Tuned params              1372    72.6%         0.1008        0.1155      0.0%      0.0%      40.0%\n",
      "\n",
      "==================================================\n",
      "Improvement summary:\n",
      "Sparsity improvement: 12.5%\n",
      "Dataset reduction: 72.6% of records can be dropped\n",
      "Remaining records: 1,372 out of 5,000\n"
     ]
    }
   ],
   "source": [
    "# Compare results\n",
    "def evaluate_calibration(weights, estimate_matrix, targets, label):\n",
    "    estimates = (estimate_matrix.T * weights).sum(axis=1).values\n",
    "    rel_errors = np.abs((estimates - targets) / targets)\n",
    "    \n",
    "    return {\n",
    "        'Label': label,\n",
    "        'Non-zero weights': np.sum(weights != 0),\n",
    "        'Sparsity': f\"{100 * np.mean(weights == 0):.1f}%\",\n",
    "        'Mean rel error': f\"{np.mean(rel_errors):.4f}\",\n",
    "        'Max rel error': f\"{np.max(rel_errors):.4f}\",\n",
    "        'Within 1%': f\"{100 * np.mean(rel_errors < 0.01):.1f}%\",\n",
    "        'Within 5%': f\"{100 * np.mean(rel_errors < 0.05):.1f}%\",\n",
    "        'Within 10%': f\"{100 * np.mean(rel_errors < 0.10):.1f}%\",\n",
    "    }\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    evaluate_calibration(weights_default, estimate_matrix, targets, 'Default params'),\n",
    "    evaluate_calibration(weights_tuned, estimate_matrix, targets, 'Tuned params'),\n",
    "])\n",
    "\n",
    "print(\"\\nParameter comparison:\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Improvement summary:\")\n",
    "sparsity_default = np.mean(weights_default == 0)\n",
    "sparsity_tuned = np.mean(weights_tuned == 0)\n",
    "print(f\"Sparsity improvement: {sparsity_tuned - sparsity_default:.1%}\")\n",
    "print(f\"Dataset reduction: {100*sparsity_tuned:.1f}% of records can be dropped\")\n",
    "print(f\"Remaining records: {np.sum(weights_tuned != 0):,} out of {len(weights_tuned):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced tuning with custom objectives\n",
    "\n",
    "You can customize the tuning process by adjusting the objective balance. Here's how different balances affect the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:microcalibrate.hyperparameter_tuning:Multi-holdout hyperparameter tuning:\n",
      "  - 2 holdout sets\n",
      "  - 2 targets per holdout (20.0%)\n",
      "  - Aggregation: mean\n",
      "\n",
      "WARNING:microcalibrate.hyperparameter_tuning:Data leakage warning: Targets often share overlapping information (e.g., geographic breakdowns like 'snap in CA' and 'snap in US'). Holdout validation may not provide complete isolation between training and validation sets. The robustness metrics should be interpreted with this limitation in mind - they may overestimate the model's true generalization performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning with Accuracy-focused objectives...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9f50e3d9f8423493290be31087c02d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1640.43epoch/s, loss=18.8, weights_mean=5.88, weights_std=2.83, weights_min=0.98]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 334.73epoch/s, loss=0.0282, loss_rel_change=-0.479]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1762.34epoch/s, loss=75, weights_mean=10.6, weights_std=3.91, weights_min=1.27]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 327.34epoch/s, loss=0.112, loss_rel_change=-0.993]\n",
      "INFO:microcalibrate.hyperparameter_tuning:Trial 0:\n",
      "  Objectives by holdout: ['201.0131', '201.0256']\n",
      "  Mean objective: 201.0193\n",
      "  Mean val accuracy: 0.00% (±0.00%)\n",
      "  Sparsity: 0.00%\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1506.32epoch/s, loss=163, weights_mean=15.2, weights_std=4.78, weights_min=2]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 308.44epoch/s, loss=0.0668, loss_rel_change=-0.996]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1833.63epoch/s, loss=284, weights_mean=19.6, weights_std=5.45, weights_min=2.41]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 239.72epoch/s, loss=0.179, loss_rel_change=-0.996]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1667.23epoch/s, loss=432, weights_mean=24, weights_std=6, weights_min=2.72]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 298.97epoch/s, loss=0.0608, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1786.79epoch/s, loss=607, weights_mean=28.2, weights_std=6.53, weights_min=8.4]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 391.59epoch/s, loss=0.023, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1736.41epoch/s, loss=802, weights_mean=32.3, weights_std=6.95, weights_min=10.6]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 303.16epoch/s, loss=0.271, loss_rel_change=-0.998]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1771.79epoch/s, loss=1.02e+3, weights_mean=36.3, weights_std=7.32, weights_min=12.5]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 281.84epoch/s, loss=0.256, loss_rel_change=-0.999]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1773.67epoch/s, loss=1.26e+3, weights_mean=40.1, weights_std=7.64, weights_min=13.6]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 286.69epoch/s, loss=0.234, loss_rel_change=-0.999]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 516.45epoch/s, loss=1.51e+3, weights_mean=43.9, weights_std=7.94, weights_min=14.3]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 402.53epoch/s, loss=0.177, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 486.85epoch/s, loss=1.77e+3, weights_mean=47.5, weights_std=8.21, weights_min=19]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 287.30epoch/s, loss=0.0374, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1961.57epoch/s, loss=2.06e+3, weights_mean=51.1, weights_std=8.48, weights_min=20.3]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 332.78epoch/s, loss=0.0206, loss_rel_change=-1]\n",
      "INFO:microcalibrate.hyperparameter_tuning:Trial 5:\n",
      "  Objectives by holdout: ['201.5720', '201.5335']\n",
      "  Mean objective: 201.5527\n",
      "  Mean val accuracy: 0.00% (±0.00%)\n",
      "  Sparsity: 2.08%\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1934.37epoch/s, loss=2.35e+3, weights_mean=54.5, weights_std=8.7, weights_min=24.9]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 320.62epoch/s, loss=0.0319, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1842.98epoch/s, loss=2.65e+3, weights_mean=57.8, weights_std=8.89, weights_min=25.7]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 270.79epoch/s, loss=0.0323, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1863.89epoch/s, loss=2.96e+3, weights_mean=61.1, weights_std=9.06, weights_min=27.8]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 306.88epoch/s, loss=0.00722, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1825.70epoch/s, loss=3.29e+3, weights_mean=64.3, weights_std=9.17, weights_min=30.2]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 327.58epoch/s, loss=0.0185, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1968.91epoch/s, loss=3.61e+3, weights_mean=67.4, weights_std=9.41, weights_min=31.8]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 256.84epoch/s, loss=0.677, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1961.18epoch/s, loss=3.95e+3, weights_mean=70.3, weights_std=9.54, weights_min=31.1]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 337.01epoch/s, loss=0.796, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1860.91epoch/s, loss=4.29e+3, weights_mean=73.3, weights_std=9.68, weights_min=37.9]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 252.18epoch/s, loss=0.364, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1951.72epoch/s, loss=4.61e+3, weights_mean=76, weights_std=9.85, weights_min=40.8]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 340.44epoch/s, loss=0.539, loss_rel_change=-1]\n",
      "INFO:microcalibrate.hyperparameter_tuning:\n",
      "Multi-holdout tuning completed!\n",
      "Best parameters:\n",
      "  - l0_lambda: 1.31e-06\n",
      "  - init_mean: 0.9322\n",
      "  - temperature: 1.4017\n",
      "Performance across 2 holdouts:\n",
      "  - Mean val loss: 0.020892 (±0.014057)\n",
      "  - Mean val accuracy: 50.00% (±50.00%)\n",
      "  - Individual objectives: ['201.0349', '1.0068']\n",
      "  - Sparsity: 0.00%\n",
      "\n",
      "Evaluation history saved with 20 records across 10 trials.\n",
      "INFO:microcalibrate.hyperparameter_tuning:Multi-holdout hyperparameter tuning:\n",
      "  - 2 holdout sets\n",
      "  - 2 targets per holdout (20.0%)\n",
      "  - Aggregation: mean\n",
      "\n",
      "WARNING:microcalibrate.hyperparameter_tuning:Data leakage warning: Targets often share overlapping information (e.g., geographic breakdowns like 'snap in CA' and 'snap in US'). Holdout validation may not provide complete isolation between training and validation sets. The robustness metrics should be interpreted with this limitation in mind - they may overestimate the model's true generalization performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning with Sparsity-focused objectives...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0818d35a3df04db0a94f17031644e061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 567.32epoch/s, loss=18.4, weights_mean=5.85, weights_std=2.81, weights_min=0.981]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 257.40epoch/s, loss=0.0282, loss_rel_change=-0.479]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1167.63epoch/s, loss=74.1, weights_mean=10.6, weights_std=3.97, weights_min=1.08]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 229.01epoch/s, loss=0.106, loss_rel_change=-0.993]\n",
      "INFO:microcalibrate.hyperparameter_tuning:Trial 0:\n",
      "  Objectives by holdout: ['99.9935', '100.0218']\n",
      "  Mean objective: 100.0076\n",
      "  Mean val accuracy: 0.00% (±0.00%)\n",
      "  Sparsity: 0.00%\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1799.85epoch/s, loss=164, weights_mean=15.2, weights_std=4.77, weights_min=2.37]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 279.03epoch/s, loss=0.0647, loss_rel_change=-0.997]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1666.83epoch/s, loss=285, weights_mean=19.7, weights_std=5.48, weights_min=3.5]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 292.92epoch/s, loss=0.182, loss_rel_change=-0.996]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1645.45epoch/s, loss=433, weights_mean=24.1, weights_std=6.03, weights_min=4.8]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 288.71epoch/s, loss=0.0601, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1507.39epoch/s, loss=608, weights_mean=28.3, weights_std=6.51, weights_min=5.81]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 274.26epoch/s, loss=0.0228, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1698.17epoch/s, loss=808, weights_mean=32.5, weights_std=6.96, weights_min=8.26]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 401.21epoch/s, loss=0.269, loss_rel_change=-0.998]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1829.26epoch/s, loss=1.03e+3, weights_mean=36.4, weights_std=7.29, weights_min=9.09]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 279.44epoch/s, loss=0.253, loss_rel_change=-0.999]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1618.55epoch/s, loss=1.27e+3, weights_mean=40.4, weights_std=7.57, weights_min=13.4]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 270.84epoch/s, loss=0.235, loss_rel_change=-0.999]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1770.25epoch/s, loss=1.53e+3, weights_mean=44.1, weights_std=7.94, weights_min=15.1]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 441.84epoch/s, loss=0.174, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1870.29epoch/s, loss=1.79e+3, weights_mean=47.7, weights_std=8.29, weights_min=18.2]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 327.45epoch/s, loss=0.0345, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1893.19epoch/s, loss=2.08e+3, weights_mean=51.3, weights_std=8.57, weights_min=19.9]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 437.13epoch/s, loss=0.0204, loss_rel_change=-1]\n",
      "INFO:microcalibrate.hyperparameter_tuning:Trial 5:\n",
      "  Objectives by holdout: ['99.9053', '99.5356']\n",
      "  Mean objective: 99.7205\n",
      "  Mean val accuracy: 0.00% (±0.00%)\n",
      "  Sparsity: 2.04%\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1919.30epoch/s, loss=2.37e+3, weights_mean=54.8, weights_std=8.76, weights_min=26.3]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 328.66epoch/s, loss=0.0325, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1895.25epoch/s, loss=2.68e+3, weights_mean=58.1, weights_std=8.96, weights_min=29.1]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 275.38epoch/s, loss=0.0321, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1853.24epoch/s, loss=2.99e+3, weights_mean=61.3, weights_std=9.17, weights_min=28.5]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 330.65epoch/s, loss=0.00741, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1940.52epoch/s, loss=3.31e+3, weights_mean=64.4, weights_std=9.37, weights_min=30.7]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 343.55epoch/s, loss=0.0188, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 2020.47epoch/s, loss=3.64e+3, weights_mean=67.5, weights_std=9.52, weights_min=35.6]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 330.64epoch/s, loss=0.686, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 506.36epoch/s, loss=3.97e+3, weights_mean=70.5, weights_std=9.68, weights_min=35.9]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 334.39epoch/s, loss=0.806, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1901.29epoch/s, loss=4.31e+3, weights_mean=73.4, weights_std=9.78, weights_min=39.9]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 261.74epoch/s, loss=0.37, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1848.88epoch/s, loss=4.66e+3, weights_mean=76.3, weights_std=9.85, weights_min=41.4]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 335.97epoch/s, loss=0.565, loss_rel_change=-1]\n",
      "INFO:microcalibrate.hyperparameter_tuning:\n",
      "Multi-holdout tuning completed!\n",
      "Best parameters:\n",
      "  - l0_lambda: 1.58e-05\n",
      "  - init_mean: 0.5779\n",
      "  - temperature: 0.7340\n",
      "Performance across 2 holdouts:\n",
      "  - Mean val loss: 0.053487 (±0.052596)\n",
      "  - Mean val accuracy: 50.00% (±50.00%)\n",
      "  - Individual objectives: ['98.6861', '49.1909']\n",
      "  - Sparsity: 1.62%\n",
      "\n",
      "Evaluation history saved with 20 records across 10 trials.\n",
      "INFO:microcalibrate.hyperparameter_tuning:Multi-holdout hyperparameter tuning:\n",
      "  - 2 holdout sets\n",
      "  - 2 targets per holdout (20.0%)\n",
      "  - Aggregation: mean\n",
      "\n",
      "WARNING:microcalibrate.hyperparameter_tuning:Data leakage warning: Targets often share overlapping information (e.g., geographic breakdowns like 'snap in CA' and 'snap in US'). Holdout validation may not provide complete isolation between training and validation sets. The robustness metrics should be interpreted with this limitation in mind - they may overestimate the model's true generalization performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning with Balanced objectives...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63b5da1620e4b058f380ebb243d0eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1818.97epoch/s, loss=19.6, weights_mean=5.94, weights_std=2.84, weights_min=0.982]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 325.64epoch/s, loss=0.0282, loss_rel_change=-0.479]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1941.75epoch/s, loss=76.5, weights_mean=10.7, weights_std=3.96, weights_min=1.13]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 336.02epoch/s, loss=0.114, loss_rel_change=-0.993]\n",
      "INFO:microcalibrate.hyperparameter_tuning:Trial 0:\n",
      "  Objectives by holdout: ['110.0095', '110.0267']\n",
      "  Mean objective: 110.0181\n",
      "  Mean val accuracy: 0.00% (±0.00%)\n",
      "  Sparsity: 0.00%\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1966.42epoch/s, loss=165, weights_mean=15.3, weights_std=4.77, weights_min=1.73]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 266.74epoch/s, loss=0.0703, loss_rel_change=-0.996]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1976.05epoch/s, loss=287, weights_mean=19.8, weights_std=5.37, weights_min=3.56]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 341.35epoch/s, loss=0.182, loss_rel_change=-0.996]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1937.71epoch/s, loss=433, weights_mean=24.1, weights_std=5.95, weights_min=5.88]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 326.82epoch/s, loss=0.0603, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 833.21epoch/s, loss=610, weights_mean=28.3, weights_std=6.45, weights_min=8.51]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 326.70epoch/s, loss=0.0218, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1949.33epoch/s, loss=804, weights_mean=32.4, weights_std=6.78, weights_min=10.8]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 338.99epoch/s, loss=0.271, loss_rel_change=-0.998]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1983.25epoch/s, loss=1.02e+3, weights_mean=36.3, weights_std=7.12, weights_min=11.2]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 272.58epoch/s, loss=0.254, loss_rel_change=-0.999]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1898.59epoch/s, loss=1.26e+3, weights_mean=40.2, weights_std=7.54, weights_min=12.2]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 335.71epoch/s, loss=0.232, loss_rel_change=-0.999]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1959.13epoch/s, loss=1.52e+3, weights_mean=43.9, weights_std=7.9, weights_min=17.1]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 213.15epoch/s, loss=0.177, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1086.84epoch/s, loss=1.78e+3, weights_mean=47.5, weights_std=8.24, weights_min=17.9]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 308.13epoch/s, loss=0.0344, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1482.00epoch/s, loss=2.06e+3, weights_mean=51, weights_std=8.5, weights_min=17.7]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 326.75epoch/s, loss=0.0214, loss_rel_change=-1]\n",
      "INFO:microcalibrate.hyperparameter_tuning:Trial 5:\n",
      "  Objectives by holdout: ['110.4485', '110.3485']\n",
      "  Mean objective: 110.3985\n",
      "  Mean val accuracy: 0.00% (±0.00%)\n",
      "  Sparsity: 2.06%\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1841.41epoch/s, loss=2.35e+3, weights_mean=54.5, weights_std=8.79, weights_min=22.6]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 450.16epoch/s, loss=0.0335, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1908.90epoch/s, loss=2.66e+3, weights_mean=57.8, weights_std=9.01, weights_min=22.6]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 335.56epoch/s, loss=0.0317, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1957.21epoch/s, loss=2.96e+3, weights_mean=61.1, weights_std=9.19, weights_min=26.6]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 447.14epoch/s, loss=0.00758, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1873.35epoch/s, loss=3.28e+3, weights_mean=64.2, weights_std=9.33, weights_min=33.2]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 318.26epoch/s, loss=0.0161, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1921.99epoch/s, loss=3.6e+3, weights_mean=67.2, weights_std=9.47, weights_min=35.5]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 343.78epoch/s, loss=0.668, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1958.86epoch/s, loss=3.94e+3, weights_mean=70.2, weights_std=9.63, weights_min=34.6]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 260.00epoch/s, loss=0.782, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1924.67epoch/s, loss=4.27e+3, weights_mean=73.1, weights_std=9.79, weights_min=36.7]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 332.87epoch/s, loss=0.361, loss_rel_change=-1]\n",
      "Reweighting progress: 100%|██████████| 30/30 [00:00<00:00, 1966.30epoch/s, loss=4.62e+3, weights_mean=76, weights_std=9.87, weights_min=44.9]\n",
      "Sparse reweighting progress: 100%|██████████| 60/60 [00:00<00:00, 277.73epoch/s, loss=0.554, loss_rel_change=-1]\n",
      "INFO:microcalibrate.hyperparameter_tuning:\n",
      "Multi-holdout tuning completed!\n",
      "Best parameters:\n",
      "  - l0_lambda: 1.58e-05\n",
      "  - init_mean: 0.5779\n",
      "  - temperature: 0.7340\n",
      "Performance across 2 holdouts:\n",
      "  - Mean val loss: 0.050039 (±0.049977)\n",
      "  - Mean val accuracy: 50.00% (±50.00%)\n",
      "  - Individual objectives: ['109.8460', '9.8461']\n",
      "  - Sparsity: 1.54%\n",
      "\n",
      "Evaluation history saved with 20 records across 10 trials.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Objective balance comparison:\n",
      "          Config l0_lambda Accuracy Sparsity\n",
      "Accuracy-focused  1.31e-06    50.0%     0.0%\n",
      "Sparsity-focused  1.58e-05    50.0%     1.6%\n",
      "        Balanced  1.58e-05    50.0%     1.5%\n"
     ]
    }
   ],
   "source": [
    "# Different objective balances for different use cases\n",
    "objective_configs = {\n",
    "    'Accuracy-focused': {'loss': 1.0, 'accuracy': 200.0, 'sparsity': 1.0},\n",
    "    'Sparsity-focused': {'loss': 1.0, 'accuracy': 50.0, 'sparsity': 50.0},\n",
    "    'Balanced': {'loss': 1.0, 'accuracy': 100.0, 'sparsity': 10.0},\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, objectives in objective_configs.items():\n",
    "    print(f\"\\nTuning with {name} objectives...\")\n",
    "    \n",
    "    cal_temp = Calibration(\n",
    "        weights=weights_init.copy(),\n",
    "        targets=targets,\n",
    "        estimate_matrix=estimate_matrix,\n",
    "        epochs=100,\n",
    "        learning_rate=1e-3,\n",
    "    )\n",
    "    \n",
    "    params = cal_temp.tune_l0_hyperparameters(\n",
    "        n_trials=10,  # Fewer trials for demonstration\n",
    "        objectives_balance=objectives,\n",
    "        n_holdout_sets=2,\n",
    "        holdout_fraction=0.2,\n",
    "        epochs_per_trial=30,\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        'Config': name,\n",
    "        'l0_lambda': f\"{params['l0_lambda']:.2e}\",\n",
    "        'Accuracy': f\"{params['mean_val_accuracy']:.1%}\",\n",
    "        'Sparsity': f\"{params['sparsity']:.1%}\",\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Objective balance comparison:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best practices for hyperparameter tuning\n",
    "\n",
    "### 1. Start with fewer trials\n",
    "Begin with 10-20 trials to get a sense of the parameter space, then increase if needed.\n",
    "\n",
    "### 2. Adjust objective balance based on your needs\n",
    "- **High accuracy weight**: When precision is critical\n",
    "- **High sparsity weight**: When dataset reduction is the priority\n",
    "- **Balanced**: Good starting point for most use cases\n",
    "\n",
    "### 3. Use appropriate cross-validation\n",
    "- **More holdout sets**: Better generalization estimates but slower\n",
    "- **Larger holdout fraction**: More robust validation but less training data\n",
    "\n",
    "### 4. Consider computational resources\n",
    "- Reduce `epochs_per_trial` for faster exploration\n",
    "- Use `n_jobs=-1` for parallel trials if you have multiple cores\n",
    "\n",
    "### 5. Monitor for overfitting\n",
    "Watch for large gaps between training and validation performance.\n",
    "\n",
    "### 6. Data leakage awareness\n",
    "Remember that targets often share information (e.g., 'income_north' and 'total_income'), so validation metrics may be optimistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "After finding optimal hyperparameters:\n",
    "1. Apply them to your full calibration with more epochs\n",
    "2. Evaluate robustness using the [Robustness evaluation](robustness_evaluation.ipynb) notebook\n",
    "3. Save the parameters for future use\n",
    "4. Consider fine-tuning if results aren't satisfactory\n",
    "\n",
    "The tuned parameters are specific to your dataset and target configuration, so re-tune if these change significantly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pe3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
