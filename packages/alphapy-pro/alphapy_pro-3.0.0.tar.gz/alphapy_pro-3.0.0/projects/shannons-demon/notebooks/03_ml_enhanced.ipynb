{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Machine Learning Enhanced Shannon's Demon\n\nThis notebook demonstrates how to enhance Shannon's Demon with machine learning using AlphaPy Pro.\n\n**📚 Learning Path**: This is Part 3 of the tutorial series:\n- **01_basic_demo.ipynb** - Basic concepts\n- **02_real_data.ipynb** - Real market data analysis\n- **03_ml_enhanced.ipynb** ← You are here (ML-enhanced strategies)\n- **../demon.ipynb** - Comprehensive analysis (must-see!)\n\n**🎯 Quick Start**: For AlphaPy integration, run:\n```bash\npython prepare_data.py --symbol BTC-USD\nalphapy --config config/model.yml\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Integration with AlphaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add AlphaPy to path\n",
    "sys.path.append('../../..')\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import AlphaPy modules\n",
    "from alphapy.data import load_data\n",
    "from alphapy.features import create_features\n",
    "from alphapy.model import Model\n",
    "from alphapy.utilities import get_pandas_data_frame\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering for Rebalancing Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rebalancing_features(data, lookback_periods=[5, 10, 20, 50]):\n",
    "    \"\"\"\n",
    "    Create features for predicting optimal rebalancing times.\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame(index=data.index)\n",
    "    \n",
    "    # Price-based features\n",
    "    for period in lookback_periods:\n",
    "        features[f'returns_{period}d'] = data['Close'].pct_change(period)\n",
    "        features[f'volatility_{period}d'] = data['Close'].pct_change().rolling(period).std()\n",
    "        features[f'volume_ratio_{period}d'] = data['Volume'] / data['Volume'].rolling(period).mean()\n",
    "    \n",
    "    # Technical indicators\n",
    "    features['rsi_14'] = calculate_rsi(data['Close'], 14)\n",
    "    features['macd_signal'] = calculate_macd_signal(data['Close'])\n",
    "    features['bollinger_position'] = calculate_bollinger_position(data['Close'])\n",
    "    features['atr_14'] = calculate_atr(data, 14)\n",
    "    \n",
    "    # Portfolio-specific features\n",
    "    features['weight_deviation'] = calculate_weight_deviation(data['Close'])\n",
    "    features['rebalance_profit_potential'] = estimate_rebalance_profit(features['weight_deviation'], \n",
    "                                                                      features['volatility_20d'])\n",
    "    \n",
    "    # Market regime features\n",
    "    features['trend_strength'] = calculate_trend_strength(data['Close'])\n",
    "    features['market_regime'] = identify_market_regime(data['Close'])\n",
    "    \n",
    "    # Time-based features\n",
    "    features['day_of_week'] = data.index.dayofweek\n",
    "    features['day_of_month'] = data.index.day\n",
    "    features['month'] = data.index.month\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technical indicator functions\n",
    "def calculate_rsi(prices, period=14):\n",
    "    \"\"\"Calculate Relative Strength Index.\"\"\"\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def calculate_macd_signal(prices, fast=12, slow=26, signal=9):\n",
    "    \"\"\"Calculate MACD signal.\"\"\"\n",
    "    ema_fast = prices.ewm(span=fast).mean()\n",
    "    ema_slow = prices.ewm(span=slow).mean()\n",
    "    macd = ema_fast - ema_slow\n",
    "    macd_signal = macd.ewm(span=signal).mean()\n",
    "    return macd - macd_signal\n",
    "\n",
    "def calculate_bollinger_position(prices, period=20, num_std=2):\n",
    "    \"\"\"Calculate position within Bollinger Bands.\"\"\"\n",
    "    sma = prices.rolling(period).mean()\n",
    "    std = prices.rolling(period).std()\n",
    "    upper_band = sma + (std * num_std)\n",
    "    lower_band = sma - (std * num_std)\n",
    "    position = (prices - lower_band) / (upper_band - lower_band)\n",
    "    return position\n",
    "\n",
    "def calculate_atr(data, period=14):\n",
    "    \"\"\"Calculate Average True Range.\"\"\"\n",
    "    high_low = data['High'] - data['Low']\n",
    "    high_close = np.abs(data['High'] - data['Close'].shift())\n",
    "    low_close = np.abs(data['Low'] - data['Close'].shift())\n",
    "    ranges = pd.concat([high_low, high_close, low_close], axis=1)\n",
    "    true_range = ranges.max(axis=1)\n",
    "    atr = true_range.rolling(period).mean()\n",
    "    return atr\n",
    "\n",
    "def calculate_weight_deviation(prices, target_weight=0.5):\n",
    "    \"\"\"Calculate deviation from target portfolio weight.\"\"\"\n",
    "    # Simulate portfolio weights\n",
    "    returns = prices.pct_change().fillna(0)\n",
    "    portfolio_value = 10000\n",
    "    asset_value = portfolio_value * target_weight\n",
    "    cash_value = portfolio_value * (1 - target_weight)\n",
    "    \n",
    "    weights = []\n",
    "    for r in returns:\n",
    "        asset_value *= (1 + r)\n",
    "        total_value = asset_value + cash_value\n",
    "        weight = asset_value / total_value\n",
    "        weights.append(weight)\n",
    "    \n",
    "    return pd.Series(weights, index=prices.index) - target_weight\n",
    "\n",
    "def estimate_rebalance_profit(weight_deviation, volatility, transaction_cost=0.001):\n",
    "    \"\"\"Estimate potential profit from rebalancing.\"\"\"\n",
    "    # Simplified profit estimation\n",
    "    potential_profit = np.abs(weight_deviation) * volatility * 2\n",
    "    cost = transaction_cost * 2  # Buy and sell\n",
    "    return potential_profit - cost\n",
    "\n",
    "def calculate_trend_strength(prices, period=20):\n",
    "    \"\"\"Calculate trend strength using linear regression.\"\"\"\n",
    "    def lin_reg_slope(y):\n",
    "        x = np.arange(len(y))\n",
    "        slope, _ = np.polyfit(x, y, 1)\n",
    "        return slope\n",
    "    \n",
    "    slopes = prices.rolling(period).apply(lin_reg_slope, raw=True)\n",
    "    return slopes / prices.rolling(period).std()\n",
    "\n",
    "def identify_market_regime(prices, short_period=50, long_period=200):\n",
    "    \"\"\"Identify market regime (trending, ranging, volatile).\"\"\"\n",
    "    sma_short = prices.rolling(short_period).mean()\n",
    "    sma_long = prices.rolling(long_period).mean()\n",
    "    volatility = prices.pct_change().rolling(20).std()\n",
    "    \n",
    "    regime = pd.Series(index=prices.index, dtype=float)\n",
    "    \n",
    "    # Trending up\n",
    "    regime[(sma_short > sma_long) & (volatility < volatility.median())] = 1\n",
    "    \n",
    "    # Trending down\n",
    "    regime[(sma_short < sma_long) & (volatility < volatility.median())] = -1\n",
    "    \n",
    "    # Volatile\n",
    "    regime[volatility > volatility.quantile(0.75)] = 2\n",
    "    \n",
    "    # Ranging\n",
    "    regime.fillna(0, inplace=True)\n",
    "    \n",
    "    return regime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Training Data with Labeled Rebalancing Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rebalancing_labels(data, threshold=0.2, min_profit=0.002):\n",
    "    \"\"\"\n",
    "    Create labels for optimal rebalancing points.\n",
    "    \n",
    "    1 = Should rebalance\n",
    "    0 = Should not rebalance\n",
    "    \"\"\"\n",
    "    prices = data['Close']\n",
    "    \n",
    "    # Calculate portfolio simulation\n",
    "    portfolio_value = 10000\n",
    "    target_weight = 0.5\n",
    "    asset_value = portfolio_value * target_weight\n",
    "    cash_value = portfolio_value * (1 - target_weight)\n",
    "    n_shares = asset_value / prices.iloc[0]\n",
    "    \n",
    "    labels = []\n",
    "    last_rebalance = 0\n",
    "    \n",
    "    for i, price in enumerate(prices):\n",
    "        # Current portfolio state\n",
    "        asset_value = n_shares * price\n",
    "        total_value = asset_value + cash_value\n",
    "        current_weight = asset_value / total_value\n",
    "        \n",
    "        # Check rebalancing conditions\n",
    "        weight_deviation = abs(current_weight - target_weight)\n",
    "        time_since_rebalance = i - last_rebalance\n",
    "        \n",
    "        # Estimate profit from rebalancing\n",
    "        rebalance_value = abs(total_value * (current_weight - target_weight))\n",
    "        transaction_cost = rebalance_value * 0.001\n",
    "        \n",
    "        # Look ahead to see if rebalancing would be profitable\n",
    "        if i < len(prices) - 20:  # Need future data to determine profitability\n",
    "            future_returns = prices.iloc[i:i+20].pct_change().std() * np.sqrt(252)\n",
    "            expected_profit = weight_deviation * future_returns * total_value * 0.1\n",
    "            \n",
    "            should_rebalance = (\n",
    "                weight_deviation > threshold and \n",
    "                expected_profit > transaction_cost * 2 and\n",
    "                time_since_rebalance > 5\n",
    "            )\n",
    "        else:\n",
    "            should_rebalance = False\n",
    "        \n",
    "        labels.append(1 if should_rebalance else 0)\n",
    "        \n",
    "        # Update portfolio if rebalanced\n",
    "        if should_rebalance:\n",
    "            # Rebalance\n",
    "            target_asset_value = total_value * target_weight\n",
    "            n_shares = (target_asset_value - transaction_cost) / price\n",
    "            asset_value = n_shares * price\n",
    "            cash_value = total_value - asset_value - transaction_cost\n",
    "            last_rebalance = i\n",
    "    \n",
    "    return pd.Series(labels, index=data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and create features\n",
    "from pathlib import Path\n",
    "data_path = Path('../data/BTC-USD.csv')\n",
    "\n",
    "# Load Bitcoin data\n",
    "btc_data = pd.read_csv(data_path)\n",
    "btc_data['Date'] = pd.to_datetime(btc_data['Date'])\n",
    "btc_data.set_index('Date', inplace=True)\n",
    "btc_data = btc_data['2018-01-01':'2023-12-31']\n",
    "\n",
    "# Create features\n",
    "features = create_rebalancing_features(btc_data)\n",
    "\n",
    "# Create labels\n",
    "labels = create_rebalancing_labels(btc_data)\n",
    "\n",
    "# Combine features and labels\n",
    "ml_data = features.copy()\n",
    "ml_data['rebalance_signal'] = labels\n",
    "\n",
    "# Remove NaN values\n",
    "ml_data = ml_data.dropna()\n",
    "\n",
    "print(f\"Dataset shape: {ml_data.shape}\")\n",
    "print(f\"Positive labels (rebalance): {(ml_data['rebalance_signal'] == 1).sum()}\")\n",
    "print(f\"Negative labels (hold): {(ml_data['rebalance_signal'] == 0).sum()}\")\n",
    "print(f\"Class balance: {(ml_data['rebalance_signal'] == 1).sum() / len(ml_data) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Prepare data for training\n",
    "X = ml_data.drop('rebalance_signal', axis=1)\n",
    "y = ml_data['rebalance_signal']\n",
    "\n",
    "# Split data (time-based split for financial data)\n",
    "split_date = '2022-01-01'\n",
    "X_train = X[X.index < split_date]\n",
    "y_train = y[y.index < split_date]\n",
    "X_test = X[X.index >= split_date]\n",
    "y_test = y[y.index >= split_date]\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")\n",
    "print(f\"Features: {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "    'LightGBM': lgb.LGBMClassifier(n_estimators=100, max_depth=5, random_state=42, verbose=-1)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Store results\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba,\n",
    "        'report': classification_report(y_test, y_pred, output_dict=True)\n",
    "    }\n",
    "    \n",
    "    # Print classification report\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from best model\n",
    "best_model_name = max(results.keys(), key=lambda x: results[x]['report']['accuracy'])\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "# Get feature importances\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Plot top features\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    top_features = feature_importance.head(15)\n",
    "    plt.barh(top_features['feature'], top_features['importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title(f'Top 15 Features - {best_model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Top 10 Most Important Features:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(feature_importance.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Backtest ML-Enhanced Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLEnhancedShannonsDemon:\n",
    "    \"\"\"\n",
    "    Shannon's Demon enhanced with machine learning predictions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, initial_capital=10000, target_allocation=0.5,\n",
    "                 ml_confidence_threshold=0.7, transaction_cost=0.001):\n",
    "        \n",
    "        self.model = model\n",
    "        self.initial_capital = initial_capital\n",
    "        self.target_allocation = target_allocation\n",
    "        self.ml_confidence_threshold = ml_confidence_threshold\n",
    "        self.transaction_cost = transaction_cost\n",
    "        \n",
    "        # Results storage\n",
    "        self.portfolio_values = []\n",
    "        self.allocations = []\n",
    "        self.trades = []\n",
    "        self.ml_signals = []\n",
    "    \n",
    "    def run(self, data, features):\n",
    "        \"\"\"\n",
    "        Run ML-enhanced strategy.\n",
    "        \"\"\"\n",
    "        prices = data['Close'].values\n",
    "        dates = data.index\n",
    "        \n",
    "        # Initialize portfolio\n",
    "        risky_value = self.initial_capital * self.target_allocation\n",
    "        safe_value = self.initial_capital * (1 - self.target_allocation)\n",
    "        n_shares = risky_value / prices[0]\n",
    "        \n",
    "        # Run strategy\n",
    "        for i in range(len(prices)):\n",
    "            # Current values\n",
    "            risky_value = n_shares * prices[i]\n",
    "            total_value = risky_value + safe_value\n",
    "            current_allocation = risky_value / total_value\n",
    "            \n",
    "            # Store values\n",
    "            self.portfolio_values.append(total_value)\n",
    "            self.allocations.append(current_allocation)\n",
    "            \n",
    "            # Get ML prediction\n",
    "            if dates[i] in features.index:\n",
    "                feature_row = features.loc[[dates[i]]]\n",
    "                ml_prob = self.model.predict_proba(feature_row)[0, 1]\n",
    "                ml_signal = ml_prob > self.ml_confidence_threshold\n",
    "                self.ml_signals.append(ml_prob)\n",
    "                \n",
    "                # Rebalance if ML says so\n",
    "                if ml_signal:\n",
    "                    # Calculate rebalancing trade\n",
    "                    target_risky_value = total_value * self.target_allocation\n",
    "                    risky_trade_value = target_risky_value - risky_value\n",
    "                    shares_traded = risky_trade_value / prices[i]\n",
    "                    \n",
    "                    # Apply transaction costs\n",
    "                    cost = abs(risky_trade_value) * self.transaction_cost\n",
    "                    \n",
    "                    # Update portfolio\n",
    "                    n_shares += shares_traded\n",
    "                    risky_value = n_shares * prices[i]\n",
    "                    safe_value = total_value - risky_value - cost\n",
    "                    \n",
    "                    # Record trade\n",
    "                    self.trades.append({\n",
    "                        'date': dates[i],\n",
    "                        'price': prices[i],\n",
    "                        'ml_confidence': ml_prob,\n",
    "                        'shares_traded': shares_traded,\n",
    "                        'value_traded': risky_trade_value,\n",
    "                        'cost': cost\n",
    "                    })\n",
    "            else:\n",
    "                self.ml_signals.append(0)\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtest on test period\n",
    "test_data = btc_data[btc_data.index >= split_date]\n",
    "test_features = features[features.index >= split_date]\n",
    "\n",
    "# Run different strategies\n",
    "strategies_results = {}\n",
    "\n",
    "# Buy and Hold\n",
    "initial = 10000\n",
    "btc_shares = (initial * 0.5) / test_data['Close'].iloc[0]\n",
    "bh_values = btc_shares * test_data['Close'].values + (initial * 0.5)\n",
    "strategies_results['Buy and Hold'] = bh_values\n",
    "\n",
    "# Traditional Shannon's Demon (threshold-based)\n",
    "from collections import namedtuple\n",
    "SDResult = namedtuple('SDResult', ['portfolio_values', 'trades'])\n",
    "\n",
    "def run_traditional_sd(data, threshold=0.2):\n",
    "    prices = data['Close'].values\n",
    "    portfolio_values = []\n",
    "    trades = []\n",
    "    \n",
    "    # Initialize\n",
    "    risky_value = initial * 0.5\n",
    "    safe_value = initial * 0.5\n",
    "    n_shares = risky_value / prices[0]\n",
    "    \n",
    "    for i, price in enumerate(prices):\n",
    "        risky_value = n_shares * price\n",
    "        total_value = risky_value + safe_value\n",
    "        portfolio_values.append(total_value)\n",
    "        \n",
    "        current_allocation = risky_value / total_value\n",
    "        if abs(current_allocation - 0.5) > threshold:\n",
    "            # Rebalance\n",
    "            target_risky = total_value * 0.5\n",
    "            trade_value = target_risky - risky_value\n",
    "            n_shares += trade_value / price\n",
    "            cost = abs(trade_value) * 0.001\n",
    "            safe_value = total_value * 0.5 - cost\n",
    "            trades.append(i)\n",
    "    \n",
    "    return SDResult(portfolio_values, trades)\n",
    "\n",
    "trad_sd = run_traditional_sd(test_data)\n",
    "strategies_results['Traditional SD'] = trad_sd.portfolio_values\n",
    "\n",
    "# ML-Enhanced strategies\n",
    "for name, model_data in results.items():\n",
    "    ml_sd = MLEnhancedShannonsDemon(model_data['model'])\n",
    "    ml_sd.run(test_data, test_features)\n",
    "    strategies_results[f'ML-{name}'] = ml_sd.portfolio_values\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(14, 8))\n",
    "for name, values in strategies_results.items():\n",
    "    plt.plot(test_data.index[:len(values)], values, label=name, linewidth=2)\n",
    "\n",
    "plt.title('Strategy Performance Comparison')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value ($)')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics for all strategies\n",
    "def calculate_strategy_metrics(values, periods_per_year=252):\n",
    "    returns = pd.Series(values).pct_change().dropna()\n",
    "    \n",
    "    total_return = (values[-1] / values[0] - 1) * 100\n",
    "    annual_return = ((values[-1] / values[0]) ** (periods_per_year / len(values)) - 1) * 100\n",
    "    volatility = returns.std() * np.sqrt(periods_per_year) * 100\n",
    "    sharpe = (annual_return - 2) / volatility if volatility > 0 else 0\n",
    "    \n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    running_max = cumulative.expanding().max()\n",
    "    drawdown = ((cumulative - running_max) / running_max).min() * 100\n",
    "    \n",
    "    return {\n",
    "        'Total Return (%)': total_return,\n",
    "        'Annual Return (%)': annual_return,\n",
    "        'Volatility (%)': volatility,\n",
    "        'Sharpe Ratio': sharpe,\n",
    "        'Max Drawdown (%)': drawdown\n",
    "    }\n",
    "\n",
    "# Calculate metrics for all strategies\n",
    "metrics_comparison = pd.DataFrame()\n",
    "for name, values in strategies_results.items():\n",
    "    metrics = calculate_strategy_metrics(values)\n",
    "    metrics_comparison[name] = metrics\n",
    "\n",
    "metrics_comparison = metrics_comparison.T\n",
    "print(\"Performance Metrics Comparison:\")\n",
    "print(\"=\" * 100)\n",
    "print(metrics_comparison.round(2).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize metrics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Annual Return\n",
    "ax = axes[0, 0]\n",
    "metrics_comparison['Annual Return (%)'].plot(kind='bar', ax=ax, color='green')\n",
    "ax.set_title('Annual Return Comparison')\n",
    "ax.set_ylabel('Annual Return (%)')\n",
    "ax.axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# Sharpe Ratio\n",
    "ax = axes[0, 1]\n",
    "metrics_comparison['Sharpe Ratio'].plot(kind='bar', ax=ax, color='blue')\n",
    "ax.set_title('Sharpe Ratio Comparison')\n",
    "ax.set_ylabel('Sharpe Ratio')\n",
    "ax.axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# Volatility\n",
    "ax = axes[1, 0]\n",
    "metrics_comparison['Volatility (%)'].plot(kind='bar', ax=ax, color='orange')\n",
    "ax.set_title('Volatility Comparison')\n",
    "ax.set_ylabel('Volatility (%)')\n",
    "\n",
    "# Max Drawdown\n",
    "ax = axes[1, 1]\n",
    "metrics_comparison['Max Drawdown (%)'].plot(kind='bar', ax=ax, color='red')\n",
    "ax.set_title('Maximum Drawdown Comparison')\n",
    "ax.set_ylabel('Max Drawdown (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ML Signal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze ML predictions\n",
    "best_ml_name = f'ML-{best_model_name}'\n",
    "ml_sd = MLEnhancedShannonsDemon(best_model)\n",
    "ml_sd.run(test_data, test_features)\n",
    "\n",
    "# Create analysis DataFrame\n",
    "ml_analysis = pd.DataFrame({\n",
    "    'date': test_data.index[:len(ml_sd.ml_signals)],\n",
    "    'price': test_data['Close'].values[:len(ml_sd.ml_signals)],\n",
    "    'ml_confidence': ml_sd.ml_signals,\n",
    "    'allocation': ml_sd.allocations\n",
    "})\n",
    "\n",
    "# Add trade markers\n",
    "trade_dates = [t['date'] for t in ml_sd.trades]\n",
    "ml_analysis['traded'] = ml_analysis['date'].isin(trade_dates)\n",
    "\n",
    "# Plot ML signals\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 12), sharex=True)\n",
    "\n",
    "# Price and trades\n",
    "ax = axes[0]\n",
    "ax.plot(ml_analysis['date'], ml_analysis['price'], label='BTC Price')\n",
    "trade_points = ml_analysis[ml_analysis['traded']]\n",
    "ax.scatter(trade_points['date'], trade_points['price'], color='red', s=50, zorder=5, label='ML Trades')\n",
    "ax.set_ylabel('Price ($)')\n",
    "ax.set_title('Bitcoin Price and ML-Triggered Trades')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# ML Confidence\n",
    "ax = axes[1]\n",
    "ax.plot(ml_analysis['date'], ml_analysis['ml_confidence'], label='ML Confidence', color='green')\n",
    "ax.axhline(0.7, color='red', linestyle='--', label='Threshold')\n",
    "ax.fill_between(ml_analysis['date'], 0, ml_analysis['ml_confidence'], alpha=0.3, color='green')\n",
    "ax.set_ylabel('ML Confidence')\n",
    "ax.set_title('Machine Learning Rebalancing Confidence')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Portfolio Allocation\n",
    "ax = axes[2]\n",
    "ax.plot(ml_analysis['date'], ml_analysis['allocation'] * 100, label='BTC Allocation')\n",
    "ax.axhline(50, color='red', linestyle='--', label='Target')\n",
    "ax.fill_between(ml_analysis['date'], 40, 60, alpha=0.2, color='gray', label='Target Range')\n",
    "ax.set_ylabel('BTC Allocation (%)')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_title('Portfolio Allocation Over Time')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Trade statistics\n",
    "print(f\"\\nML Trading Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total trades: {len(ml_sd.trades)}\")\n",
    "print(f\"Average trades per month: {len(ml_sd.trades) / (len(test_data) / 30):.2f}\")\n",
    "print(f\"Average ML confidence when trading: {np.mean([t['ml_confidence'] for t in ml_sd.trades]):.3f}\")\n",
    "print(f\"Total transaction costs: ${sum(t['cost'] for t in ml_sd.trades):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Advanced ML Features: Ensemble and Time-Series Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble predictions\n",
    "ensemble_predictions = np.zeros(len(X_test))\n",
    "for name, model_data in results.items():\n",
    "    ensemble_predictions += model_data['probabilities']\n",
    "\n",
    "ensemble_predictions /= len(results)\n",
    "\n",
    "# Create ensemble strategy\n",
    "class EnsembleModel:\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        predictions = np.zeros((len(X), 2))\n",
    "        for model in self.models.values():\n",
    "            predictions += model['model'].predict_proba(X)\n",
    "        return predictions / len(self.models)\n",
    "\n",
    "ensemble_model = EnsembleModel(results)\n",
    "ensemble_sd = MLEnhancedShannonsDemon(ensemble_model, ml_confidence_threshold=0.6)\n",
    "ensemble_sd.run(test_data, test_features)\n",
    "\n",
    "# Add to results\n",
    "strategies_results['ML-Ensemble'] = ensemble_sd.portfolio_values\n",
    "\n",
    "# Recalculate metrics with ensemble\n",
    "ensemble_metrics = calculate_strategy_metrics(ensemble_sd.portfolio_values)\n",
    "print(\"\\nEnsemble Strategy Performance:\")\n",
    "print(\"=\" * 50)\n",
    "for metric, value in ensemble_metrics.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusions and Production Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Final values comparison\n",
    "final_values = {name: values[-1] for name, values in strategies_results.items()}\n",
    "sorted_strategies = sorted(final_values.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "ax1.bar(range(len(sorted_strategies)), [v for _, v in sorted_strategies])\n",
    "ax1.set_xticks(range(len(sorted_strategies)))\n",
    "ax1.set_xticklabels([n for n, _ in sorted_strategies], rotation=45, ha='right')\n",
    "ax1.set_title('Final Portfolio Values')\n",
    "ax1.set_ylabel('Portfolio Value ($)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Risk-return scatter\n",
    "returns = []\n",
    "volatilities = []\n",
    "names = []\n",
    "\n",
    "for name, values in strategies_results.items():\n",
    "    metrics = calculate_strategy_metrics(values)\n",
    "    returns.append(metrics['Annual Return (%)'])\n",
    "    volatilities.append(metrics['Volatility (%)'])\n",
    "    names.append(name)\n",
    "\n",
    "ax2.scatter(volatilities, returns, s=100)\n",
    "for i, name in enumerate(names):\n",
    "    ax2.annotate(name, (volatilities[i], returns[i]), xytext=(5, 5), \n",
    "                textcoords='offset points', fontsize=8)\n",
    "\n",
    "ax2.set_xlabel('Volatility (%)')\n",
    "ax2.set_ylabel('Annual Return (%)')\n",
    "ax2.set_title('Risk-Return Profile')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings and Recommendations\n",
    "\n",
    "### 1. Machine Learning Impact\n",
    "- ML models can successfully predict profitable rebalancing opportunities\n",
    "- Ensemble approaches often provide more stable predictions\n",
    "- Feature importance shows volatility and weight deviation are key indicators\n",
    "\n",
    "### 2. Best Practices for Production\n",
    "- **Data Quality**: Ensure real-time data feeds are reliable\n",
    "- **Model Updates**: Retrain models periodically (monthly/quarterly)\n",
    "- **Risk Management**: Set maximum position limits and drawdown controls\n",
    "- **Transaction Costs**: Account for slippage and market impact\n",
    "\n",
    "### 3. Further Enhancements\n",
    "- **Deep Learning**: LSTM/GRU for time-series prediction\n",
    "- **Reinforcement Learning**: Learn optimal rebalancing policy\n",
    "- **Multi-Asset**: Extend to portfolios with 3+ assets\n",
    "- **Market Regime**: Adapt strategy based on market conditions\n",
    "\n",
    "### 4. Implementation Checklist\n",
    "- [ ] Set up real-time data pipeline\n",
    "- [ ] Implement model serving infrastructure\n",
    "- [ ] Create monitoring dashboard\n",
    "- [ ] Add alerting for anomalies\n",
    "- [ ] Implement position sizing logic\n",
    "- [ ] Add transaction cost modeling\n",
    "- [ ] Create backtesting framework\n",
    "- [ ] Set up model retraining pipeline\n",
    "\n",
    "### 5. Risk Warnings\n",
    "- Past performance doesn't guarantee future results\n",
    "- ML models can fail in unprecedented market conditions\n",
    "- Always use proper risk management\n",
    "- Start with small capital for live testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}