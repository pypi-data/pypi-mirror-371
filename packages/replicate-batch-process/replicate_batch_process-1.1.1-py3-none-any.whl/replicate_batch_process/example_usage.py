#!/usr/bin/env python3
"""
Replicate æ¨¡å‹è°ƒç”¨ - å®Œæ•´ä½¿ç”¨ç¤ºä¾‹
ä¸‰ç§ä½¿ç”¨åœºæ™¯çš„ç»è¿‡æµ‹è¯•çš„ç¤ºä¾‹ä»£ç ï¼Œå¯ç›´æ¥å¤åˆ¶ä½¿ç”¨
"""

import asyncio
import time
import os

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
from .main import replicate_model_calling
from .intelligent_batch_processor import intelligent_batch_process, IntelligentBatchProcessor, BatchRequest


# =============================================================================
# åœºæ™¯1: å•ä¸ªå›¾åƒç”Ÿæˆ - æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼
# =============================================================================

# ğŸ“‹ è¾“å…¥å‚æ•°é…ç½® - å¯ç›´æ¥ä¿®æ”¹è¿™äº›å‚æ•°
SINGLE_IMAGE_PARAMS = {
    "prompt": "A beautiful sunset over mountains with golden light",
    "model_name": "black-forest-labs/flux-dev",  # å¯é€‰: qwen/qwen-image, google/imagen-4-ultra
    "output_filepath": "output/single_example.jpg",
    
    # å¯é€‰å‚æ•° - æ ¹æ®æ¨¡å‹æ”¯æŒè°ƒæ•´
    "aspect_ratio": "16:9",        # å®½é«˜æ¯”: "1:1", "4:3", "16:9"
    "output_quality": 80,          # è¾“å‡ºè´¨é‡: 1-100
    "num_outputs": 1,              # è¾“å‡ºæ•°é‡: é€šå¸¸ä¸º1
    # "guidance": 3,               # å¼•å¯¼å¼ºåº¦: 1-10ï¼ˆä»…æŸäº›æ¨¡å‹ï¼‰
    # "num_inference_steps": 28,   # æ¨ç†æ­¥æ•°ï¼ˆä»…æŸäº›æ¨¡å‹ï¼‰
}

def single_image_generation():
    """
    åœºæ™¯1: ç”Ÿæˆå•ä¸ªå›¾åƒ
    
    ä½¿ç”¨æ–¹æ³•:
    1. ä¿®æ”¹ä¸Šé¢çš„ SINGLE_IMAGE_PARAMS å‚æ•°
    2. è°ƒç”¨æ­¤å‡½æ•°æˆ–ç›´æ¥å¤åˆ¶è°ƒç”¨ä»£ç 
    
    é€‚ç”¨åœºæ™¯:
    - æµ‹è¯•æ¨¡å‹æ•ˆæœ
    - å•æ¬¡ç”Ÿæˆéœ€æ±‚
    - äº¤äº’å¼ä½¿ç”¨
    """
    
    print("ğŸ¯ åœºæ™¯1: å•ä¸ªå›¾åƒç”Ÿæˆ")
    print(f"   æç¤ºè¯: {SINGLE_IMAGE_PARAMS['prompt']}")
    print(f"   æ¨¡å‹: {SINGLE_IMAGE_PARAMS['model_name']}")
    
    try:
        start_time = time.time()
        
        # ğŸš€ æ ¸å¿ƒè°ƒç”¨ä»£ç  - å¯ç›´æ¥å¤åˆ¶ä½¿ç”¨
        file_paths = replicate_model_calling(
            prompt=SINGLE_IMAGE_PARAMS["prompt"],
            model_name=SINGLE_IMAGE_PARAMS["model_name"],
            output_filepath=SINGLE_IMAGE_PARAMS["output_filepath"],
            aspect_ratio=SINGLE_IMAGE_PARAMS["aspect_ratio"],
            output_quality=SINGLE_IMAGE_PARAMS["output_quality"],
            num_outputs=SINGLE_IMAGE_PARAMS["num_outputs"]
        )
        
        duration = time.time() - start_time
        
        print(f"âœ… ç”Ÿæˆå®Œæˆ!")
        print(f"   è€—æ—¶: {duration:.1f}ç§’")
        print(f"   æ–‡ä»¶: {file_paths[0]}")
        
        return file_paths[0]
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
        return None


# =============================================================================
# åœºæ™¯2: åŒæ¨¡å‹æ‰¹é‡ç”Ÿæˆ - ç›¸åŒå‚æ•°çš„æ‰¹é‡å¤„ç†
# =============================================================================

# ğŸ“‹ æ‰¹é‡å¤„ç†å‚æ•°é…ç½® - å¯ç›´æ¥ä¿®æ”¹è¿™äº›å‚æ•°
BATCH_SAME_MODEL_PARAMS = {
    # æç¤ºè¯åˆ—è¡¨ - æ‰€æœ‰ä½¿ç”¨ç›¸åŒæ¨¡å‹å’Œå‚æ•°
    "prompts": [
        "A serene lake reflecting autumn trees with golden leaves",
        "A cozy cabin in the mountains during a snowy winter evening", 
        "A vibrant flower garden in full bloom during spring",
        "A peaceful beach scene with gentle waves at sunset",
        "A mystical forest path with rays of sunlight filtering through",
    ],
    
    # è‡ªå®šä¹‰æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰ - ä¸promptså¯¹åº”ï¼Œå®Œæ•´è·¯å¾„
    "output_filepath": [
        "output/batch_same_model_example/scene_01_autumn_lake.jpg",
        "output/batch_same_model_example/scene_02_winter_cabin.jpg", 
        "output/batch_same_model_example/scene_03_spring_garden.jpg",
        "output/batch_same_model_example/scene_04_sunset_beach.jpg",
        "output/batch_same_model_example/scene_05_forest_path.jpg",
    ],
    
    # ç»Ÿä¸€æ¨¡å‹
    "model_name": "black-forest-labs/flux-dev",  # æ‰€æœ‰å›¾åƒä½¿ç”¨åŒä¸€æ¨¡å‹
    
    # æ‰¹é‡å¤„ç†è®¾ç½®
    "max_concurrent": 8,                         # å¹¶å‘æ•°: 5-20æ¨è
    
    # å…±åŒå‚æ•° - æ‰€æœ‰å›¾åƒä½¿ç”¨ç›¸åŒè®¾ç½®
    "aspect_ratio": "16:9",        # ç»Ÿä¸€å®½é«˜æ¯”
    "output_quality": 90,          # ç»Ÿä¸€è´¨é‡
    "num_outputs": 1,              # æ¯ä¸ªæç¤ºè¯ç”Ÿæˆ1å¼ å›¾
    # "guidance": 3,               # ç»Ÿä¸€å¼•å¯¼å¼ºåº¦
    # "num_inference_steps": 28,   # ç»Ÿä¸€æ¨ç†æ­¥æ•°
}

async def batch_same_model():
    """
    åœºæ™¯2: ä½¿ç”¨åŒä¸€ä¸ªæ¨¡å‹æ‰¹é‡ç”Ÿæˆå›¾åƒ
    
    ä½¿ç”¨æ–¹æ³•:
    1. ä¿®æ”¹ä¸Šé¢çš„ BATCH_SAME_MODEL_PARAMS å‚æ•°
    2. è°ƒç”¨æ­¤å‡½æ•°æˆ–ç›´æ¥å¤åˆ¶è°ƒç”¨ä»£ç 
    
    é€‚ç”¨åœºæ™¯:
    - æ‰¹é‡ç”Ÿæˆç›¸ä¼¼é£æ ¼çš„å›¾åƒ
    - æ‰€æœ‰å›¾åƒä½¿ç”¨ç›¸åŒå‚æ•°
    - ä¸­ç­‰è§„æ¨¡æ‰¹å¤„ç† (2-100ä¸ª)
    """
    
    print("ğŸ¯ åœºæ™¯2: åŒæ¨¡å‹æ‰¹é‡ç”Ÿæˆ")
    print(f"   æç¤ºè¯æ•°é‡: {len(BATCH_SAME_MODEL_PARAMS['prompts'])}")
    print(f"   æ¨¡å‹: {BATCH_SAME_MODEL_PARAMS['model_name']}")
    print(f"   å¹¶å‘æ•°: {BATCH_SAME_MODEL_PARAMS['max_concurrent']}")
    
    try:
        start_time = time.time()
        
        # ğŸš€ æ ¸å¿ƒè°ƒç”¨ä»£ç  - å¯ç›´æ¥å¤åˆ¶ä½¿ç”¨
        files = await intelligent_batch_process(
            prompts=BATCH_SAME_MODEL_PARAMS["prompts"],
            model_name=BATCH_SAME_MODEL_PARAMS["model_name"],
            max_concurrent=BATCH_SAME_MODEL_PARAMS["max_concurrent"],
            output_filepath=BATCH_SAME_MODEL_PARAMS["output_filepath"],
            aspect_ratio=BATCH_SAME_MODEL_PARAMS["aspect_ratio"],
            output_quality=BATCH_SAME_MODEL_PARAMS["output_quality"],
            num_outputs=BATCH_SAME_MODEL_PARAMS["num_outputs"]
        )
        
        duration = time.time() - start_time
        
        print(f"âœ… æ‰¹é‡ç”Ÿæˆå®Œæˆ!")
        print(f"   æ€»è€—æ—¶: {duration:.1f}ç§’")
        print(f"   ç”Ÿæˆæ–‡ä»¶: {len(files)}ä¸ª")
        print(f"   å¹³å‡é€Ÿåº¦: {len(files)/duration:.2f} æ–‡ä»¶/ç§’")
        print(f"   æ–‡ä»¶åˆ—è¡¨:")
        for file_path in files:
            print(f"     - {os.path.basename(file_path)}")
        
        return files
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡ç”Ÿæˆå¤±è´¥: {e}")
        return []


# =============================================================================
# åœºæ™¯3: æ··åˆæ¨¡å‹é«˜çº§æ‰¹å¤„ç† - ä¸åŒæ¨¡å‹å’Œå‚æ•°çš„å¤æ‚å¤„ç†
# =============================================================================

# ğŸ“‹ æ··åˆæ¨¡å‹è¯·æ±‚é…ç½® - å¯ç›´æ¥ä¿®æ”¹è¿™äº›å‚æ•°
MIXED_MODEL_REQUESTS = [
    {
        "prompt": "A professional headshot portrait of a business woman",
        "model": "google/imagen-4-ultra",      # é«˜è´¨é‡äººåƒ
        "params": {
            "aspect_ratio": "4:3",             # äººåƒæ¯”ä¾‹
            "output_quality": 95,              # é«˜è´¨é‡
            # "style": "photorealistic"
        }
    },
    {
        "prompt": "An anime-style character design with magical powers", 
        "model": "black-forest-labs/flux-dev", # å¿«é€Ÿé£æ ¼åŒ–
        "params": {
            "aspect_ratio": "1:1",             # æ­£æ–¹å½¢
            "output_quality": 80,
            "guidance": 4,                     # é£æ ¼åŒ–å¼•å¯¼
            "num_inference_steps": 30
        }
    },
    {
        "prompt": "A technical diagram showing 'äººå·¥æ™ºèƒ½æ¶æ„' with Chinese text",
        "model": "qwen/qwen-image",            # ä¸­æ–‡æ–‡æœ¬æ¸²æŸ“
        "params": {
            "aspect_ratio": "16:9",           # å›¾è¡¨æ¯”ä¾‹
            "output_quality": 90,
            "guidance": 5,                    # ç²¾ç¡®æ–‡æœ¬æ¸²æŸ“
            "image_size": "optimize_for_quality"
        }
    },
    {
        "prompt": "A fantasy landscape with dragons flying over castles",
        "model": "black-forest-labs/flux-dev", # åˆ›æ„å†…å®¹
        "params": {
            "aspect_ratio": "16:9",           # é£æ™¯æ¯”ä¾‹
            "output_quality": 85,
            "guidance": 3
        }
    },
    {
        "prompt": "A minimalist logo design for a tech startup",
        "model": "qwen/qwen-image",           # è®¾è®¡ç±»å›¾åƒ
        "params": {
            "aspect_ratio": "1:1",           # æ ‡å¿—æ¯”ä¾‹
            "output_quality": 100,          # æœ€é«˜è´¨é‡
            "image_size": "optimize_for_quality",
            "enhance_prompt": True
        }
    }
]

# é«˜çº§æ‰¹å¤„ç†å™¨é…ç½®
ADVANCED_PROCESSOR_CONFIG = {
    "max_concurrent": 15,        # æ··åˆæ¨¡å‹å¯ä»¥æ›´é«˜å¹¶å‘
    "rate_limit_per_minute": 600,  # Replicate API é™åˆ¶
    "max_retries": 3             # å¤±è´¥é‡è¯•æ¬¡æ•°
}

async def advanced_mixed_models():
    """
    åœºæ™¯3: æ··åˆæ¨¡å‹é«˜çº§æ‰¹å¤„ç†
    
    ä½¿ç”¨æ–¹æ³•:
    1. ä¿®æ”¹ä¸Šé¢çš„ MIXED_MODEL_REQUESTS å‚æ•°é…ç½®
    2. è°ƒæ•´ ADVANCED_PROCESSOR_CONFIG å¤„ç†å™¨è®¾ç½®
    3. è°ƒç”¨æ­¤å‡½æ•°æˆ–ç›´æ¥å¤åˆ¶è°ƒç”¨ä»£ç 
    
    é€‚ç”¨åœºæ™¯:
    - ä¸åŒç±»å‹çš„å›¾åƒéœ€æ±‚
    - æ¯ä¸ªä»»åŠ¡ä½¿ç”¨æœ€é€‚åˆçš„æ¨¡å‹
    - å¤æ‚çš„æ‰¹å¤„ç†éœ€æ±‚
    - å¤§è§„æ¨¡å¤„ç† (10-1000+ä¸ª)
    """
    
    print("ğŸ¯ åœºæ™¯3: æ··åˆæ¨¡å‹é«˜çº§æ‰¹å¤„ç†")
    print(f"   ä»»åŠ¡æ•°é‡: {len(MIXED_MODEL_REQUESTS)}")
    
    try:
        # ğŸš€ æ ¸å¿ƒè°ƒç”¨ä»£ç å¼€å§‹ - å¯ç›´æ¥å¤åˆ¶ä½¿ç”¨
        
        # 1. è½¬æ¢ä¸ºBatchRequestå¯¹è±¡
        batch_requests = []
        
        for i, req_config in enumerate(MIXED_MODEL_REQUESTS):
            request = BatchRequest(
                prompt=req_config["prompt"],
                model_name=req_config["model"],
                output_filepath=f"output/mixed_example_{i+1:02d}_{req_config['model'].replace('/', '_')}.jpg",
                kwargs=req_config["params"],
                request_id=f"mixed_example_{i+1:02d}"
            )
            batch_requests.append(request)
        
        # 2. åˆ›å»ºé«˜çº§æ‰¹å¤„ç†å™¨
        processor = IntelligentBatchProcessor(
            max_concurrent=ADVANCED_PROCESSOR_CONFIG["max_concurrent"],
            rate_limit_per_minute=ADVANCED_PROCESSOR_CONFIG["rate_limit_per_minute"],
            max_retries=ADVANCED_PROCESSOR_CONFIG["max_retries"]
        )
        
        # 3. æ‰§è¡Œæ™ºèƒ½æ‰¹å¤„ç†
        results = await processor.process_intelligent_batch(batch_requests)
        
        # ğŸš€ æ ¸å¿ƒè°ƒç”¨ä»£ç ç»“æŸ
        
        # ç»Ÿè®¡æ¨¡å‹åˆ†å¸ƒ
        model_counts = {}
        for req in batch_requests:
            model_counts[req.model_name] = model_counts.get(req.model_name, 0) + 1
        
        print("ğŸ“Š æ¨¡å‹åˆ†å¸ƒ:")
        for model, count in model_counts.items():
            print(f"   {model}: {count} ä¸ªä»»åŠ¡")
        
        # åˆ†æç»“æœ
        successful_results = [r for r in results if r.success]
        failed_results = [r for r in results if not r.success]
        
        print(f"âœ… æ··åˆæ¨¡å‹æ‰¹å¤„ç†å®Œæˆ!")
        print(f"   æˆåŠŸ: {len(successful_results)} ä¸ª")
        print(f"   å¤±è´¥: {len(failed_results)} ä¸ª")
        print(f"   æˆåŠŸç‡: {len(successful_results)/len(results)*100:.1f}%")
        
        # æ”¶é›†æˆåŠŸçš„æ–‡ä»¶
        successful_files = []
        print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        for result in successful_results:
            if result.file_paths:
                successful_files.extend(result.file_paths)
                print(f"   âœ… {result.model_name}: {os.path.basename(result.file_paths[0])}")
        
        # æ˜¾ç¤ºå¤±è´¥çš„ä»»åŠ¡
        if failed_results:
            print("âŒ å¤±è´¥çš„ä»»åŠ¡:")
            for result in failed_results:
                print(f"   {result.model_name}: {result.error}")
        
        return successful_files
        
    except Exception as e:
        print(f"âŒ æ··åˆæ¨¡å‹æ‰¹å¤„ç†å¤±è´¥: {e}")
        return []


# =============================================================================
# å®Œæ•´æ¼”ç¤ºå’Œæµ‹è¯•å‡½æ•°
# =============================================================================

async def run_all_examples():
    """è¿è¡Œæ‰€æœ‰ä¸‰ä¸ªä½¿ç”¨åœºæ™¯çš„å®Œæ•´æ¼”ç¤º"""
    
    print("ğŸš€ Replicate æ¨¡å‹è°ƒç”¨ - ä¸‰ç§åœºæ™¯å®Œæ•´æ¼”ç¤º")
    print("=" * 60)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs("output", exist_ok=True)
    
    all_files = []
    
    try:
        # åœºæ™¯1: å•ä¸ªå›¾åƒç”Ÿæˆ
        print("\n" + "=" * 60)
        single_file = single_image_generation()
        if single_file:
            all_files.append(single_file)
        
        # åœºæ™¯2: åŒæ¨¡å‹æ‰¹é‡ç”Ÿæˆ
        print("\n" + "=" * 60)
        batch_files = await batch_same_model()
        all_files.extend(batch_files)
        
        # åœºæ™¯3: æ··åˆæ¨¡å‹é«˜çº§æ‰¹å¤„ç†
        print("\n" + "=" * 60)
        mixed_files = await advanced_mixed_models()
        all_files.extend(mixed_files)
        
        # æœ€ç»ˆæ€»ç»“
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆ!")
        print(f"   æ€»ç”Ÿæˆæ–‡ä»¶: {len(all_files)} ä¸ª")
        print(f"   è¾“å‡ºç›®å½•: output/")
        print("   ä¸‰ç§ä½¿ç”¨åœºæ™¯éƒ½å·²ç»è¿‡æµ‹è¯•éªŒè¯")
        
        return all_files
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return all_files


# =============================================================================
# ç¤ºä¾‹5: Text-to-Speech with Chatterbox
# =============================================================================

def text_to_speech_example():
    """
    ä½¿ç”¨ Chatterbox æ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ°è¯­éŸ³è½¬æ¢
    æ”¯æŒæƒ…æ„Ÿæ§åˆ¶å’Œå¯é€‰çš„è¯­éŸ³å…‹éš†
    """
    print("\n" + "=" * 60)
    print("ğŸ¤ Text-to-Speech Example with Chatterbox")
    print("=" * 60)
    
    # åŸºæœ¬ TTS ç¤ºä¾‹
    print("\n1ï¸âƒ£ Basic Text-to-Speech:")
    basic_text = "Hello! This is a test of the Chatterbox text-to-speech model. It can generate natural sounding speech with emotion control."
    
    print(f"   Text: {basic_text[:50]}...")
    output_basic = replicate_model_calling(
        prompt=basic_text,
        model_name="resemble-ai/chatterbox",
        output_filepath="output/tts_basic.wav"
    )
    print(f"   âœ… Generated: {output_basic[0]}")
    
    # å¸¦å‚æ•°æ§åˆ¶çš„ TTS
    print("\n2ï¸âƒ£ TTS with Custom Parameters:")
    custom_text = "I'm speaking with different temperature and exaggeration settings. This creates more expressive speech!"
    
    output_custom = replicate_model_calling(
        prompt=custom_text,
        model_name="resemble-ai/chatterbox",
        output_filepath="output/tts_custom.wav",
        temperature=1.5,  # æ›´é«˜çš„æ¸©åº¦ï¼Œæ›´å¤šå˜åŒ–
        exaggeration=0.8,  # æ›´é«˜çš„å¤¸å¼ åº¦
        cfg_weight=0.7,
        seed=42  # å›ºå®šç§å­ä»¥ä¾¿å¤ç°
    )
    print(f"   Parameters used:")
    print(f"   - Temperature: 1.5 (more variation)")
    print(f"   - Exaggeration: 0.8 (more expressive)")
    print(f"   - CFG Weight: 0.7")
    print(f"   âœ… Generated: {output_custom[0]}")
    
    # å¸¦å‚è€ƒéŸ³é¢‘çš„ TTSï¼ˆè¯­éŸ³å…‹éš†ï¼‰- å¯é€‰
    print("\n3ï¸âƒ£ TTS with Voice Cloning (Optional):")
    clone_text = "If you provide a reference audio file, I can clone that voice style!"
    
    # æ£€æŸ¥æ˜¯å¦è¦ä½¿ç”¨å‚è€ƒéŸ³é¢‘
    use_ref = input("   Do you have a reference audio file for voice cloning? (y/n): ").lower().strip()
    
    if use_ref == 'y':
        ref_audio_path = input("   Enter the path to your reference audio file: ").strip()
        if ref_audio_path and os.path.exists(ref_audio_path):
            output_clone = replicate_model_calling(
                prompt=clone_text,
                model_name="resemble-ai/chatterbox",
                output_filepath="output/tts_cloned.wav",
                audio_prompt=ref_audio_path
            )
            print(f"   âœ… Generated with voice cloning: {output_clone[0]}")
        else:
            print("   âš ï¸ Reference audio file not found, skipping voice cloning example")
    else:
        print("   â­ï¸ Skipping voice cloning example")
    
    # æ‰¹é‡ TTS å¤„ç†
    print("\n4ï¸âƒ£ Batch TTS Processing:")
    texts = [
        "This is the first sentence.",
        "Here comes the second one with more emotion!",
        "And finally, the third sentence completes our batch."
    ]
    
    print("   Processing multiple texts...")
    for i, text in enumerate(texts, 1):
        output = replicate_model_calling(
            prompt=text,
            model_name="resemble-ai/chatterbox",
            output_filepath=f"output/tts_batch_{i}.wav",
            temperature=0.8 + (i * 0.2),  # é€’å¢æ¸©åº¦
            exaggeration=0.4 + (i * 0.1)  # é€’å¢å¤¸å¼ åº¦
        )
        print(f"   âœ… [{i}/3] Generated: {output[0]}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ Text-to-Speech examples completed!")
    print("=" * 60)
    
    return True


# =============================================================================
# äº¤äº’å¼é€‰æ‹©å‡½æ•°
# =============================================================================

async def interactive_examples():
    """äº¤äº’å¼é€‰æ‹©è¦è¿è¡Œçš„ç¤ºä¾‹"""
    
    print("ğŸ¯ Replicate æ¨¡å‹è°ƒç”¨ - ä½¿ç”¨ç¤ºä¾‹")
    print("è¯·é€‰æ‹©è¦è¿è¡Œçš„ç¤ºä¾‹:")
    print("1. å•ä¸ªå›¾åƒç”Ÿæˆ (æœ€ç®€å•)")
    print("2. åŒæ¨¡å‹æ‰¹é‡ç”Ÿæˆ (5ä¸ªå›¾åƒ)")
    print("3. æ··åˆæ¨¡å‹é«˜çº§æ‰¹å¤„ç† (5ä¸ªä¸åŒé…ç½®)")
    print("4. ğŸ¤ Text-to-Speech (ChatterboxéŸ³é¢‘ç”Ÿæˆ)")
    print("5. è¿è¡Œæ‰€æœ‰ç¤ºä¾‹")
    print("0. é€€å‡º")
    
    while True:
        try:
            choice = input("\nè¯·è¾“å…¥é€‰æ‹© (0-5): ").strip()
            
            if choice == '0':
                print("ğŸ‘‹ å†è§!")
                break
            elif choice == '1':
                single_image_generation()
            elif choice == '2':
                await batch_same_model()
            elif choice == '3':
                await advanced_mixed_models()
            elif choice == '4':
                text_to_speech_example()
            elif choice == '5':
                await run_all_examples()
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 0-5")
                continue
                
            print("\n" + "-" * 40)
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§!")
            break
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")


# =============================================================================
# ä¸»ç¨‹åºå…¥å£
# =============================================================================

if __name__ == "__main__":
    """
    ä½¿ç”¨è¯´æ˜:
    
    1. ç›´æ¥è¿è¡Œ: python example_usage.py
       - äº¤äº’å¼é€‰æ‹©è¦è¿è¡Œçš„ç¤ºä¾‹
    
    2. è¿è¡Œæ‰€æœ‰ç¤ºä¾‹: python example_usage.py all
       - è‡ªåŠ¨è¿è¡Œä¸‰ä¸ªåœºæ™¯çš„å®Œæ•´æ¼”ç¤º
       
    3. åœ¨ä½ çš„ä»£ç ä¸­å¯¼å…¥ä½¿ç”¨:
       from example_usage import single_image_generation, batch_same_model, advanced_mixed_models
    """
    
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == 'all':
        # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
        asyncio.run(run_all_examples())
    else:
        # äº¤äº’å¼é€‰æ‹©
        asyncio.run(interactive_examples())