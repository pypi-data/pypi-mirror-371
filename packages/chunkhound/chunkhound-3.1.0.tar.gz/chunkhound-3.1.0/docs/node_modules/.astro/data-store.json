[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.13.2","content-config-digest","9a95ec2e8398aaca","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://ofriw.github.io\",\"compressHTML\":true,\"base\":\"/chunkhound\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"where\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true,\"allowedHosts\":[]},\"redirects\":{},\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[],\"remotePatterns\":[],\"responsiveStyles\":false},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":false,\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[null,null,null],\"rehypePlugins\":[null,[null,{\"experimentalHeadingIdCompat\":false}],null,[null,{\"themes\":[\"github-light\",\"github-dark\"],\"defaultLocale\":\"en\",\"cascadeLayer\":\"starlight.components\",\"styleOverrides\":{\"borderRadius\":\"0px\",\"borderWidth\":\"1px\",\"codePaddingBlock\":\"0.75rem\",\"codePaddingInline\":\"1rem\",\"codeFontFamily\":\"var(--__sl-font-mono)\",\"codeFontSize\":\"var(--sl-text-code)\",\"codeLineHeight\":\"var(--sl-line-height)\",\"uiFontFamily\":\"var(--__sl-font)\",\"textMarkers\":{\"lineDiffIndicatorMarginLeft\":\"0.25rem\",\"defaultChroma\":\"45\",\"backgroundOpacity\":\"60%\"}},\"plugins\":[{\"name\":\"Starlight Plugin\",\"hooks\":{}},{\"name\":\"astro-expressive-code\",\"hooks\":{}}]}]],\"remarkRehype\":{},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"headingIdCompat\":false,\"preserveScriptOrder\":false,\"liveContentCollections\":false,\"csp\":false,\"staticImportMetaEnv\":false,\"chromeDevtoolsWorkspace\":false},\"legacy\":{\"collections\":false},\"prefetch\":{\"prefetchAll\":true},\"i18n\":{\"defaultLocale\":\"en\",\"locales\":[\"en\"],\"routing\":{\"prefixDefaultLocale\":false,\"redirectToDefaultLocale\":false,\"fallbackType\":\"redirect\"}}}","docs",["Map",11,12,36,37,47,48,58,59],"index",{"id":11,"data":13,"body":30,"filePath":31,"assetImports":32,"digest":35,"deferredRender":16},{"title":14,"description":15,"editUrl":16,"head":17,"template":18,"hero":19,"sidebar":27,"pagefind":16,"draft":28},"ChunkHound","Semantic and regex search for codebases via MCP",true,[],"doc",{"title":20,"tagline":21,"image":22,"actions":26},"","Modern RAG for your codebase - semantic and regex search via MCP",{"alt":23,"dark":24,"light":25},"ChunkHound Logo","__ASTRO_IMAGE_../../assets/wordmark-dark.svg","__ASTRO_IMAGE_../../assets/wordmark.svg",[],{"hidden":28,"attrs":29},false,{},"import { Tabs, TabItem } from '@astrojs/starlight/components';\n\n## What it does\n\nLLMs like Claude and GPT don't know your codebase - they only know what they were trained on. Every time they help you code, they need to search your files to understand your project's specific patterns and terminology.\n\nChunkHound gives AI assistants two ways to explore your code:\n- **Semantic search** - Finds code by meaning, so when the AI looks for \"user authentication\" it also finds your `validateLogin()` and `checkCredentials()` functions\n- **Regex search** - Pattern matching for precise code structures\n\nTraditional search was built for humans who know what they're looking for. But AI assistants start with zero knowledge about your codebase. Semantic search bridges this gap by understanding that \"database timeout\" and \"SQL connection lost\" are related concepts, even though they share no keywords.\n\n## Requirements\n\n- Python 3.10+\n- [uv package manager](https://docs.astral.sh/uv/)\n- API key for semantic search (optional)\n\n## Installation\n\n```bash\n# Install uv package manager\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Install ChunkHound\nuv tool install chunkhound\n```\n\n## Configuration\n\nChunkHound works **without configuration** for regex search. For semantic search, create `.chunkhound.json` in your project root:\n\n\u003CTabs syncKey=\"provider\">\n  \u003CTabItem label=\"VoyageAI (Recommended)\">\n    **Best for:** Fastest, most accurate, and cost effective\n\n    ```json\n    {\n      \"embedding\": {\n        \"provider\": \"voyageai\",\n        \"api_key\": \"pa-your-voyage-key\"\n      }\n    }\n    ```\n\n    Get API key from [VoyageAI Console](https://dash.voyageai.com/)\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"OpenAI\">\n    **Best for:** Wide compatibility and ecosystem\n\n    ```json\n    {\n      \"embedding\": {\n        \"provider\": \"openai\",\n        \"api_key\": \"sk-your-openai-key\"\n      }\n    }\n    ```\n\n    Get API key from [OpenAI Platform](https://platform.openai.com/api-keys)\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Local (Ollama)\">\n    **Best for:** Privacy and offline use\n\n    ```bash\n    # Start Ollama with embedding model\n    ollama pull nomic-embed-text\n    ```\n\n    ```json\n    {\n      \"embedding\": {\n        \"provider\": \"openai\",\n        \"base_url\": \"http://localhost:11434/v1\",\n        \"model\": \"nomic-embed-text\"\n      }\n    }\n    ```\n\n    No API key required - completely local\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## IDE Setup\n\nConfigure ChunkHound as an MCP server in your AI assistant:\n\n\u003CTabs syncKey=\"ide-setup\">\n  \u003CTabItem label=\"Claude Code\">\n    Add to `~/.claude.json`:\n    ```json\n    {\n      \"mcpServers\": {\n        \"chunkhound\": {\n          \"command\": \"chunkhound\",\n          \"args\": [\"mcp\"]\n        }\n      }\n    }\n    ```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"VS Code\">\n    Add to `.vscode/mcp.json`:\n    ```json\n    {\n      \"servers\": {\n        \"chunkhound\": {\n          \"type\": \"stdio\",\n          \"command\": \"chunkhound\",\n          \"args\": [\"mcp\", \"/path/to/project\"]\n        }\n      }\n    }\n    ```\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Cursor\">\n    Add to `.cursor/mcp.json`:\n    ```json\n    {\n      \"mcpServers\": {\n        \"chunkhound\": {\n          \"command\": \"chunkhound\",\n          \"args\": [\"mcp\", \"/path/to/project\"]\n        }\n      }\n    }\n    ```\n  \u003C/TabItem>\n\u003C/Tabs>\n\n## Initial Indexing\n\n```bash\n# Index your codebase (respects .gitignore automatically)\ncd /path/to/project && chunkhound index\n```\n\n## Documentation\n\n- [Tutorial](/tutorial/) - Learn ChunkHound in 5 minutes\n- [Configuration](/configuration/) - Complete configuration reference\n- [Under the Hood](/under-the-hood/) - Technical deep dive into architecture and algorithms\n\n## Links\n\n- [GitHub Repository](https://github.com/ofriw/chunkhound)\n- [Report Issues](https://github.com/ofriw/chunkhound/issues)","src/content/docs/index.mdx",[33,34],"../../assets/wordmark-dark.svg","../../assets/wordmark.svg","46adc8d6b62db6f9","under-the-hood",{"id":36,"data":38,"body":44,"filePath":45,"digest":46,"deferredRender":16},{"title":39,"description":40,"editUrl":16,"head":41,"template":18,"sidebar":42,"pagefind":16,"draft":28},"Under the Hood","Technical deep dive into ChunkHound's architecture, algorithms, and design decisions",[],{"hidden":28,"attrs":43},{},"import { Tabs, TabItem } from '@astrojs/starlight/components';\nimport { Card, CardGrid, Aside } from '@astrojs/starlight/components';\nimport SemanticSearchFlow from '../../components/SemanticSearchFlow.tsx';\nimport TwoHopSearchFlow from '../../components/TwoHopSearchFlow.tsx';\n\n## Architecture Overview\n\nChunkHound uses a local-first architecture with embedded databases and universal code parsing:\n\n\u003CCardGrid>\n  \u003CCard title=\"Database Layer\" icon=\"setting\">\n    **DuckDB** (primary) - OLAP columnar database with HNSW vector indexing\n    **LanceDB** (experimental) - Purpose-built vector database with disk-based storage\n  \u003C/Card>\n\n  \u003CCard title=\"Parsing Engine\" icon=\"open-book\">\n    **Tree-sitter** - Universal AST parser supporting 20+ languages\n    **Language-agnostic** - Same semantic concepts across all languages\n  \u003C/Card>\n\n  \u003CCard title=\"Flexible Providers\" icon=\"puzzle\">\n    **Pluggable backends** - OpenAI, VoyageAI, Ollama\n    **Cloud & Local** - Run with APIs or fully offline with local models\n  \u003C/Card>\n\n  \u003CCard title=\"Advanced Algorithms\" icon=\"rocket\">\n    **cAST** - Semantic code chunking preserving AST structure\n    **Two-Hop Search** - Context-aware search with reranking\n  \u003C/Card>\n\u003C/CardGrid>\n\nChunkHound's local-first architecture provides key advantages: **Privacy** - Your code never leaves your machine. **Speed** - No network latency or API rate limits. **Reliability** - Works offline and in air-gapped environments. **Cost** - No per-token charges for indexing large codebases.\n\n## The cAST Algorithm\n\nWhen AI assistants search your codebase, they need code split into \"chunks\" - searchable pieces small enough to understand but large enough to be meaningful. The challenge: how do you split code without breaking its logic?\n\n### Three Approaches Compared\n\n**1. Naive Fixed-Size Chunking**\n\nSplit every 1000 characters regardless of code structure:\n\n```python\ndef authenticate_user(username, password):\n    if not username or not password:\n        return False\n\n    hashed = hash_password(password)\n    user = database.get_u\n# CHUNK BOUNDARY CUTS HERE ❌\nser(username)\n    return user and user.password_hash == hashed\n```\n\n**Problem**: Functions get cut in half, breaking meaning.\n\n**2. Naive AST Chunking**\n\nSplit only at function/class boundaries:\n\n```python\n# Chunk 1: Tiny function (50 characters)\ndef get_name(self):\n    return self.name\n\n# Chunk 2: Massive function (5000 characters)\ndef process_entire_request(self, request):\n    # ... 200 lines of complex logic ...\n```\n\n**Problem**: Creates chunks that are too big or too small.\n\n**3. Smart cAST Algorithm (ChunkHound's Solution)**\n\nRespects code boundaries AND enforces size limits:\n\n```python\n# Right-sized chunks that preserve meaning\ndef authenticate_user(username, password):    # ✅ Complete function\n    if not username or not password:          #    fits in one chunk\n        return False\n    hashed = hash_password(password)\n    user = database.get_user(username)\n    return user and user.password_hash == hashed\n\ndef hash_password(password):                  # ✅ Small adjacent functions\ndef validate_email(email):                   #    merged together\ndef sanitize_input(data):\n    # All fit together in one chunk\n```\n\n### How cAST Works\n\nThe algorithm is surprisingly simple:\n\n1. **Parse** code into a syntax tree (AST)\n2. **Walk** the tree top-down (classes → functions → statements)\n3. **For each piece**:\n   - If it fits in size limit (1200 chars) → make it a chunk\n   - If too big → split at smart boundaries (`;`, `}`, line breaks)\n   - If too small → merge with neighboring pieces\n4. **Result**: Every chunk is meaningful code that fits in context window\n\n\u003CAside type=\"tip\">\n**Think of code like paragraphs in an essay**. You wouldn't split a paragraph mid-sentence - cAST doesn't split code mid-statement. It keeps related logic together while respecting size limits.\n\u003C/Aside>\n\n### Why This Matters for AI\n\n- **Better Search**: Find complete functions, not fragments\n- **Better Context**: AI sees full logic flow, not half-statements\n- **Better Results**: AI gives accurate suggestions based on complete code understanding\n\nTraditional chunking gives AI puzzle pieces. cAST gives it complete pictures.\n\n## Semantic Search Architecture\n\nChunkHound provides two search modes depending on your embedding provider's capabilities.\n\n### Regular Semantic Search\n\nThe standard approach used by most embedding providers:\n\n\u003CSemanticSearchFlow client:load />\n\n**How it works**:\n1. Convert query to embedding vector\n2. Search the vector index for nearest neighbors\n3. Return top-k most similar code chunks\n\n### Two-Hop Semantic Search\n\nAdvanced search for providers with reranking (VoyageAI, custom servers):\n\n\u003CTwoHopSearchFlow client:load />\n\n**Why it's better**:\n- **Semantic bridging**: Discovers related concepts through intermediate connections\n- **Example**: Search \"authentication\" → finds `validateLogin()` → discovers related `hashPassword()` through semantic similarity\n- **Context expansion**: Finds supporting functions you might not think to search for\n\n\u003CAside type=\"tip\" title=\"When Two-Hop Activates\">\nTwo-hop search automatically activates when you use providers with reranking support:\n- **VoyageAI**: Built-in `rerank-lite-1` model\n- **Custom servers**: With reranking endpoints\n- **OpenAI**: Falls back to regular search (no reranking)\n\u003C/Aside>","src/content/docs/under-the-hood.mdx","c34e250ca786c8fd","configuration",{"id":47,"data":49,"body":55,"filePath":56,"digest":57,"deferredRender":16},{"title":50,"description":51,"editUrl":16,"head":52,"template":18,"sidebar":53,"pagefind":16,"draft":28},"Configuration","Complete reference for all ChunkHound configuration options",[],{"hidden":28,"attrs":54},{},"import { Tabs, TabItem } from '@astrojs/starlight/components';\nimport { Card, CardGrid, Aside } from '@astrojs/starlight/components';\n\n## Configuration Sources\n\nChunkHound uses a 5-level configuration hierarchy. Each source can override the previous ones:\n\n1. **CLI arguments** (highest priority) - `--api-key`, `--model`, `--debug`\n2. **Local `.chunkhound.json`** - Project-specific config in target directory\n3. **Config file** - Specified via `--config` path or `CHUNKHOUND_CONFIG_FILE`\n4. **Environment variables** - `CHUNKHOUND_*` prefixed variables\n5. **Default values** (lowest priority) - Built-in defaults\n\n\u003CAside type=\"tip\" title=\"Configuration Discovery\">\nChunkHound automatically looks for `.chunkhound.json` in your project directory. No need to specify paths manually!\n\u003C/Aside>\n\n## Complete Configuration Schema\n\n### Full JSON Configuration\n\n```json\n{\n  \"database\": {\n    \"provider\": \"duckdb\",\n    \"path\": \"/path/to/database\"\n  },\n  \"embedding\": {\n    \"provider\": \"voyageai\",\n    \"model\": \"voyage-3.5\",\n    \"api_key\": \"pa-your-key\",\n    \"base_url\": \"https://api.voyageai.com/v1\",\n    \"rerank_model\": \"rerank-lite-1\",\n    \"rerank_url\": \"/rerank\"\n  },\n  \"indexing\": {\n    \"include\": [\"**/*.py\", \"**/*.js\", \"**/*.ts\"],\n    \"exclude\": [\"**/node_modules/**\", \"**/__pycache__/**\"]\n  },\n  \"mcp\": {\n    \"transport\": \"stdio\",\n    \"host\": \"0.0.0.0\",\n    \"port\": 3000\n  },\n  \"debug\": false\n}\n```\n\n## Database Configuration\n\n\u003CCardGrid>\n  \u003CCard title=\"DuckDB (Default)\" icon=\"database\">\n    **File**: Single `.db` file\n    **Performance**: Excellent for code search\n    **Storage**: Efficient columnar format\n    **Setup**: Zero configuration required\n  \u003C/Card>\n\n  \u003CCard title=\"LanceDB (Alternative)\" icon=\"database\">\n    **File**: Directory with multiple files\n    **Performance**: Optimized for vector operations\n    **Storage**: Native vector format\n    **Setup**: Set `\"provider\": \"lancedb\"`\n  \u003C/Card>\n\u003C/CardGrid>\n\n### Database Options\n\n| Field | Type | Default | Description |\n|-------|------|---------|-------------|\n| `provider` | `\"duckdb\"` \\| `\"lancedb\"` | `\"duckdb\"` | Database engine |\n| `path` | `string` | `.chunkhound` | Database directory path |\n\n**Environment Variables**:\n- `CHUNKHOUND_DATABASE__PROVIDER` - Database provider\n- `CHUNKHOUND_DATABASE__PATH` - Database directory path\n\n**CLI Arguments**:\n- `--database-provider` - Choose database provider\n- `--db`, `--database-path` - Set database path\n\n## Embedding Configuration\n\n\u003CTabs syncKey=\"embedding-provider\">\n  \u003CTabItem label=\"VoyageAI\">\n    **Best for**: Accuracy, cost efficiency, code understanding\n\n    ```json\n    {\n      \"embedding\": {\n        \"provider\": \"voyageai\",\n        \"api_key\": \"pa-your-voyage-key\",\n        \"model\": \"voyage-3.5\",\n        \"rerank_model\": \"rerank-lite-1\"\n      }\n    }\n    ```\n\n    **Available Models**:\n    - `voyage-3.5` (default) - General purpose, 1024 dimensions\n    - `voyage-code-3` - Optimized for code, 1024 dimensions\n    - `voyage-3-large` - Higher accuracy, 1024 dimensions\n    - `voyage-law-2` - Legal documents, 1024 dimensions\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"OpenAI\">\n    **Best for**: Wide compatibility and ecosystem support\n\n    ```json\n    {\n      \"embedding\": {\n        \"provider\": \"openai\",\n        \"api_key\": \"sk-your-openai-key\",\n        \"model\": \"text-embedding-3-small\"\n      }\n    }\n    ```\n\n    **Available Models**:\n    - `text-embedding-3-small` (default) - Fast, 1536 dimensions\n    - `text-embedding-3-large` - Higher accuracy, 3072 dimensions\n    - `text-embedding-ada-002` - Legacy model, 1536 dimensions\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"Custom/Local\">\n    **Best for**: Privacy, custom models, local deployment\n\n    ```json\n    {\n      \"embedding\": {\n        \"provider\": \"openai\",\n        \"base_url\": \"http://localhost:11434/v1\",\n        \"model\": \"nomic-embed-text\"\n      }\n    }\n    ```\n\n    **Compatible Servers**:\n    - **Ollama** - `http://localhost:11434/v1`\n    - **LocalAI** - `http://localhost:8080/v1`\n    - **LM Studio** - `http://localhost:1234/v1`\n    - **Custom OpenAI-compatible APIs**\n  \u003C/TabItem>\n\u003C/Tabs>\n\n### Embedding Options\n\n| Field | Type | Default | Description |\n|-------|------|---------|-------------|\n| `provider` | `\"openai\"` \\| `\"voyageai\"` | None | Embedding provider |\n| `model` | `string` | Provider default | Model name |\n| `api_key` | `string` | None | API key for authentication |\n| `base_url` | `string` | Provider default | Custom API base URL |\n| `rerank_model` | `string` | None | Reranking model |\n| `rerank_url` | `string` | `\"/rerank\"` | Rerank endpoint path |\n\n## Indexing Configuration\n\n### File Discovery\n\nChunkHound automatically respects `.gitignore` files and includes comprehensive defaults:\n\n**Default Include Patterns**:\n```json\n[\n  \"**/*.py\", \"**/*.js\", \"**/*.ts\", \"**/*.tsx\", \"**/*.jsx\",\n  \"**/*.go\", \"**/*.rs\", \"**/*.java\", \"**/*.c\", \"**/*.cpp\",\n  \"**/*.h\", \"**/*.hpp\", \"**/*.cs\", \"**/*.php\", \"**/*.rb\",\n  \"**/*.swift\", \"**/*.kt\", \"**/*.scala\", \"**/*.clj\",\n  \"**/*.sh\", \"**/*.bash\", \"**/*.zsh\", \"**/*.fish\",\n  \"**/*.sql\", \"**/*.json\", \"**/*.yaml\", \"**/*.yml\",\n  \"**/*.toml\", \"**/*.xml\", \"**/*.html\", \"**/*.css\",\n  \"**/*.scss\", \"**/*.sass\", \"**/*.less\", \"**/*.md\",\n  \"**/*.rst\", \"**/*.txt\", \"**/*.dockerfile\",\n  \"**/Dockerfile*\", \"**/Makefile*\", \"**/*.mk\"\n]\n```\n\n**Default Exclude Patterns**:\n```json\n[\n  \"**/node_modules/**\", \"**/.git/**\", \"**/__pycache__/**\",\n  \"**/venv/**\", \"**/.venv/**\", \"**/dist/**\", \"**/build/**\",\n  \"**/target/**\", \"**/.vscode/**\", \"**/.idea/**\",\n  \"**/*.tmp*\", \"**/*.swp\", \"**/*.swo\", \"**/*.min.js\",\n  \"**/*.min.css\", \"**/package-lock.json\", \"**/yarn.lock\"\n]\n```\n\n### Indexing Options\n\n| Field | Type | Default | Description |\n|-------|------|---------|-------------|\n| `include` | `string[]` | Comprehensive list | File patterns to include |\n| `exclude` | `string[]` | Comprehensive list | File patterns to exclude |\n\n**Environment Variables**:\n- `CHUNKHOUND_INDEXING__INCLUDE` - Comma-separated include patterns\n- `CHUNKHOUND_INDEXING__EXCLUDE` - Comma-separated exclude patterns\n\n**CLI Arguments**:\n- `--force-reindex` - Force reindexing all files\n- `--include PATTERN` - Add include pattern (can be used multiple times)\n- `--exclude PATTERN` - Add exclude pattern (can be used multiple times)\n\n## MCP Server Configuration\n\nMCP transport mode is controlled via CLI arguments when starting the server, not through configuration files.\n\n\u003CTabs syncKey=\"mcp-transport\">\n  \u003CTabItem label=\"stdio (Default)\">\n    **Best for**: IDE integrations (Claude Desktop, Claude Code, Cursor)\n\n    ```bash\n    # Default stdio mode\n    chunkhound mcp\n\n    # Explicit stdio mode\n    chunkhound mcp --stdio\n    ```\n\n    Uses standard input/output for communication. Most IDE integrations expect this mode.\n  \u003C/TabItem>\n\n  \u003CTabItem label=\"HTTP\">\n    **Best for**: Web applications, VS Code extensions, debugging\n\n    ```bash\n    # HTTP mode with default port (3000)\n    chunkhound mcp --http\n\n    # HTTP mode with custom port and host\n    chunkhound mcp --http --port 8000 --host 127.0.0.1\n    ```\n\n    Runs an HTTP server for MCP communication. Easier to debug and test.\n  \u003C/TabItem>\n\u003C/Tabs>\n\n### CLI Arguments for MCP Server\n\n| Argument | Description | Example |\n|----------|-------------|---------|\n| `--stdio` | Use stdio transport (default) | `chunkhound mcp --stdio` |\n| `--http` | Use HTTP transport | `chunkhound mcp --http` |\n| `--host HOST` | Set HTTP server host | `chunkhound mcp --http --host localhost` |\n| `--port PORT` | Set HTTP server port | `chunkhound mcp --http --port 8000` |\n\n**Environment Variables** (for HTTP mode):\n- `CHUNKHOUND_MCP__HOST` - Default HTTP server host\n- `CHUNKHOUND_MCP__PORT` - Default HTTP server port\n\n## Environment Variables Reference\n\n### Naming Convention\n\nChunkHound uses a standardized naming pattern:\n- **Prefix**: `CHUNKHOUND_`\n- **Sections**: Separated by `__` (double underscore)\n- **Example**: `CHUNKHOUND_EMBEDDING__API_KEY`\n\n### Complete Environment Variables List\n\n```bash\n# Main Configuration\nCHUNKHOUND_DEBUG=true                           # Enable debug mode\nCHUNKHOUND_CONFIG_FILE=/path/to/config.json     # Config file path\n\n# Database Configuration\nCHUNKHOUND_DATABASE__PROVIDER=duckdb            # Database provider\nCHUNKHOUND_DATABASE__PATH=/custom/db/path       # Database directory\n\n# Embedding Configuration\nCHUNKHOUND_EMBEDDING__PROVIDER=voyageai         # Embedding provider\nCHUNKHOUND_EMBEDDING__API_KEY=pa-your-key       # API key\nCHUNKHOUND_EMBEDDING__BASE_URL=https://api...   # Custom base URL\nCHUNKHOUND_EMBEDDING__MODEL=voyage-3.5          # Model name\n\n# Indexing Configuration\nCHUNKHOUND_INDEXING__INCLUDE=\"*.py,*.js\"       # Include patterns\nCHUNKHOUND_INDEXING__EXCLUDE=\"*/tests/*\"       # Exclude patterns\n\n# MCP Configuration (HTTP mode only)\nCHUNKHOUND_MCP__HOST=localhost                  # Default HTTP server host\nCHUNKHOUND_MCP__PORT=8080                       # Default HTTP server port\n\n# Provider Fallback Variables\nOPENAI_API_KEY=sk-your-key                      # OpenAI API key fallback\nOPENAI_BASE_URL=https://api.openai.com/v1       # OpenAI base URL fallback\nVOYAGE_API_KEY=pa-your-key                      # VoyageAI API key fallback\n```","src/content/docs/configuration.mdx","2a8ab258deddfc2b","tutorial",{"id":58,"data":60,"body":66,"filePath":67,"digest":68,"deferredRender":16},{"title":61,"description":62,"editUrl":16,"head":63,"template":18,"sidebar":64,"pagefind":16,"draft":28},"ChunkHound Tutorial","Learn ChunkHound in 5 minutes - from installation to advanced search",[],{"hidden":28,"attrs":65},{},"import { Tabs, TabItem } from '@astrojs/starlight/components';\nimport { Card, CardGrid, Aside } from '@astrojs/starlight/components';\n\n## Understanding ChunkHound\n\nChunkHound transforms your codebase into a searchable knowledge base for AI assistants. It provides two powerful search methods:\n- **Semantic search** - Natural language queries that understand meaning and context\n- **Regex search** - Precise pattern matching for exact code structures\n\n## The Index Command - Your Knowledge Base\n\n### Why Index Separately?\n\nFor large codebases, indexing is a separate step that provides significant benefits:\n\n\u003CCardGrid>\n  \u003CCard title=\"Performance\" icon=\"rocket\">\n    **Index once, search many times**\n    Initial indexing takes time, but subsequent searches are instant\n  \u003C/Card>\n\n  \u003CCard title=\"Smart Diffing\" icon=\"puzzle\">\n    **Only processes changed files**\n    Preserves embeddings for unchanged code\n  \u003C/Card>\n\n  \u003CCard title=\"Fix Command\" icon=\"setting\">\n    **Repairs inconsistencies**\n    `chunkhound index` detects and fixes database drift\n  \u003C/Card>\n\n  \u003CCard title=\"Enterprise Ready\" icon=\"approve-check\">\n    **Battle-tested scaling**\n    Used on codebases with 75k+ LOC\n  \u003C/Card>\n\u003C/CardGrid>\n\n### Example: Initial Index\n\n```bash\n$ chunkhound index /path/to/large-codebase\nScanning 10,000 files...\nProcessing 8,234 Python files, 1,766 TypeScript files...\n✓ 45,000 chunks indexed\n✓ Embeddings: 45,000 generated\n⏱️  Time: 34m 30s\n```\n\n### Example: Incremental Update\n\n```bash\n$ chunkhound index  # After editing 3 files\nDetecting changes...\n✓ 3 files modified, 8,234 files unchanged\n✓ 150 chunks updated\n✓ Embeddings: 150 generated, 45,000 reused\n⏱️  Time: 18 seconds\n```\n\n\u003CAside type=\"tip\" title=\"Performance Tip\">\nYou can re-index frequently without penalty. Run `chunkhound index` after major code changes.\n\u003C/Aside>\n\n## Choosing Your Server Mode\n\n| **Use Case** | **Mode** | **Command** |\n|--------------|----------|-------------|\n| Personal development | stdio | `chunkhound mcp` |\n| Team/production use | HTTP | `chunkhound mcp --http` |\n\n### stdio Mode - Let Your IDE Handle It\n\nYour IDE starts/stops the server automatically. The index stays in memory for instant searches. Perfect for personal development with a single IDE.\n\n```bash\nchunkhound mcp /path/to/project\n```\n\n### HTTP Mode - Shared Server\n\nYou start the server once, multiple IDEs can connect. Ideal for teams or when switching between multiple git worktrees.\n\n```bash\nchunkhound mcp /path/to/project --http --port 8000\n# Connect IDEs to http://localhost:8000\n```\n\n\u003CAside type=\"tip\">\n**Quick rule**: Use stdio for personal work, HTTP for everything else.\n\u003C/Aside>\n\n## Production Usage\n\nChunkHound is production-ready and actively tested:\n\n\u003CCardGrid>\n  \u003CCard title=\"Enterprise Scale\" icon=\"star\">\n    **75k+ LOC indexed**\n\n    Proven on massive monorepos with complex dependency graphs\n  \u003C/Card>\n\n  \u003CCard title=\"Real-World Testing\" icon=\"laptop\">\n    **Enterprise Validated**\n\n    Tested on multiple enterprise projects and [GoatDB's](https://goatdb.dev) TypeScript codebase\n  \u003C/Card>\n\n  \u003CCard title=\"Multi-Language Support\" icon=\"translate\">\n    **20+ Languages**\n\n    Python, TypeScript, Go, Rust, Java, C++, and more via Tree-sitter\n  \u003C/Card>\n\n  \u003CCard title=\"AI-Built Architecture\" icon=\"rocket\">\n    **100% AI-Generated**\n\n    Entire codebase written by AI agents, battle-tested through usage\n  \u003C/Card>\n\u003C/CardGrid>\n\n## Next Steps\n\nNow that you understand ChunkHound's core concepts:\n\n1. **Start using it** - Index your codebase and connect your AI assistant\n2. **[Advanced configuration](/configuration/)** - Advanced configuration options\n3. **[Technical deep dive](/under-the-hood/)** - Understand the architecture\n\n\u003CAside type=\"note\" title=\"Questions or Issues?\">\nChunkHound is actively developed. Report issues or ask questions on [GitHub](https://github.com/ofriw/chunkhound/issues).\n\u003C/Aside>","src/content/docs/tutorial.mdx","846fb7aeb8e163f0"]