#coding:utf-8
import random
import time
from threading import Thread
from DrissionPage import WebPage, ChromiumOptions
from DrissionPage.errors import ElementNotFoundError
from DrissionPage.common import Keys
import requests
import json
import re
from wadeTools import wadeTools_error, wadeTools_Police, wadeTools_path, wadeTools_feishu
from wadeTools import wadeTools_UserJSON, wadeTools_Text
from retrying import retry
from wadeTools.wadeTools_Request import HEADERS
from wadeTools.wadeTools_Print import wadePrint
# è¿™ä¸ªç±»ä»¥åè¦æ‰©å±•å¾ˆå¤šæ¥å£
class JDSpider():
    @wadeTools_Police.safe_Mode([],[],'çˆ¬è¯„è®ºå‡ºé”™')
    @retry(stop_max_attempt_number=5,wait_random_min=3)
    def spider_Newcomment(self, id, page,proxies=None,sortType=5):

        """çˆ¬æœ€æ–°çš„è¯„è®ºï¼Œåªè´Ÿè´£çˆ¬è¯„è®ºï¼Œå…¶ä»–çš„å•¥éƒ½ä¸ç®¡ï¼Œ è¾“å…¥å•†å“ID,pageï¼Œè¾“å‡º  commentList, imgList, 'ğŸ˜†jdmainè½¬æ¢æ­£å¸¸'  # æ‰“ä¹±é‡æ‹
        score 0å…¨éƒ¨è¯„è®º 1æ˜¯å·®è¯„ 2æ˜¯ä¸­è¯„ 3æ˜¯å¥½è¯„
        sortType 5æ˜¯çƒ­è¯„æ’åº 6æ˜¯æ—¶é—´æ’åº 7æ˜¯è§†é¢‘è¯„è®º
        """
        url = f'https://club.jd.com/comment/skuProductPageComments.action?callback=fetchJSON_comment98&productId={id}&score=3&sortType={sortType}&page={page}&pageSize=10&isShadowSku=0&rid=0&fold=1'
        headers = {
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'User-Agent': random.choice(HEADERS),
            'Connection': 'keep-alive',
            'Host': 'club.jd.com',
        }
        with requests.Session() as session:
            html = session.get(url=url, headers=headers,proxies=proxies,timeout=10)

        # å»æ‰å¤šä½™å¾—åˆ°jsonæ ¼å¼
        if html.status_code==200 and 'fetchJSON_comment' not in html.text:
            #ç©ºè¯„ä»·ï¼Œè¿”å›ç©º
            return ([],[],'html.status_code==200 and fetchJSON_comment not in html.text')

        if html.status_code==200:
            wadePrint(f'IPæ­£å¸¸ï¼šå½“å‰æ­£åœ¨è¯·æ±‚ç¬¬{page}é¡µè¯„è®ºå’Œå›¾ç‰‡æ•°æ®')
        wadePrint(html.text)
        # å¼€å§‹æ¸…æ´—æ•°æ®
        content = html.text.strip('fetchJSON_comment98vv995();')
        content = content.strip('fetchJSON_comment98vv37();')
        json_flag = json.loads(content, strict=False)  # æ”¶åˆ°çš„strå†…å®¹è¿›è¡Œæ¸…æ´—å¤„ç†ï¼Œå˜æˆå¯ç”¨çš„jsonï¼Œå¤„ç†å¥½äº†

        # wadePrint('jdmainè¿è¡ŒæˆåŠŸï¼ˆäº¬ä¸œçˆ¬è™«ä¸»ç¨‹åºï¼‰')
        JSONlist = json_flag["comments"]
        if JSONlist == []:  #ç©ºçš„è¯´æ˜æœ¬é¡µæœ¬èº«æ— å†…
            return ([], [], f'ç¬¬{page}é¡µè¯„è®ºæ•°æ®ä¸ºç©º')
        commentList = []
        imgList = []
        # wadePrint(JSONlist)

        for item in JSONlist:

            commentList.extend(wadeTools_UserJSON.getValueList_From_Dict_By_Key_ExceptSbKey(item,"content",['replies','afterUserComment']))
            imgList.extend(wadeTools_UserJSON.getValueList_From_Dict_By_Key_ExceptSbKey(item,"imgUrl",[]))
            # wadePrint(commentList)
            # è¿‡æ»¤åƒåœ¾è¯„è®º
        commentList = wadeTools_Text.delBadItemFromList(commentList,wadeTools_Text.getDefaultBadWords())  #
        commentList = [item for item in commentList if len(item)>=10]
        commentList = sorted(commentList,key=len,reverse=True)

        # wadePrint(imgList)
        imgListNew = []
        for this_imgUrl in imgList:
            # urlç»Ÿä¸€ä¿®æ”¹å‡½æ•°ï¼šæŠŠé‡Œè¾¹çš„n0å­—ç¬¦ä¸²æ›¿æ¢ï¼Œå°ºå¯¸ä¹Ÿæ›¿æ¢æ‰ æ”¹æˆs720x540
            if 'img30.360buyimg.com/n0/' in this_imgUrl:
                this_imgUrl = this_imgUrl.replace("img30.360buyimg.com/n0/",
                                                  "img30.360buyimg.com/n1/")
            if 's128x96_jfs/' in this_imgUrl:
                this_imgUrl = this_imgUrl.replace("s128x96_jfs/", "s720x540_jfs/")
            if '\n' in this_imgUrl:
                this_imgUrl = this_imgUrl.replace('\n', '')
            if '\r' in this_imgUrl:
                this_imgUrl = this_imgUrl.replace('\r', '')
            # if '//' in this_imgUrl:
            #     this_imgUrl = this_imgUrl.replace("//", "")
            imgListNew.append(this_imgUrl)
            del this_imgUrl  # é”€æ¯å˜é‡

        imgList = imgListNew
        del imgListNew

        random.shuffle(commentList)
        random.shuffle(imgList)

        del content,json_flag,JSONlist
        return (commentList, imgList, 'ğŸ˜†jdmainè½¬æ¢æ­£å¸¸')  # æ‰“ä¹±é‡æ‹

    @wadeTools_Police.safe_Mode([])
    @retry(stop_max_attempt_number=5, wait_random_min=3)
    def spider_itemData(self, id,proxies=None):
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å•†å“å‚æ•°åº“
        wadeTools_path.checkFilePath('å•†å“å‚æ•°åº“')
        try:
            # å¦‚æœå‚æ•°åº“ä¸­æœ‰å°±ä¸ç”¨è¯·æ±‚äº†
            itemDataList = wadeTools_UserJSON.readjson(f'å•†å“å‚æ•°åº“/{id}')
            wadePrint(f"{id}--æˆåŠŸåŠ è½½åº“ä¸­å•†å“å‚æ•°....")
            return (itemDataList)
        except FileNotFoundError:

            # wadePrint(1)
            """çˆ¬å•†å“ä¿¡æ¯"""
            headers = {
                'Accept': '*/*',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'User-Agent': random.choice(HEADERS),
                'Connection': 'keep-alive',
                'Host': 'item.jd.com',
                'cookie': '__jdu=1734234452490698444113; shshshfpa=348768b0-2db6-6975-701b-8806212a360f-1734234453; shshshfpx=348768b0-2db6-6975-701b-8806212a360f-1734234453; _base_=YKH2KDFHMOZBLCUV7NSRBWQUJPBI7JIMU5R3EFJ5UDHJ5LCU7R2NILKK5UJ6GLA2RGYT464UKXAI4Z6HPCTN4UQM3WHVQ4ENFP57OC42IY6KIHS3K6LGGVHIT4HK4V34TCNE6YVKRXISUOMSORKLWKHP26UVH46IGQS4XX2SG4SOQWCP5WPWO6EFS7HEHMRWVKBRVHB33TFD5EX5PZYGBFPE3NNFL5EMGOMYKHKDXUXEXIYMM754UEEO27G4MQ6BOJX7RLRW37V6KA2D4ZKSH4RVPCUSKABKJZDW5EDMTTJWVDYWOMZSFS6B4DTLR7CXIKFZ5Q723KWBCTLPPIF3FVZJBY; pinId=w3NN1JXR88LgQNJQMCMYmw; unick=%E7%82%B9%E6%88%91%E4%B8%8B%E5%96%AE%E6%9B%B4%E4%BE%BF%E5%AE%9C; _tp=RnXd490p0A8w6swDdN3FcA%3D%3D; _pst=jd_DgzZpkHEQlFG; __jdv=209449046|direct|-|none|-|1740040897468; areaId=7; ipLoc-djd=7-427-3557-53893; jsavif=1; jsavif=1; user-key=9715d11d-6d18-4304-be20-2a3a9b8ecccd; 3AB9D23F7A4B3C9B=SRQK3ESS76RF76R4XHLIESTUAHA6ACY2E2SZGJYIZVGVBO6BWKOZHKPPORTB7FWL52HS432WZK4TRGAV7WWUOEETFM; PCSYCityID=CN_410000_410300_0; umc_count=1; TrackID=1zufm4ELWgBwNOlOQUKYJ6bvZ8vT0k5AXW9B1hiXGVXiQGsXjQQ6wlOno-EXz-1UznUgMyM9z5dlUSpD_1w2R5wa8TeYYdYOj2U42W1C50_h_jjhLwjaT6k3gkwJzChew; thor=A950C58AE39C76DB638A05D5BB527229C34C87388D48A57AFB18AF40FE9054FEB8ED4D708DBCE7F20E7A3C8494DAA6CB45DC72D8C4E3A6FD9B0652A2C71ACEB9CA2DBB4CBA2405900006F8DE3344FBD387BF70CA8C948435B17593F6837D17FE6211659D0A98BF4326F12DBACD9055A610C2BC5E633EBEE74CB16D9EE575B81578D10704F453B63AB86A8D1DEFF152799F937B84924881A60772C47800B72EFE; light_key=AASBKE7rOxgWQziEhC_QY6yaucNZPHEVXDQhBhKS-wl950m4Di2cJsVzhagTMOKGwM0RnodC; pin=jd_DgzZpkHEQlFG; ceshi3.com=203; token=435daf8ab91a1aab57cbf171345bf05f,3,966732; 3AB9D23F7A4B3CSS=jdd03SRQK3ESS76RF76R4XHLIESTUAHA6ACY2E2SZGJYIZVGVBO6BWKOZHKPPORTB7FWL52HS432WZK4TRGAV7WWUOEETFMAAAAMVE4RAM5AAAAAADXDENVX7WBZFPQX; __jda=181111935.1734234452490698444113.1734234452.1740113207.1740116789.18; __jdb=181111935.30.1734234452490698444113|18.1740116789; __jdc=181111935; shshshfpb=BApXSOpEqJPBAccag3_GHwcLS4XGa7IfVBnZiQ3xg9xJ1MupqQ4EzsnqL7Ek; flash=3_FRLDk7Sa7Bt57bROZ0PGCuxoCmudgths6jvOueRW6cR5KQ7_deDrOgQqpBW-f_MQy8NkkJVxvHqzE9-lVuV-uSIzrVhQuXkESoBYntQOqhRAxgq5ChDFam7uyS5bzQLo2uXhCdawGXUhrXK6unx9iB0JNVMqDA_K_LOYcYGxAgOjKKAQFXfO',
            }
            mainHtml = requests.get(url=f"https://item.jd.com/{id}.html", headers=headers,proxies =proxies,timeout=10)
            wadePrint(f"https://item.jd.com/{id}.html")
            print(mainHtml.text)
            if 'å•†å“åç§°' not in str(mainHtml.text):
                raise wadeTools_error.Error_continue("æ‰“å¼€ç½‘é¡µF12ï¼Œæ‰“å¼€å•†å“é¡µï¼Œæ‰¾åˆ°Cookie:åˆ‡æ¢åå†è¿è¡Œ")
            pattern = re.compile(r"<li title='(.*)'>(.*)ï¼š(.*)</li>")  # æŸ¥æ‰¾æ•°å­—
            itemDataList = pattern.findall(mainHtml.text)
            wadeTools_UserJSON.savejson(itemDataList, f'å•†å“å‚æ•°åº“/{id}')
            return (itemDataList)



    @wadeTools_Police.safe_Mode([])
    @retry(stop_max_attempt_number=5, wait_random_min=3)
    def spider_itemQueston(self,id,proxies=None):
        """çˆ¬äº§å“é—®ç­”æ¨¡å—ï¼Œéšå¿ƒè°ƒç”¨"""
        # try:

        headers = {
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'User-Agent': random.choice(HEADERS),
            'Connection': 'keep-alive',
            'Host': 'question.jd.com',
            'Content-Type': 'application/json'
        }

        # è¯·æ±‚ç¤ºä¾‹ https://question.jd.com/question/getQuestionAnswerList.action?callback=jQuery8364807&page=2&productId=100008631911
        mainHtml = requests.get(
            url=f"https://question.jd.com/question/getQuestionAnswerList.action?callback=jQuery8364807&page=2&productId={id}",
            proxies=proxies,
            headers=headers,
            timeout=10)
        try:
            questionList = json.loads(mainHtml.text[14:-2])['questionList']
        except KeyError as e:
            wadePrint("é—®ç­”æ•°æ®æ˜¯ç©º")
            return []

        askList = []  # åšä¸€ä¸ªæ¸²æŸ“åˆ—è¡¨ç»™jsonå‰æ®µæ¸²æŸ“
        for ask in questionList:
            askJSONG = {}
            # wadePrint(ask['content'])  è¿™ä¸ªæ˜¯é—®é¢˜
            askJSONG["QUESTION"] = ask['content']
            KEYSList = []
            for keys in ask['answerList']:
                # wadePrint(keys['content'])  è¿™ä¸ªæ˜¯ä¸¤ä¸ªå›ç­”
                KEYSList.append(keys['content'])
            askJSONG['KEYS'] = KEYSList
            askList.append(askJSONG)

        """[{'QUESTION': 'äº²ä»¬æ”¶åˆ°çš„æš–é£æœºå™ªéŸ³å¤§å—ï¼Ÿæœ‰æ²¡æœ‰60åˆ†è´ï¼Ÿ', 'KEYS': ['åˆšå¼€å§‹å£°éŸ³å°ï¼Œåæ¥è¶Šæ¥è¶Šåµäº†', 'å™ªéŸ³å¾ˆå°']}, {'QUESTION': 'è¿™ä¸ªæ™šä¸Šç”¨å£°éŸ³å¤§å—ï¼Ÿ', 'KEYS': ['ä¸å¤§ï¼ŒæŒºå¥½çš„', 'å£°éŸ³æ˜¯æœ‰ç‚¹çš„ï¼Œä½†èƒ½æ¥å—èŒƒå›´']}, {'QUESTION': 'è¯·é—®åˆ¶çƒ­åæœ‰æ²¡æœ‰éš¾é—»çš„å¡‘æ–™å‘³ï¼Ÿï¼Ÿï¼Ÿ', 'KEYS': ['æ²¡æœ‰', 'æ²¡æœ‰']}, {'QUESTION': 'é£é‡å¤§å—', 'KEYS': ['é£ä¸å¤§ï¼Œå¹ä¸ªä¸€ç±³å¤šå§', 'è¿‘è·ç¦»å¾ˆå¥½']}, {'QUESTION': 'å¯ä»¥é¥æ§å¼€å…³å—', 'KEYS': ['ä¸å¯ä»¥ã€‚å¯ä»¥å®šæ—¶', 'æœ‰2ç§æ¬¾å¼é€‰æ‹©   å¸¦é¥æ§çš„è´µç‚¹']}, {'QUESTION': 'æ‚éŸ³å’Œå£°éŸ³å¤§ä¸ï¼Ÿä¹°è¿‡çš„å°ä¼™ä¼´ä»¬', 'KEYS': ['æ²¡å•¥æ‚éŸ³ï¼Œä¸é€‚åˆæˆ¿é—´å¤§çš„', 'ä¸ä¼šï¼ŒåŠ çƒ­ç‰¹åˆ«å¿«ï¼Œå¥½ç”¨']}, {'QUESTION': 'æˆ‘ä¹°çš„è¿™æ¬¾æœ‰æ²¡æœ‰é¥æ§å™¨ï¼Ÿ', 'KEYS': ['æ²¡æœ‰', 'æ²¡æœ‰']}, {'QUESTION': 'æœ‰å£°éŸ³å—ï¼Ÿ', 'KEYS': ['å£°éŸ³æ¯”è¾ƒå°ï¼Œæ¥å—èŒƒå›´å†…ï¼Œä¸å½±å“', 'è¿˜æŒºå®‰é™çš„']}, {'QUESTION': 'è¯·é—®é˜²æ°´å—', 'KEYS': ['æ²¡è¯•è¿‡ï¼Œå°½é‡é¿å…æ°´å§ã€‚', 'IPX0é˜²æ°´ç­‰çº§ï¼Œæ¯”è¾ƒå·®ï¼Œä½†æ”¾åœ¨æµ´å®¤æœ‰ç‚¹æ°´æ±½é—®é¢˜ä¸å¤§ï¼Œä¸è¦æŠŠè°æº…åˆ°ä¸Šé¢']}, {'QUESTION': 'æœ‰å°å®å®å®‰å…¨å—ï¼Ÿ', 'KEYS': ['ç›¸å½“å®‰å…¨', 'å°±æ˜¯ä¹°æ¥ç»™å°å®å®æ¢å°¿ä¸æ¹¿ç”¨çš„']}]"""
            # wadePrint(askList)
        return (askList)

    def spider_itemByLeiMu(self,leimu = "",page= 1):
        url = "https://union.jd.com/api/goods/search"
        leimuITER = leimu.split(",").__iter__()
        # wadePrint(next(leimuITER,"null"))
        # exit()
        payload = "{\"pageNo\":"+str(page)+",\"pageSize\":60,\"searchUUID\":\"7b3dac2a9cc74fc8b3349161f203f4a6\",\"data\":{\"bonusIds\":null,\"categoryId\":"+next(leimuITER,"null")+",\"cat2Id\":"+next(leimuITER,"null")+",\"cat3Id\":"+next(leimuITER,"null")+",\"deliveryType\":0,\"fromCommissionRatio\":null,\"toCommissionRatio\":null,\"fromPrice\":null,\"toPrice\":null,\"hasCoupon\":0,\"isHot\":null,\"preSale\":0,\"isPinGou\":0,\"jxFlag\":0,\"isZY\":0,\"isCare\":0,\"lock\":0,\"orientationFlag\":0,\"sort\":\"desc\",\"sortName\":\"inOrderCount30Days\",\"searchType\":\"st3\",\"keywordType\":\"kt0\"}}"
        headers = {
            'accept': 'application/json, text/plain, */*',
            'user-agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36',
            'content-type': 'application/json;charset=UTF-8',
            'origin': 'https://union.jd.com',
            # 'Cookie': 'ssid="CuFN9wVpT7Co5gL20lq3Ow=="'
        }
        wadePrint(payload)
        response = requests.request("POST", url, headers=headers, data=payload)

        resultList = wadeTools_UserJSON.get_dict_by_key_method(response.json(),'skuId')
        return resultList
    def spider_itemBaiduSearch(self,keyword,page= 1):
        """
            è·å–ç™¾åº¦æœç´¢ä¸‹æ‹‰è¯æ¨èåˆ—è¡¨
            :param keyword: æœç´¢å…³é”®è¯
            :return: ä¸‹æ‹‰è¯æ¨èåˆ—è¡¨
            """
        url = "https://suggestion.baidu.com/su"
        params = {
            "wd": keyword,  # æœç´¢å…³é”®è¯
            "cb": "jQuery11020231084039737774_1678901234567",  # å›è°ƒå‡½æ•°åï¼Œå¯éšæ„å¡«å†™
            "_": "1678901234567"  # æ—¶é—´æˆ³ï¼Œå¯éšæ„å¡«å†™
        }
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"}
        try:
            response = requests.get(url, params=params, headers=headers)
            response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
            # å»é™¤JSONPçš„å›è°ƒå‡½æ•°åŒ…è£…
            json_str = response.text.strip().replace(params["cb"] + "(", "").rstrip(");")
            import json
            data = json.loads(json_str)
            suggestions = data.get("s", [])
            return suggestions
        except requests.RequestException as e:
            print(f"è¯·æ±‚å‡ºé”™: {e}")
        except json.JSONDecodeError as e:
            print(f"JSONè§£æå‡ºé”™: {e}")
        return []
class JDSpider_Drissionpage():
    """
    å› ä¸ºæ¥å£å¤±æ•ˆï¼Œé‡‡ç”¨æ¨¡æ‹Ÿæµè§ˆå™¨çš„æ–¹æ³•å–å†…å®¹
    """
    def spider_Newcomment(self, id):
        co = ChromiumOptions(read_file=False).set_paths(local_port='9888',
                                                        browser_path=r'.\chrome\Chrome.exe',
                                                        user_data_path=r'.\Chrome\userData')
        # co.headless(True)  # æ— å¤´æ¨¡å¼
        # co.set_argument('--no-headless')
        # co.set_argument('--no-sandbox')  # æ— æ²™ç›’æ¨¡å¼
        # co.set_argument('--headless=new')  # æ— ç•Œé¢ç³»ç»Ÿæ·»åŠ 
        co.set_argument('--start-maximized')
        # åˆ›å»º WebPage å®ä¾‹å¹¶ä¼ å…¥ chromium_options
        page = WebPage(chromium_options=co, session_or_options=False)
        # page.set.window.normal()
        # page.set.window.hide()
        page.set.window.show()
        # è°ƒç”¨å·²æœ‰çš„æœ€å¤§åŒ–æ–¹æ³•å°†çª—å£æœ€å¤§åŒ–
        page.set.window.max()
        # page.set.window.max()
        # page.set.window.mini()


        # æ³¨æ„ï¼šsession_or_options=False
        page.get(f"https://item.jd.com/{id}.html")
        page.wait.new_tab(timeout=2)
        tab = page.latest_tab
        wadePrint(tab.title)
        wadePrint(page.html)
        api_prefix = "https://api.m.jd.com/client.action"
        page.listen.start(targets=api_prefix, method="POST")  # ç›‘å¬åŒ…å«æŒ‡å®šå‰ç¼€çš„URL
        print("ç›‘å¬å™¨å·²å¯åŠ¨ï¼Œå¼€å§‹è®¿é—®é¡µé¢...")
        page.ele('@@tag()=div@@text()=å…¨éƒ¨è¯„ä»·').click()
        time.sleep(2)


        packet = page.listen.wait(timeout=10)  # è·å–1ä¸ªç¬¦åˆæ¡ä»¶çš„æ•°æ®åŒ…

        if not packet:
            print("è¶…æ—¶æœªè·å–åˆ°ç›®æ ‡APIæ•°æ®åŒ…")
            return None

        # 6. è§£ææ•°æ®åŒ…å†…å®¹
        print(f"æˆåŠŸæ•è·API: {packet.url}")
        # å“åº”ä½“è‡ªåŠ¨è§£æä¸ºJSONï¼ˆè‹¥ä¸ºJSONæ ¼å¼ï¼‰

        api_data = packet.response.body #æŠ“åˆ°çš„æ˜¯dictæ ¼å¼
        print(api_data)
        wadePrint(type(api_data))

        content = api_data
        # from wadeTools import wadeTools_txt
        # TXT111 = wadeTools_txt.wadeTxtObject(filename='111.txt')
        # TXT111.additem_to_Txt(page.html)
        if page.latest_tab.title == "äº¬ä¸œ-æ¬¢è¿ç™»å½•-ç™»é™†åæŒ‰å›è½¦ç»§ç»­":
            # é‡åˆ°äº¬ä¸œéªŒè¯äº†
            wadeTools_feishu.send_feishu_message(fr"ââââäº¬ä¸œ-æ¬¢è¿ç™»å½•")

            input("äº¬ä¸œ-æ¬¢è¿ç™»å½•-ç™»é™†åæŒ‰å›è½¦ç»§ç»­")  # ç¨‹åºä¼šåœ¨è¿™é‡Œæš‚åœï¼Œç›´åˆ°ç”¨æˆ·æŒ‰ä¸‹å›è½¦é”®
        if page.latest_tab.title == "äº¬ä¸œéªŒè¯":
            # é‡åˆ°äº¬ä¸œéªŒè¯äº†
            wadeTools_feishu.send_feishu_message(fr"ââââäº¬ä¸œ-éªŒè¯")

            input("éªŒè¯å--æŒ‰å›è½¦ç»§ç»­")  # ç¨‹åºä¼šåœ¨è¿™é‡Œæš‚åœï¼Œç›´åˆ°ç”¨æˆ·æŒ‰ä¸‹å›è½¦é”®



        #åˆ¤æ–­è¯„è®ºçš„ä¸ªæ•°

        commentList = wadeTools_UserJSON.get_dict_by_key_method(content, "commentData")
        imgList = wadeTools_UserJSON.get_dict_by_key_method(content, "largePicURL")

        commentList = wadeTools_Text.delBadItemFromList(commentList, wadeTools_Text.getDefaultBadWords())  #
        commentList = [item for item in commentList if len(item) >= 6]
        commentList = sorted(commentList, key=len, reverse=True)

        # wadePrint(imgList)
        imgListNew = []
        for this_imgUrl in imgList:
            # urlç»Ÿä¸€ä¿®æ”¹å‡½æ•°ï¼šæŠŠé‡Œè¾¹çš„n0å­—ç¬¦ä¸²æ›¿æ¢ï¼Œå°ºå¯¸ä¹Ÿæ›¿æ¢æ‰ æ”¹æˆs720x540
            if 'img30.360buyimg.com/n0/' in this_imgUrl:
                this_imgUrl = this_imgUrl.replace("img30.360buyimg.com/n0/",
                                                  "img30.360buyimg.com/n1/")
            if 's128x96_jfs/' in this_imgUrl:
                this_imgUrl = this_imgUrl.replace("s128x96_jfs/", "s720x540_jfs/")
            if '\n' in this_imgUrl:
                this_imgUrl = this_imgUrl.replace('\n', '')
            if '\r' in this_imgUrl:
                this_imgUrl = this_imgUrl.replace('\r', '')
            # if '//' in this_imgUrl:
            #     this_imgUrl = this_imgUrl.replace("//", "")
            imgListNew.append(this_imgUrl)
            del this_imgUrl  # é”€æ¯å˜é‡

        imgList = imgListNew
        del imgListNew

        random.shuffle(commentList)
        random.shuffle(imgList)

        del content
        return (commentList, imgList, 'ğŸ˜†jdmainè½¬æ¢æ­£å¸¸')  # æ‰“ä¹±é‡æ‹

        # return (commentList, imgList, 'ğŸ˜†jdmainè½¬æ¢æ­£å¸¸')  # æ‰“ä¹±é‡æ‹

    @wadeTools_Police.safe_Mode([])
    # @retry(stop_max_attempt_number=5, wait_random_min=3)
    def spider_itemData(self, id,proxies=None):

        # æ£€æŸ¥æ˜¯å¦æœ‰å•†å“å‚æ•°åº“
        wadeTools_path.checkFilePath('å•†å“å‚æ•°åº“')
        try:
            # å¦‚æœå‚æ•°åº“ä¸­æœ‰å°±ä¸ç”¨è¯·æ±‚äº†
            itemDataList = wadeTools_UserJSON.readjson(f'å•†å“å‚æ•°åº“/{id}')
            wadePrint(f"{id}--æˆåŠŸåŠ è½½åº“ä¸­å•†å“å‚æ•°....")
            return (itemDataList)
        except FileNotFoundError:

            # wadePrint(1)
            """çˆ¬å•†å“ä¿¡æ¯"""

            co = ChromiumOptions(read_file=False).set_paths(local_port='9888',
                                                            browser_path=r'.\chrome\Chrome.exe',
                                                            user_data_path=r'.\Chrome\userData')
            # co.headless(True)  # æ— å¤´æ¨¡å¼
            # co.set_argument('--no-headless')
            # co.set_argument('--no-sandbox')  # æ— æ²™ç›’æ¨¡å¼
            # co.set_argument('--headless=new')  # æ— ç•Œé¢ç³»ç»Ÿæ·»åŠ 
            co.set_argument('--start-maximized')
            # åˆ›å»º WebPage å®ä¾‹å¹¶ä¼ å…¥ chromium_options
            page = WebPage(chromium_options=co, session_or_options=False)
            # page.set.window.normal()
            # page.set.window.hide()
            page.set.window.show()
            # è°ƒç”¨å·²æœ‰çš„æœ€å¤§åŒ–æ–¹æ³•å°†çª—å£æœ€å¤§åŒ–
            page.set.window.max()
            # page.set.window.max()
            # page.set.window.mini()

            # page.listen.start(targets=api_prefix)  # ç›‘å¬åŒ…å«æŒ‡å®šå‰ç¼€çš„URL
            print("ç›‘å¬å™¨å·²å¯åŠ¨ï¼Œå¼€å§‹è®¿é—®é¡µé¢...")
            # æ³¨æ„ï¼šsession_or_options=False
            page.get(f"https://item.jd.com/{id}.html")
            page.wait.new_tab(timeout=2)
            tab = page.latest_tab
            wadePrint(tab.title)
            wadePrint(page.html)
            # from wadeTools import wadeTools_txt
            # TXT111 = wadeTools_txt.wadeTxtObject(filename='111.txt')
            # TXT111.additem_to_Txt(page.html)
            if page.latest_tab.title == "äº¬ä¸œ-æ¬¢è¿ç™»å½•":
                # é‡åˆ°äº¬ä¸œéªŒè¯äº†
                input("äº¬ä¸œ-æ¬¢è¿ç™»å½•-ç™»é™†åæŒ‰å›è½¦ç»§ç»­")  # ç¨‹åºä¼šåœ¨è¿™é‡Œæš‚åœï¼Œç›´åˆ°ç”¨æˆ·æŒ‰ä¸‹å›è½¦é”®
            if page.latest_tab.title == "äº¬ä¸œéªŒè¯":
                # é‡åˆ°äº¬ä¸œéªŒè¯äº†
                input("éªŒè¯å--æŒ‰å›è½¦ç»§ç»­")  # ç¨‹åºä¼šåœ¨è¿™é‡Œæš‚åœï¼Œç›´åˆ°ç”¨æˆ·æŒ‰ä¸‹å›è½¦é”®

            def parse_goods_html_with_re(html):
                """
                ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æå•†å“å±æ€§HTMLï¼Œæå–åç§°å’Œå†…å®¹ç”ŸæˆitemDataList

                å‚æ•°:
                    html: åŒ…å«å•†å“å±æ€§çš„HTMLå­—ç¬¦ä¸²
                è¿”å›:
                    itemDataList: åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º[åºå·, åç§°, å†…å®¹]
                """
                # æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼šåŒ¹é…æ¯ä¸ªitemå—ä¸­çš„nameå’Œtextå†…å®¹
                # å…ˆåŒ¹é…æ•´ä¸ªitemå—ï¼Œå†ä»ä¸­æå–nameå’Œtext
                item_pattern = re.compile(
                    r'<div class="item[^>]*?>.*?'  # åŒ¹é…itemå¼€å§‹æ ‡ç­¾
                    r'<div class="name">(.*?)</div>.*?'  # æå–nameå†…å®¹
                    r'<div class="text">(.*?)</div>.*?'  # æå–textå†…å®¹
                    r'</div>',  # åŒ¹é…itemç»“æŸæ ‡ç­¾
                    re.DOTALL  # DOTALLæ¨¡å¼è®©.åŒ¹é…åŒ…æ‹¬æ¢è¡Œç¬¦åœ¨å†…çš„æ‰€æœ‰å­—ç¬¦
                )

                # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„item
                matches = item_pattern.findall(html)

                itemDataList = []
                for index, (name, content) in enumerate(matches, 1):
                    # æ¸…ç†åç§°å’Œå†…å®¹ä¸­çš„å¤šä½™ç©ºç™½ã€HTMLæ ‡ç­¾
                    clean_name = re.sub(r'<.*?>', '', name).strip()  # ç§»é™¤å¯èƒ½çš„åµŒå¥—æ ‡ç­¾
                    clean_content = re.sub(r'<.*?>', '', content).strip()  # ç§»é™¤aæ ‡ç­¾ç­‰

                    itemDataList.append([index, clean_name, clean_content])

                return itemDataList

            # è§£æå¹¶æ‰“å°ç»“æœ
            itemDataList = parse_goods_html_with_re(page.html)
            print("ç”Ÿæˆçš„itemDataList:")
            for item in itemDataList:
                print(item)

            # æ¼”ç¤ºä½¿ç”¨æ–¹å¼
            # print("\nä½¿ç”¨ç¤ºä¾‹:")
            # for items in itemDataList:
            #     itemName = items[1]
            #     itemContent = items[2]
            #     print(f"{itemName}: {itemContent}")
            wadeTools_UserJSON.savejson(itemDataList, f'å•†å“å‚æ•°åº“/{id}')
            return (itemDataList)



    @wadeTools_Police.safe_Mode([])
    @retry(stop_max_attempt_number=5, wait_random_min=3)
    def spider_itemQueston(self,id,proxies=None):
        """çˆ¬äº§å“é—®ç­”æ¨¡å—ï¼Œéšå¿ƒè°ƒç”¨"""
        # try:

        headers = {
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'User-Agent': random.choice(HEADERS),
            'Connection': 'keep-alive',
            'Host': 'question.jd.com',
            'Content-Type': 'application/json'
        }

        # è¯·æ±‚ç¤ºä¾‹ https://question.jd.com/question/getQuestionAnswerList.action?callback=jQuery8364807&page=2&productId=100008631911
        mainHtml = requests.get(
            url=f"https://question.jd.com/question/getQuestionAnswerList.action?callback=jQuery8364807&page=2&productId={id}",
            proxies=proxies,
            headers=headers,
            timeout=10)
        try:
            questionList = json.loads(mainHtml.text[14:-2])['questionList']
        except KeyError as e:
            wadePrint("é—®ç­”æ•°æ®æ˜¯ç©º")
            return []

        askList = []  # åšä¸€ä¸ªæ¸²æŸ“åˆ—è¡¨ç»™jsonå‰æ®µæ¸²æŸ“
        for ask in questionList:
            askJSONG = {}
            # wadePrint(ask['content'])  è¿™ä¸ªæ˜¯é—®é¢˜
            askJSONG["QUESTION"] = ask['content']
            KEYSList = []
            for keys in ask['answerList']:
                # wadePrint(keys['content'])  è¿™ä¸ªæ˜¯ä¸¤ä¸ªå›ç­”
                KEYSList.append(keys['content'])
            askJSONG['KEYS'] = KEYSList
            askList.append(askJSONG)

        """[{'QUESTION': 'äº²ä»¬æ”¶åˆ°çš„æš–é£æœºå™ªéŸ³å¤§å—ï¼Ÿæœ‰æ²¡æœ‰60åˆ†è´ï¼Ÿ', 'KEYS': ['åˆšå¼€å§‹å£°éŸ³å°ï¼Œåæ¥è¶Šæ¥è¶Šåµäº†', 'å™ªéŸ³å¾ˆå°']}, {'QUESTION': 'è¿™ä¸ªæ™šä¸Šç”¨å£°éŸ³å¤§å—ï¼Ÿ', 'KEYS': ['ä¸å¤§ï¼ŒæŒºå¥½çš„', 'å£°éŸ³æ˜¯æœ‰ç‚¹çš„ï¼Œä½†èƒ½æ¥å—èŒƒå›´']}, {'QUESTION': 'è¯·é—®åˆ¶çƒ­åæœ‰æ²¡æœ‰éš¾é—»çš„å¡‘æ–™å‘³ï¼Ÿï¼Ÿï¼Ÿ', 'KEYS': ['æ²¡æœ‰', 'æ²¡æœ‰']}, {'QUESTION': 'é£é‡å¤§å—', 'KEYS': ['é£ä¸å¤§ï¼Œå¹ä¸ªä¸€ç±³å¤šå§', 'è¿‘è·ç¦»å¾ˆå¥½']}, {'QUESTION': 'å¯ä»¥é¥æ§å¼€å…³å—', 'KEYS': ['ä¸å¯ä»¥ã€‚å¯ä»¥å®šæ—¶', 'æœ‰2ç§æ¬¾å¼é€‰æ‹©   å¸¦é¥æ§çš„è´µç‚¹']}, {'QUESTION': 'æ‚éŸ³å’Œå£°éŸ³å¤§ä¸ï¼Ÿä¹°è¿‡çš„å°ä¼™ä¼´ä»¬', 'KEYS': ['æ²¡å•¥æ‚éŸ³ï¼Œä¸é€‚åˆæˆ¿é—´å¤§çš„', 'ä¸ä¼šï¼ŒåŠ çƒ­ç‰¹åˆ«å¿«ï¼Œå¥½ç”¨']}, {'QUESTION': 'æˆ‘ä¹°çš„è¿™æ¬¾æœ‰æ²¡æœ‰é¥æ§å™¨ï¼Ÿ', 'KEYS': ['æ²¡æœ‰', 'æ²¡æœ‰']}, {'QUESTION': 'æœ‰å£°éŸ³å—ï¼Ÿ', 'KEYS': ['å£°éŸ³æ¯”è¾ƒå°ï¼Œæ¥å—èŒƒå›´å†…ï¼Œä¸å½±å“', 'è¿˜æŒºå®‰é™çš„']}, {'QUESTION': 'è¯·é—®é˜²æ°´å—', 'KEYS': ['æ²¡è¯•è¿‡ï¼Œå°½é‡é¿å…æ°´å§ã€‚', 'IPX0é˜²æ°´ç­‰çº§ï¼Œæ¯”è¾ƒå·®ï¼Œä½†æ”¾åœ¨æµ´å®¤æœ‰ç‚¹æ°´æ±½é—®é¢˜ä¸å¤§ï¼Œä¸è¦æŠŠè°æº…åˆ°ä¸Šé¢']}, {'QUESTION': 'æœ‰å°å®å®å®‰å…¨å—ï¼Ÿ', 'KEYS': ['ç›¸å½“å®‰å…¨', 'å°±æ˜¯ä¹°æ¥ç»™å°å®å®æ¢å°¿ä¸æ¹¿ç”¨çš„']}]"""
            # wadePrint(askList)
        return (askList)

    def spider_itemByLeiMu(self,leimu = "",page= 1):
        url = "https://union.jd.com/api/goods/search"
        leimuITER = leimu.split(",").__iter__()
        # wadePrint(next(leimuITER,"null"))
        # exit()
        payload = "{\"pageNo\":"+str(page)+",\"pageSize\":60,\"searchUUID\":\"7b3dac2a9cc74fc8b3349161f203f4a6\",\"data\":{\"bonusIds\":null,\"categoryId\":"+next(leimuITER,"null")+",\"cat2Id\":"+next(leimuITER,"null")+",\"cat3Id\":"+next(leimuITER,"null")+",\"deliveryType\":0,\"fromCommissionRatio\":null,\"toCommissionRatio\":null,\"fromPrice\":null,\"toPrice\":null,\"hasCoupon\":0,\"isHot\":null,\"preSale\":0,\"isPinGou\":0,\"jxFlag\":0,\"isZY\":0,\"isCare\":0,\"lock\":0,\"orientationFlag\":0,\"sort\":\"desc\",\"sortName\":\"inOrderCount30Days\",\"searchType\":\"st3\",\"keywordType\":\"kt0\"}}"
        headers = {
            'accept': 'application/json, text/plain, */*',
            'user-agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36',
            'content-type': 'application/json;charset=UTF-8',
            'origin': 'https://union.jd.com',
            # 'Cookie': 'ssid="CuFN9wVpT7Co5gL20lq3Ow=="'
        }
        wadePrint(payload)
        response = requests.request("POST", url, headers=headers, data=payload)

        resultList = wadeTools_UserJSON.get_dict_by_key_method(response.json(),'skuId')
        return resultList
    def spider_itemBaiduSearch(self,keyword,page= 1):
        """
            è·å–ç™¾åº¦æœç´¢ä¸‹æ‹‰è¯æ¨èåˆ—è¡¨
            :param keyword: æœç´¢å…³é”®è¯
            :return: ä¸‹æ‹‰è¯æ¨èåˆ—è¡¨
            """
        url = "https://suggestion.baidu.com/su"
        params = {
            "wd": keyword,  # æœç´¢å…³é”®è¯
            "cb": "jQuery11020231084039737774_1678901234567",  # å›è°ƒå‡½æ•°åï¼Œå¯éšæ„å¡«å†™
            "_": "1678901234567"  # æ—¶é—´æˆ³ï¼Œå¯éšæ„å¡«å†™
        }
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"}
        try:
            response = requests.get(url, params=params, headers=headers)
            response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
            # å»é™¤JSONPçš„å›è°ƒå‡½æ•°åŒ…è£…
            json_str = response.text.strip().replace(params["cb"] + "(", "").rstrip(");")
            import json
            data = json.loads(json_str)
            suggestions = data.get("s", [])
            return suggestions
        except requests.RequestException as e:
            print(f"è¯·æ±‚å‡ºé”™: {e}")
        except json.JSONDecodeError as e:
            print(f"JSONè§£æå‡ºé”™: {e}")
        return []



# è¿™ä¸ªç±»ä»¥åè¦æ‰©å±•å¾ˆå¤šæ¥å£
class TBSpider():
    def spider_comment(self, id, page):
        """çˆ¬è¯„è®º"""
        # try:
        HEADERS = [
            'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.5359.95 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.117 Safari/537.36',
            'Mozilla/5.0Â (Windows;U;WindowsNT6.1;en-us)AppleWebKit/534.50(KHTML,likeGecko)Version/5.1Safari/534.50',
        ]
        # url = f'https://club.jd.com/productpage/p-{id}-s-3-t-5-p-0.html?callback=fetchJSON_comment98vv37'

        url = f'https://rate.tmall.com/list_detail_rate.htm?itemId=524673596684&spuId=473544268&sellerId=2594916711&order=3&currentPage=4&pageSize=20&append=0&picture=0'
        # else:
        #     url = f'https://club.jd.com/comment/productPageComments.action?callback=fetchJSON_comment98&productId={id}&score=3&sortType=6&page={page}0&pageSize=10&isShadowSku=0&fold=1'
        headers = {
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'User-Agent': random.choice(HEADERS),
            'Connection': 'keep-alive',
            # 'Host': 'club.jd.com',
        }
        # wadePrint(url)
        html = requests.get(url=url, headers=headers)
        # wadePrint(html.text)
        # # å»æ‰å¤šä½™å¾—åˆ°jsonæ ¼å¼
        # content = html.text.strip('fetchJSON_comment98vv995();')
        # content = content.strip('fetchJSON_comment98vv37();')
        # json_flag = json.loads(content, strict=False)  # æ”¶åˆ°çš„strå†…å®¹è¿›è¡Œæ¸…æ´—å¤„ç†ï¼Œå˜æˆå¯ç”¨çš„jsonï¼Œå¤„ç†å¥½äº†
        #
        # wadePrint('jdmainè¿è¡ŒæˆåŠŸï¼ˆäº¬ä¸œçˆ¬è™«ä¸»ç¨‹åºï¼‰')
        # JSONlist = json_flag["comments"]
        # if JSONlist == []:
        #     wadePrint('JDSpiderè¯„è®ºä¸ºç©º')
        #     return [], [], 'ğŸ˜…JDSpiderçˆ¬è™«è¯„è®ºä¸ºç©º'
        # commentList = []
        # imgList = []
        #
        # for num in range(0, len(JSONlist) - 1):
        #     if 'content' in JSONlist[num] and len(commentList) < 150000:  # è‹¥å­˜åœ¨å†…å®¹ï¼Œå¹¶ä¸”å†…å®¹æ¡æ•°å°‘äº4æ¡
        #         if len(JSONlist[num]['content']) <= 300 and len(JSONlist[num]['content']) >= 8:  # æ§åˆ¶å­—ç¬¦150ä»¥å†…
        #             if 'æ­¤ç”¨æˆ·æœªå¡«å†™è¯„' in JSONlist[num]['content'] \
        #                     or 'åƒåœ¾' in JSONlist[num]['content'] \
        #                     or 'ä¸è¦ä¹°' in JSONlist[num]['content'] \
        #                     or 'å·®è¯„' in JSONlist[num]['content'] \
        #                     or 'åäº†' in JSONlist[num]['content'] \
        #                     or 'åˆ·' in JSONlist[num]['content'] \
        #                     or 'è¯„è®º' in JSONlist[num]['content'] \
        #                     or 'åˆ«ä¹°' in JSONlist[num]['content'] \
        #                     or 'åæ‚”' in JSONlist[num]['content'] \
        #                     or 'çœŸçƒ‚' in JSONlist[num]['content'] \
        #                     or 'å¯’å¿ƒ' in JSONlist[num]['content'] \
        #                     or 'è¾£é¸¡' in JSONlist[num]['content'] \
        #                     or 'å·®' in JSONlist[num]['content'] \
        #                     or 'å·®' in JSONlist[num]['content'] \
        #                     or 'æ…é‡ä¹°' in JSONlist[num]['content'] \
        #                     or 'æŠ•è¯‰' in JSONlist[num]['content'] \
        #                     or 'é€€è´§' in JSONlist[num]['content'] \
        #                     or 'æœ‰ç¼ºé™·' in JSONlist[num]['content'] \
        #                     or 'ä¸è´Ÿè´£ä»»' in JSONlist[num]['content'] \
        #                     or '**' in JSONlist[num]['content'] \
        #                     :
        #                 wadePrint('å¿½ç•¥å†…å®¹--------------------------------------------')
        #                 pass
        #             else:
        #                 commentList.append(JSONlist[num]['content'].replace('\n', '').replace('\r', ''))
        #         else:
        #             continue
        # for num in range(0, len(JSONlist) - 1):
        #     if 'images' in JSONlist[num] and len(imgList) < 10000:  # è‹¥å­˜åœ¨å†…å®¹ï¼Œå¹¶ä¸”å†…å®¹æ¡æ•°å°‘äº4æ¡
        #         for imgNum in range(0, len(JSONlist[num]['images'])):
        #             if 'imgUrl' in JSONlist[num]['images'][imgNum]:  # æ§åˆ¶å­—ç¬¦150ä»¥å†…
        #                 this_imgUrl = JSONlist[num]['images'][imgNum]['imgUrl']
        #                 # urlç»Ÿä¸€ä¿®æ”¹å‡½æ•°ï¼šæŠŠé‡Œè¾¹çš„n0å­—ç¬¦ä¸²æ›¿æ¢ï¼Œå°ºå¯¸ä¹Ÿæ›¿æ¢æ‰ æ”¹æˆs720x540
        #                 if 'img30.360buyimg.com/n0/' in this_imgUrl:
        #                     this_imgUrl = this_imgUrl.replace("img30.360buyimg.com/n0/",
        #                                                       "img30.360buyimg.com/n1/")
        #                 if 's128x96_jfs/' in this_imgUrl:
        #                     this_imgUrl = this_imgUrl.replace("s128x96_jfs/", "s720x540_jfs/")
        #                 if '\n' in this_imgUrl:
        #                     this_imgUrl = this_imgUrl.replace('\n', '')
        #                 if '\r' in this_imgUrl:
        #                     this_imgUrl = this_imgUrl.replace('\r', '')
        #                 # if '//' in this_imgUrl:
        #                 #     this_imgUrl = this_imgUrl.replace("//", "")
        #                 imgList.append(this_imgUrl)
        #                 del this_imgUrl  # é”€æ¯å˜é‡
        #             else:
        #                 continue
        #     if 'afterImages' in JSONlist[num] and len(imgList) < 10000:  # è‹¥å­˜åœ¨å†…å®¹ï¼Œå¹¶ä¸”å†…å®¹æ¡æ•°å°‘äº4æ¡
        #         wadePrint(JSONlist[num]['afterImages'])
        #         for imgNum in range(0, len(JSONlist[num]['afterImages'])):
        #             wadePrint(JSONlist[num]['afterImages'][imgNum])
        #             if 'imgUrl' in JSONlist[num]['afterImages'][imgNum]:  # æ§åˆ¶å­—ç¬¦150ä»¥å†…
        #                 this_imgUrl = JSONlist[num]['afterImages'][imgNum]['imgUrl']
        #                 wadePrint(JSONlist[num]['afterImages'][imgNum]['imgUrl'])
        #                 # urlç»Ÿä¸€ä¿®æ”¹å‡½æ•°ï¼šæŠŠé‡Œè¾¹çš„n0å­—ç¬¦ä¸²æ›¿æ¢ï¼Œå°ºå¯¸ä¹Ÿæ›¿æ¢æ‰ æ”¹æˆs720x540
        #                 if 'img30.360buyimg.com/n0/' in this_imgUrl:
        #                     this_imgUrl = this_imgUrl.replace("img30.360buyimg.com/n0/",
        #                                                       "img30.360buyimg.com/n1/")
        #                 if 's128x96_jfs/' in this_imgUrl:
        #                     this_imgUrl = this_imgUrl.replace("s128x96_jfs/", "s720x540_jfs/")
        #                 if '\n' in this_imgUrl:
        #                     this_imgUrl = this_imgUrl.replace('\n', '')
        #                 if '\r' in this_imgUrl:
        #                     this_imgUrl = this_imgUrl.replace('\r', '')
        #                 # if '//' in this_imgUrl:
        #                 #     this_imgUrl = this_imgUrl.replace("//", "")
        #                 imgList.append(this_imgUrl)
        #                 del this_imgUrl  # é”€æ¯å˜é‡
        #             else:
        #                 continue
        #     else:
        #         continue
        #
        # wadePrint(f'äº¬ä¸œçˆ¬è™«ç¨‹åºç»“æŸ,è·å–è¯„è®º{len(commentList)}æ¡ï¼Œå›¾ç‰‡{len(imgList)}æ¡')
        # # wadePrint(imgList)
        # random.shuffle(commentList)
        # random.shuffle(imgList)
        # # wadePrint(imgList)
        #
        # del content,json_flag,JSONlist
        # return commentList, imgList, 'ğŸ˜†jdmainè½¬æ¢æ­£å¸¸'  # æ‰“ä¹±é‡æ‹
        # # except Exception as e:
        # #     return [], [], 'ğŸ˜…jdmainè½¬æ¢å‡ºé”™'


if __name__ == '__main__':
    # wordList,imgLIST,result = JDSpider().spider_Newcomment(10034589227536, 0)
    # wadePrint(wordList,imgLIST,result)
    # wadePrint(JDSpider().spider_itemByLeiMu("1319,1523,7054"))
    # wadePrint(JDSpider().spider_Newcomment(100021972412, 211111))
    # jdOBJ = JDSpider()
    # jdOBJ.jdSing()
    # for i in range(20):
    #
    #     # wadePrint(JDSpider().spider_Newcomment(100021972412, i,proxies=wadeTools_Agent.getAGENT()))
    #     wadePrint(JDSpider().spider_Newcomment(100021972412, i,wadeTools_Agent.getAgent()))
    #     # wadePrint(JDSpider().spider_itemQueston(100016086218))
    #     # wadePrint(max(len(s) for s in JDSpider().spider_itemQueston(100016086218)[0]['KEYS']))
    #     # wadePrint(max(JDSpider().spider_itemQueston(100016086218)[0]['KEYS'], key=len, default=''))


    # wadePrint(JDSpider().spider_Newcomment(10142124390094, 0))
    # a = JDSpider_Drissionpage().spider_itemQueston(10142124390094)    # a = JDSpider().spider_itspider_itemDataemBaiduSearch(10090874160408, 0)
    # wadePrint(a)
    print(JDSpider_Drissionpage().spider_itemBaiduSearch(keyword="è”æƒ³å°æ–°ç¬”è®°æœ¬"))