Metadata-Version: 2.1
Name: pyautocausal
Version: 0.1.1
Summary: Automated causal inference pipelines for data scientists
Home-page: https://github.com/NickyTops23/pyautocausal
License: MIT
Keywords: causal-inference,econometrics,statistics,difference-in-differences,synthetic-control
Author: Nicholas Topousis
Author-email: nicktopousis@gmail.com
Requires-Python: >=3.10,<3.13
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Office/Business :: Financial :: Investment
Classifier: Topic :: Scientific/Engineering :: Information Analysis
Classifier: Topic :: Scientific/Engineering :: Mathematics
Requires-Dist: cloudpickle (>=3.1.1,<4.0.0)
Requires-Dist: cvxpy (>=1.1.7)
Requires-Dist: jinja2 (>=2.10)
Requires-Dist: linearmodels (>=6.1,<7.0)
Requires-Dist: matplotlib (>=2.2.3)
Requires-Dist: nbformat (>=5.10.4,<6.0.0)
Requires-Dist: networkx (>=3.4.2,<4.0.0)
Requires-Dist: numpy (>=1.17)
Requires-Dist: pandas (>=1.1.2)
Requires-Dist: pyarrow (>=18.1.0,<19.0.0)
Requires-Dist: pyyaml (>=6.0,<7.0)
Requires-Dist: scikit-learn (>=1.6.1,<2.0.0)
Requires-Dist: scipy (>=1.4.1)
Requires-Dist: statsmodels (>=0.14.1,<0.15.0)
Project-URL: Documentation, https://github.com/NickyTops23/pyautocausal/blob/main/README.md
Project-URL: Repository, https://github.com/NickyTops23/pyautocausal
Description-Content-Type: text/markdown

# PyAutoCausal

**Automated causal inference pipelines for data scientists**

## Why Causal Inference Matters in Tech

As data scientists, we're often asked to go beyond correlation and answer causal questions: 
- "Did our new recommendation algorithm actually increase user engagement, or was it just seasonal trends?"
- "What's the true impact of our premium subscription tier on customer retention?"
- "How much did our marketing campaign increase conversions versus organic growth?"
- "Did our product redesign cause the drop in user activity, or was it market conditions?"

These questions can't be answered with standard predictive models or A/B tests alone. Real-world constraints often prevent randomized experiments:
- **Ethical concerns**: Can't randomly deny users important features
- **Business constraints**: Can't risk revenue on large-scale experiments  
- **Natural experiments**: Sometimes changes happen organically (competitor exits, policy changes)
- **Historical analysis**: Need to evaluate past decisions without experimental data

## The Challenge of Observational Data

When working with observational data (logs, user behavior, historical metrics), we face fundamental challenges:

1. **Confounding**: Users who adopt premium features might be inherently more engaged
2. **Selection bias**: Treatment assignment isn't random
3. **Time-varying effects**: Impact changes over time
4. **Heterogeneous effects**: Different user segments respond differently

Traditional ML models are built for prediction, not causal inference. They'll happily exploit confounders and selection bias to maximize accuracy, giving you precisely wrong answers to causal questions.

## PyAutoCausal: Causal Inference Made Practical

PyAutoCausal automates the complex decision tree of modern causal inference methods. Instead of manually implementing and choosing between dozens of estimators, PyAutoCausal:

1. **Analyzes your data structure** to understand treatment timing, units, and available controls
2. **Selects appropriate methods** based on your data characteristics
3. **Validates assumptions** and warns about potential violations
4. **Executes analysis** with proper statistical inference
5. **Exports results** in formats ready for stakeholder communication

## Quick Example: Measuring Feature Impact

```python
from pyautocausal.pipelines.example_graph import causal_pipeline
import pandas as pd

# Your product data with treatment (feature rollout) and outcome (engagement)
data = pd.DataFrame({
    'id_unit': [...],        # User identifier
    't': [...],              # Time periods
    'treat': [...],          # 1 if user has feature, 0 otherwise
    'y': [...],              # Your KPI (DAU, sessions, revenue, etc.)
    'x1': [...],             # User characteristics
    'x2': [...]              # Additional controls
})

# PyAutoCausal automatically:
# - Detects this is panel data with staggered treatment
# - Chooses modern DiD methods (e.g., Callaway-Sant'Anna)
# - Handles heterogeneous treatment effects
# - Produces event study plots

pipeline = causal_pipeline(output_path="./feature_impact_analysis")
pipeline.fit(df=data)

# Results include:
# - Average treatment effect with confidence intervals
# - Dynamic effects over time since treatment
# - Heterogeneity analysis across user segments
# - Diagnostic plots and assumption checks
```

## Real Tech Applications

### Product & Feature Analysis
- **Feature rollout impact**: Measure true lift from new features beyond selection effects
- **UI/UX changes**: Isolate design impact from user self-selection
- **Pricing changes**: Estimate elasticity when users choose their plans
- **Platform migrations**: Quantify the causal effect of moving users to new systems

### Marketing & Growth
- **Campaign effectiveness**: Separate campaign impact from organic trends
- **Channel attribution**: Understand true incremental value of marketing channels
- **Retention interventions**: Measure causal impact of win-back campaigns
- **Geographic expansions**: Estimate market entry effects using synthetic controls

### Business Operations
- **Policy changes**: Evaluate impact of new policies on user behavior
- **Competitive effects**: Measure how competitor actions affect your metrics
- **Seasonal adjustments**: Separate true treatment effects from seasonality
- **Long-term impacts**: Track how effects evolve over months/years

## Why Automation Matters

Modern causal inference has seen an explosion of methods in recent years. Choosing correctly requires deep knowledge of:
- Parallel trends assumptions
- Staggered treatment timing
- Heterogeneous treatment effects
- Two-way fixed effects bias
- Synthetic control construction

PyAutoCausal encodes this expertise, automatically routing your analysis through the appropriate methods while maintaining transparency about assumptions and limitations.

## Installation

```bash
pip install pyautocausal
```

Or for development:

```bash
git clone https://github.com/yourusername/pyautocausal.git
cd pyautocausal
poetry install
```

## Core Concepts

### Graph-Based Pipeline Architecture

PyAutoCausal organizes causal analysis as directed graphs of computational nodes:

```python
from pyautocausal.orchestration.graph import ExecutableGraph
from pyautocausal.persistence.output_config import OutputConfig, OutputType

# Build custom pipelines using the graph API
graph = (ExecutableGraph()
    .configure_runtime(output_path="./outputs")
    .create_input_node("data", input_dtype=pd.DataFrame)
    .create_decision_node("has_multiple_periods", 
                         condition=lambda df: df['t'].nunique() > 1,
                         predecessors=["data"])
    .create_node("cross_sectional_analysis", 
                cross_sectional_estimator,
                predecessors=["has_multiple_periods"])
    .create_node("panel_analysis",
                panel_estimator, 
                predecessors=["has_multiple_periods"])
    .when_false("has_multiple_periods", "cross_sectional_analysis")
    .when_true("has_multiple_periods", "panel_analysis")
)

graph.fit(data=your_dataframe)
```

### Automated Method Selection

The framework automatically routes your data through appropriate causal inference methods:

- **Cross-sectional** (single time period) â†’ OLS with robust inference
- **Panel with single treated unit** â†’ Synthetic control methods
- **Panel with multiple treatment timing** â†’ Modern DiD estimators
- **Staggered treatment adoption** â†’ Callaway-Sant'Anna, BACON decomposition
- **Large datasets** â†’ Double/debiased machine learning approaches

### Built-in Validation

Every analysis includes:
- **Data quality checks**: Missing values, duplicates, proper formatting
- **Assumption testing**: Parallel trends, common support, balance
- **Robustness checks**: Alternative specifications and estimators
- **Diagnostic plots**: Visual assumption validation

## Project Structure

```
pyautocausal/
â”œâ”€â”€ orchestration/          # Core graph execution framework
â”‚   â”œâ”€â”€ graph.py            # ExecutableGraph class and execution logic
â”‚   â”œâ”€â”€ nodes.py            # Node types (standard, decision, input)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ pipelines/              # Pre-built causal inference workflows
â”‚   â”œâ”€â”€ library/            # Reusable causal analysis components
â”‚   â”‚   â”œâ”€â”€ specifications.py  # Treatment/outcome specifications
â”‚   â”‚   â”œâ”€â”€ estimators.py      # Statistical estimators
â”‚   â”‚   â”œâ”€â”€ conditions.py      # Data characteristic detectors
â”‚   â”‚   â”œâ”€â”€ plots.py           # Visualization functions
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ example_graph.py    # Main causal inference pipeline
â”œâ”€â”€ causal_methods/         # Core statistical methods
â”‚   â””â”€â”€ double_ml.py        # DoubleML implementation
â”œâ”€â”€ persistence/            # Output handling and export
â”‚   â”œâ”€â”€ notebook_export.py  # Jupyter notebook generation
â”‚   â”œâ”€â”€ output_config.py    # Output format configuration
â”‚   â””â”€â”€ ...
â””â”€â”€ utils/                  # Utility functions
```

## Next Steps

- **ðŸ“– [Getting Started Guide](docs/getting-started.md)** - Step-by-step tutorial
- **ðŸ“Š [Causal Methods Reference](docs/causal-methods.md)** - All available estimators
- **ðŸ”§ [Pipeline Development](docs/pipeline-guide.md)** - Building custom workflows
- **ðŸ“‹ [Data Requirements](docs/data-requirements.md)** - Input formats and validation
- **ðŸ’¡ [Examples](docs/examples/)** - Real-world case studies

## Contributing

We welcome contributions! Please see our [contributing guidelines](CONTRIBUTING.md) for details.

## License

[MIT License](LICENSE)

## Citation

If you use PyAutoCausal in your research, please cite:

```bibtex
@software{pyautocausal,
  title={PyAutoCausal: Automated Causal Inference Pipelines},
  author={Your Name},
  year={2024},
  url={https://github.com/yourusername/pyautocausal}
}
```

