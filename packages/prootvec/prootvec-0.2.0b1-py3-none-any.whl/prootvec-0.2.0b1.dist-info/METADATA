Metadata-Version: 2.4
Name: prootvec
Version: 0.2.0b1
Summary: ProotVec: librer√≠a m√≠nima para vectorizaci√≥n y entrenamiento b√°sico en ARM64/Ubuntu/Termux
Author-email: TuNombre <tucorreo@example.com>
License: MIT
Project-URL: Homepage, https://pypi.org/project/prootvec/
Requires-Python: >=3.8
Description-Content-Type: text/markdown
Requires-Dist: numpy>=1.20
Requires-Dist: regex>=2020.0.0

# ProotVec 0.2.0b1

üöÄ **ProotVec** es una librer√≠a **m√≠nima** y **ligera** para vectorizaci√≥n y entrenamiento b√°sico de embeddings en sistemas **ARM64**, ideal para entornos como **Ubuntu** y **Termux**.

Incluye un sistema modular en **6 nanos**:
- `tokenizer.py` ‚Üí Convierte texto en tokens.
- `losses.py` ‚Üí Funciones de p√©rdida b√°sicas.
- `model.py` ‚Üí Modelo de embeddings con inicializaci√≥n aleatoria.
- `trainer.py` ‚Üí Entrenamiento supervisado simple.
- `reinforce.py` ‚Üí Refuerzo con similitud coseno.
- `utils.py` ‚Üí Guardar y cargar modelos.

---

## Instalaci√≥n

Desde PyPI (cuando lo subas):

```bash
pip install prootvec

from prootvec import Tokenizer, EmbeddingModel, Trainer, Reinforce, save_model, load_model

# 1. Tokenizar
tk = Tokenizer()
tk.fit(["hola mundo", "texto de prueba"])
print("Vocabulario:", tk.vocab)

# 2. Modelo
model = EmbeddingModel(vocab_size=len(tk.vocab), embedding_dim=8)

# 3. Entrenador
trainer = Trainer(model)
pairs = [(tk.vocab["hola"], tk.vocab["mundo"])]
trainer.train_epoch(pairs, epochs=5)

# 4. Refuerzo
reinforce = Reinforce(model)
sim = reinforce.reinforce_pair(tk.vocab["hola"], tk.vocab["mundo"])
print("Similitud reforzada:", sim)

# 5. Guardar
save_model("modelo.json", tk.vocab, model.embeddings)

# 6. Cargar
vocab, embeddings = load_model("modelo.json")
print("Vocabulario cargado:", vocab)
